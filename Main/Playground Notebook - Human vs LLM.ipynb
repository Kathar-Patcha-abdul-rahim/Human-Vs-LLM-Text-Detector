{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e691ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e47123e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>lexical_diversity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Federal law supersedes state law, and cannabis...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>967</td>\n",
       "      <td>157</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.806630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Miles feels restless after working all day. He...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>5068</td>\n",
       "      <td>778</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.661255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So first of I am danish. That means that I fol...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>1602</td>\n",
       "      <td>267</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.718354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this paper we present a novel rule-based ap...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>5469</td>\n",
       "      <td>848</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.564532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Most social progressives, love democracy, and ...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>2379</td>\n",
       "      <td>380</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.752860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    source  text_length  \\\n",
       "0  Federal law supersedes state law, and cannabis...  Bloom-7B          967   \n",
       "1  Miles feels restless after working all day. He...  Bloom-7B         5068   \n",
       "2  So first of I am danish. That means that I fol...  Bloom-7B         1602   \n",
       "3  In this paper we present a novel rule-based ap...  Bloom-7B         5469   \n",
       "4  Most social progressives, love democracy, and ...  Bloom-7B         2379   \n",
       "\n",
       "   word_count     Prompt  lexical_diversity  \n",
       "0         157  Undefined           0.806630  \n",
       "1         778  Undefined           0.661255  \n",
       "2         267  Undefined           0.718354  \n",
       "3         848  Undefined           0.564532  \n",
       "4         380  Undefined           0.752860  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbd859bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/abishekjoshuat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 89\u001b[0m\n\u001b[1;32m     86\u001b[0m df \u001b[38;5;241m=\u001b[39m df_merged\n\u001b[1;32m     88\u001b[0m model \u001b[38;5;241m=\u001b[39m KeyedVectors\u001b[38;5;241m.\u001b[39mload_word2vec_format(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGoogleNews-vectors-negative300.bin\u001b[39m\u001b[38;5;124m'\u001b[39m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 89\u001b[0m df \u001b[38;5;241m=\u001b[39m add_features_to_df(df, model)\n\u001b[1;32m     91\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(pca,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlp_pca.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 63\u001b[0m, in \u001b[0;36madd_features_to_df\u001b[0;34m(df, model)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Add computed features to the DataFrame.\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlexical_diversity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(lexical_diversity)\n\u001b[0;32m---> 63\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_sentence_length\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(average_sentence_length)\n\u001b[1;32m     64\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadability_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(compute_readability_score)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Adding text length metrics\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer(\n\u001b[1;32m   1175\u001b[0m             values,\n\u001b[1;32m   1176\u001b[0m             f,\n\u001b[1;32m   1177\u001b[0m             convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype,\n\u001b[1;32m   1178\u001b[0m         )\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m, in \u001b[0;36maverage_sentence_length\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the average sentence length.\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m sentences \u001b[38;5;241m=\u001b[39m sent_tokenize(text)\n\u001b[0;32m---> 25\u001b[0m tokens \u001b[38;5;241m=\u001b[39m word_tokenize(text)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tokens) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(sentences) \u001b[38;5;28;01mif\u001b[39;00m sentences \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/nltk/tokenize/__init__.py:130\u001b[0m, in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03mReturn a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03musing NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m:type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    131\u001b[0m     token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[1;32m    132\u001b[0m ]\n",
      "File \u001b[0;32m~/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/nltk/tokenize/__init__.py:131\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03mReturn a tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03musing NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m:type preserve_line: bool\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 131\u001b[0m     token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[1;32m    132\u001b[0m ]\n",
      "File \u001b[0;32m~/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/nltk/tokenize/destructive.py:157\u001b[0m, in \u001b[0;36mNLTKWordTokenizer.tokenize\u001b[0;34m(self, text, convert_parentheses, return_str)\u001b[0m\n\u001b[1;32m    149\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn_str\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been deprecated and should no \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlonger be used.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    152\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m    153\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    154\u001b[0m     )\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m regexp, substitution \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSTARTING_QUOTES:\n\u001b[0;32m--> 157\u001b[0m     text \u001b[38;5;241m=\u001b[39m regexp\u001b[38;5;241m.\u001b[39msub(substitution, text)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m regexp, substitution \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPUNCTUATION:\n\u001b[1;32m    160\u001b[0m     text \u001b[38;5;241m=\u001b[39m regexp\u001b[38;5;241m.\u001b[39msub(substitution, text)\n",
      "File \u001b[0;32m~/Developer/Sample_ML_Project/env/lib/python3.11/re/__init__.py:317\u001b[0m, in \u001b[0;36m_subx\u001b[0;34m(pattern, template)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_subx\u001b[39m(pattern, template):\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# internal: Pattern.sub/subn implementation helper\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m     template \u001b[38;5;241m=\u001b[39m _compile_repl(template, pattern)\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m template[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(template[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;66;03m# literal replacement\u001b[39;00m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m template[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from textstat.textstat import textstatistics\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "# Ensure nltk resources are downloaded (needed for tokenization)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define feature extraction functions\n",
    "def lexical_diversity(text):\n",
    "    \"\"\"Compute lexical diversity as the ratio of unique tokens to total tokens.\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    return len(set(tokens)) / len(tokens) if tokens else 0\n",
    "\n",
    "def average_sentence_length(text):\n",
    "    \"\"\"Compute the average sentence length.\"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    tokens = word_tokenize(text)\n",
    "    return len(tokens) / len(sentences) if sentences else 0\n",
    "\n",
    "def compute_readability_score(text):\n",
    "    \"\"\"Compute a readability score (e.g., Flesch Reading Ease).\"\"\"\n",
    "    return textstatistics().flesch_reading_ease(text)\n",
    "\n",
    "def compute_text_length_metrics(text):\n",
    "    \"\"\"Compute various text length metrics.\"\"\"\n",
    "    chars = len(text)\n",
    "    words = len(word_tokenize(text))\n",
    "    sentences = len(sent_tokenize(text))\n",
    "    return chars, words, sentences\n",
    "\n",
    "def compute_prompt_features(prompt):\n",
    "    \"\"\"Compute features based on prompts, such as prompt length.\"\"\"\n",
    "    prompt_length = len(prompt)\n",
    "    return prompt_length\n",
    "\n",
    "def extract_nlp_embeddings(text, model):\n",
    "    \"\"\"Extract word embeddings for the given text and average them, compatible with Gensim 4.0.0 and later.\"\"\"\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Check if each token is in the model's vocabulary using .key_to_index\n",
    "    tokens_in_model = [word for word in tokens if word in model.key_to_index]\n",
    "    \n",
    "    # If no tokens are found in the model's vocabulary, return a zero vector\n",
    "    if not tokens_in_model:\n",
    "        return np.zeros(model.vector_size)\n",
    "    \n",
    "    # Compute the average embedding for the tokens found in the model's vocabulary\n",
    "    embeddings = np.mean([model[word] for word in tokens_in_model], axis=0)\n",
    "    return embeddings\n",
    "\n",
    "def add_features_to_df(df, model):\n",
    "    \"\"\"Add computed features to the DataFrame.\"\"\"\n",
    "    df['lexical_diversity'] = df['text'].apply(lexical_diversity)\n",
    "    df['avg_sentence_length'] = df['text'].apply(average_sentence_length)\n",
    "    df['readability_score'] = df['text'].apply(compute_readability_score)\n",
    "    \n",
    "    # Adding text length metrics\n",
    "    text_length_metrics = df['text'].apply(compute_text_length_metrics)\n",
    "    df['char_count'], df['word_count'], df['sentence_count'] = zip(*text_length_metrics)\n",
    "    \n",
    "    # Adding prompt-based features\n",
    "    df['prompt_length'] = df['Prompt'].apply(compute_prompt_features)\n",
    "    \n",
    "    # Classification feature: 1 for AI-generated (non-human sources) and 0 for human\n",
    "    df['classification'] = df['source'].apply(lambda x: 0 if x == 'Human' else 1)\n",
    "    \n",
    "    # Extract embeddings and perform dimensionality reduction\n",
    "    embeddings = np.array([extract_nlp_embeddings(text, model) for text in df['text']])\n",
    "    pca = PCA(n_components=50)  # Adjust based on your dataset and model\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "    \n",
    "    # Append the reduced embeddings to the DataFrame\n",
    "    for i in range(reduced_embeddings.shape[1]):\n",
    "        df[f'embedding_{i}'] = reduced_embeddings[:, i]\n",
    "    \n",
    "    return df\n",
    "df = df_merged\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "df = add_features_to_df(df, model)\n",
    "\n",
    "with open('mlp_pca.pkl', 'wb') as file:\n",
    "    pickle.dump(pca, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "845a9c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/abishekjoshuat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from textstat.textstat import textstatistics\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "# Ensure nltk resources are downloaded (needed for tokenization)\n",
    "nltk.download('punkt')\n",
    "\n",
    "def lexical_diversity(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return len(set(tokens)) / len(tokens) if tokens else 0\n",
    "\n",
    "def average_sentence_length(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    tokens = word_tokenize(text)\n",
    "    return len(tokens) / len(sentences) if sentences else 0\n",
    "\n",
    "def compute_readability_score(text):\n",
    "    return textstatistics().flesch_reading_ease(text)\n",
    "\n",
    "def compute_text_length_metrics(text):\n",
    "    chars = len(text)\n",
    "    words = len(word_tokenize(text))\n",
    "    sentences = len(sent_tokenize(text))\n",
    "    return chars, words, sentences\n",
    "\n",
    "def compute_prompt_features(prompt):\n",
    "    prompt_length = len(prompt)\n",
    "    return prompt_length\n",
    "\n",
    "def extract_nlp_embeddings(text, model):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_in_model = [word for word in tokens if word in model.key_to_index]\n",
    "    if not tokens_in_model:\n",
    "        return np.zeros(model.vector_size)\n",
    "    embeddings = np.mean([model.get_vector(word) for word in tokens_in_model], axis=0)\n",
    "    return embeddings\n",
    "\n",
    "def add_features_to_df(df, model, pca):\n",
    "    df['lexical_diversity'] = df['text'].apply(lexical_diversity)\n",
    "    df['avg_sentence_length'] = df['text'].apply(average_sentence_length)\n",
    "    df['readability_score'] = df['text'].apply(compute_readability_score)\n",
    "    \n",
    "    text_length_metrics = df['text'].apply(compute_text_length_metrics)\n",
    "    df['char_count'], df['word_count'], df['sentence_count'] = zip(*text_length_metrics)\n",
    "    \n",
    "    df['prompt_length'] = df['Prompt'].apply(compute_prompt_features)\n",
    "    \n",
    "    df['classification'] = df['source'].apply(lambda x: 0 if x == 'Human' else 1)\n",
    "    \n",
    "    embeddings = np.array([extract_nlp_embeddings(text, model) for text in df['text']])\n",
    "    reduced_embeddings = pca.transform(embeddings)\n",
    "    \n",
    "    for i in range(reduced_embeddings.shape[1]):\n",
    "        df[f'embedding_{i}'] = reduced_embeddings[:, i]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load the Word2Vec model\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# Assuming df is your DataFrame containing the text data\n",
    "# Extract embeddings for PCA fitting\n",
    "embeddings = np.array([extract_nlp_embeddings(text, model) for text in df['text']])\n",
    "\n",
    "# Fit PCA on the embeddings\n",
    "pca = PCA(n_components=50)\n",
    "pca.fit(embeddings)\n",
    "\n",
    "# Save the fitted PCA model\n",
    "with open('mlp_pca.pkl', 'wb') as file:\n",
    "    pickle.dump(pca, file)\n",
    "\n",
    "# Now, transform your dataset\n",
    "df_transformed = add_features_to_df(df, model, pca)\n",
    "\n",
    "# Loading the pre-fitted PCA model\n",
    "with open('mlp_pca.pkl', 'rb') as file:\n",
    "    pca = pickle.load(file)\n",
    "\n",
    "# Transform new data\n",
    "# Assume new_df is the new DataFrame you want to process\n",
    "new_df_transformed = add_features_to_df(df, model, pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e24eb990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bloom-7B    100\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4eefa17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>char_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Federal law supersedes state law, and cannabis...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>967</td>\n",
       "      <td>181</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>25.857143</td>\n",
       "      <td>57.30</td>\n",
       "      <td>967</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035092</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>-0.041666</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.071304</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>0.004744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Miles feels restless after working all day. He...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>5068</td>\n",
       "      <td>924</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.661255</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>53.21</td>\n",
       "      <td>5068</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003091</td>\n",
       "      <td>-0.043269</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.060853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So first of I am danish. That means that I fol...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>1602</td>\n",
       "      <td>316</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.718354</td>\n",
       "      <td>22.571429</td>\n",
       "      <td>61.97</td>\n",
       "      <td>1602</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.012316</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.005499</td>\n",
       "      <td>-0.011693</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this paper we present a novel rule-based ap...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>5469</td>\n",
       "      <td>1015</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.564532</td>\n",
       "      <td>40.600000</td>\n",
       "      <td>27.86</td>\n",
       "      <td>5469</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018165</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>-0.006033</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>-0.019899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Most social progressives, love democracy, and ...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>2379</td>\n",
       "      <td>437</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.752860</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>61.67</td>\n",
       "      <td>2379</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    source  text_length  \\\n",
       "0  Federal law supersedes state law, and cannabis...  Bloom-7B          967   \n",
       "1  Miles feels restless after working all day. He...  Bloom-7B         5068   \n",
       "2  So first of I am danish. That means that I fol...  Bloom-7B         1602   \n",
       "3  In this paper we present a novel rule-based ap...  Bloom-7B         5469   \n",
       "4  Most social progressives, love democracy, and ...  Bloom-7B         2379   \n",
       "\n",
       "   word_count     Prompt  lexical_diversity  avg_sentence_length  \\\n",
       "0         181  Undefined           0.806630            25.857143   \n",
       "1         924  Undefined           0.661255            23.100000   \n",
       "2         316  Undefined           0.718354            22.571429   \n",
       "3        1015  Undefined           0.564532            40.600000   \n",
       "4         437  Undefined           0.752860            23.000000   \n",
       "\n",
       "   readability_score  char_count  sentence_count  ...  embedding_40  \\\n",
       "0              57.30         967               7  ...     -0.035092   \n",
       "1              53.21        5068              40  ...     -0.003091   \n",
       "2              61.97        1602              14  ...      0.011013   \n",
       "3              27.86        5469              25  ...     -0.018165   \n",
       "4              61.67        2379              19  ...      0.004131   \n",
       "\n",
       "   embedding_41  embedding_42  embedding_43  embedding_44  embedding_45  \\\n",
       "0     -0.001925     -0.041666     -0.005266      0.034543      0.002532   \n",
       "1     -0.043269      0.003721     -0.005574      0.030584     -0.006616   \n",
       "2     -0.008409      0.008066     -0.012316      0.007549     -0.000401   \n",
       "3      0.012030     -0.020475     -0.006033      0.002823     -0.000594   \n",
       "4      0.014534      0.007382     -0.016189      0.007070      0.001430   \n",
       "\n",
       "   embedding_46  embedding_47  embedding_48  embedding_49  \n",
       "0     -0.071304      0.014727     -0.012865      0.004744  \n",
       "1      0.030465      0.000941      0.020913      0.060853  \n",
       "2     -0.001133     -0.005499     -0.011693      0.000179  \n",
       "3      0.000835      0.001109      0.009936     -0.019899  \n",
       "4     -0.017871      0.004868      0.010563      0.008097  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed3c0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197288ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Federal law supersedes state law, and cannabis...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0</td>\n",
       "      <td>967</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Miles feels restless after working all day. He...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0</td>\n",
       "      <td>5068</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So first of I am danish. That means that I fol...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0</td>\n",
       "      <td>1602</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this paper we present a novel rule-based ap...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0</td>\n",
       "      <td>5469</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Most social progressives, love democracy, and ...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0</td>\n",
       "      <td>2379</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788917</th>\n",
       "      <td>\\nIn the vast expanse of time, where the echoe...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>1293</td>\n",
       "      <td>5523</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788918</th>\n",
       "      <td>\\nThe phenomenon of brain drain, particularly ...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>1154</td>\n",
       "      <td>4540</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788919</th>\n",
       "      <td>\\nThe Influence of Climate Change on Marine Ec...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>2783</td>\n",
       "      <td>3889</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788920</th>\n",
       "      <td>\\nTitle: The Case for Limiting Car Usage: Navi...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>41</td>\n",
       "      <td>3560</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788921</th>\n",
       "      <td>\\nIn the vast expanse of a globalized society,...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>4318</td>\n",
       "      <td>4563</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>788922 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text    source  \\\n",
       "0       Federal law supersedes state law, and cannabis...  Bloom-7B   \n",
       "1       Miles feels restless after working all day. He...  Bloom-7B   \n",
       "2       So first of I am danish. That means that I fol...  Bloom-7B   \n",
       "3       In this paper we present a novel rule-based ap...  Bloom-7B   \n",
       "4       Most social progressives, love democracy, and ...  Bloom-7B   \n",
       "...                                                   ...       ...   \n",
       "788917  \\nIn the vast expanse of time, where the echoe...    YI-34B   \n",
       "788918  \\nThe phenomenon of brain drain, particularly ...    YI-34B   \n",
       "788919  \\nThe Influence of Climate Change on Marine Ec...    YI-34B   \n",
       "788920  \\nTitle: The Case for Limiting Car Usage: Navi...    YI-34B   \n",
       "788921  \\nIn the vast expanse of a globalized society,...    YI-34B   \n",
       "\n",
       "        prompt_id  text_length  word_count  \n",
       "0               0          967         157  \n",
       "1               0         5068         778  \n",
       "2               0         1602         267  \n",
       "3               0         5469         848  \n",
       "4               0         2379         380  \n",
       "...           ...          ...         ...  \n",
       "788917       1293         5523         870  \n",
       "788918       1154         4540         677  \n",
       "788919       2783         3889         598  \n",
       "788920         41         3560         533  \n",
       "788921       4318         4563         693  \n",
       "\n",
       "[788922 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "frame = pd.read_csv('data.csv')\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c48e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_df = pd.read_csv('prompts.csv')\n",
    "data_df = pd.read_csv('data.csv')\n",
    "# Merging the DataFrames on 'prompt_id'\n",
    "df_merged = pd.merge(data_df, prompts_df, left_on='prompt_id', right_on='Prompt ID', how='left')\n",
    "\n",
    "# Optionally, if you don't need the 'Prompt ID' column anymore, you can drop it\n",
    "df_merged.drop('prompt_id', axis=1, inplace=True)\n",
    "df_merged.drop('Prompt ID', axis=1, inplace=True)\n",
    "#df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffbed494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(788922, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_merged\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "deca0ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Federal law supersedes state law, and cannabis...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>967</td>\n",
       "      <td>157</td>\n",
       "      <td>Undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Miles feels restless after working all day. He...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>5068</td>\n",
       "      <td>778</td>\n",
       "      <td>Undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So first of I am danish. That means that I fol...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>1602</td>\n",
       "      <td>267</td>\n",
       "      <td>Undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this paper we present a novel rule-based ap...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>5469</td>\n",
       "      <td>848</td>\n",
       "      <td>Undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Most social progressives, love democracy, and ...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>2379</td>\n",
       "      <td>380</td>\n",
       "      <td>Undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788917</th>\n",
       "      <td>\\nIn the vast expanse of time, where the echoe...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>5523</td>\n",
       "      <td>870</td>\n",
       "      <td>The Ethics of De-extinction and Bringing Back ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788918</th>\n",
       "      <td>\\nThe phenomenon of brain drain, particularly ...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>4540</td>\n",
       "      <td>677</td>\n",
       "      <td>The Economic and Social Consequences of Brain ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788919</th>\n",
       "      <td>\\nThe Influence of Climate Change on Marine Ec...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>3889</td>\n",
       "      <td>598</td>\n",
       "      <td>The influence of climate change on marine ecos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788920</th>\n",
       "      <td>\\nTitle: The Case for Limiting Car Usage: Navi...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>3560</td>\n",
       "      <td>533</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788921</th>\n",
       "      <td>\\nIn the vast expanse of a globalized society,...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>4563</td>\n",
       "      <td>693</td>\n",
       "      <td>The Importance of Intercultural Communication ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>788922 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text    source  \\\n",
       "0       Federal law supersedes state law, and cannabis...  Bloom-7B   \n",
       "1       Miles feels restless after working all day. He...  Bloom-7B   \n",
       "2       So first of I am danish. That means that I fol...  Bloom-7B   \n",
       "3       In this paper we present a novel rule-based ap...  Bloom-7B   \n",
       "4       Most social progressives, love democracy, and ...  Bloom-7B   \n",
       "...                                                   ...       ...   \n",
       "788917  \\nIn the vast expanse of time, where the echoe...    YI-34B   \n",
       "788918  \\nThe phenomenon of brain drain, particularly ...    YI-34B   \n",
       "788919  \\nThe Influence of Climate Change on Marine Ec...    YI-34B   \n",
       "788920  \\nTitle: The Case for Limiting Car Usage: Navi...    YI-34B   \n",
       "788921  \\nIn the vast expanse of a globalized society,...    YI-34B   \n",
       "\n",
       "        text_length  word_count  \\\n",
       "0               967         157   \n",
       "1              5068         778   \n",
       "2              1602         267   \n",
       "3              5469         848   \n",
       "4              2379         380   \n",
       "...             ...         ...   \n",
       "788917         5523         870   \n",
       "788918         4540         677   \n",
       "788919         3889         598   \n",
       "788920         3560         533   \n",
       "788921         4563         693   \n",
       "\n",
       "                                                   Prompt  \n",
       "0                                               Undefined  \n",
       "1                                               Undefined  \n",
       "2                                               Undefined  \n",
       "3                                               Undefined  \n",
       "4                                               Undefined  \n",
       "...                                                   ...  \n",
       "788917  The Ethics of De-extinction and Bringing Back ...  \n",
       "788918  The Economic and Social Consequences of Brain ...  \n",
       "788919  The influence of climate change on marine ecos...  \n",
       "788920  Write an explanatory essay to inform fellow ci...  \n",
       "788921  The Importance of Intercultural Communication ...  \n",
       "\n",
       "[788922 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e78df96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>char_count</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Federal law supersedes state law, and cannabis...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>967</td>\n",
       "      <td>181</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>25.857143</td>\n",
       "      <td>57.30</td>\n",
       "      <td>967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035092</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>-0.041666</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.071304</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>0.004744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Miles feels restless after working all day. He...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>5068</td>\n",
       "      <td>924</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.661255</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>53.21</td>\n",
       "      <td>5068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003091</td>\n",
       "      <td>-0.043269</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.060853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>So first of I am danish. That means that I fol...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>1602</td>\n",
       "      <td>316</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.718354</td>\n",
       "      <td>22.571429</td>\n",
       "      <td>61.97</td>\n",
       "      <td>1602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.012316</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.005499</td>\n",
       "      <td>-0.011693</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>In this paper we present a novel rule-based ap...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>5469</td>\n",
       "      <td>1015</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.564532</td>\n",
       "      <td>40.600000</td>\n",
       "      <td>27.86</td>\n",
       "      <td>5469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018165</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>-0.006033</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>-0.019899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Most social progressives, love democracy, and ...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>2379</td>\n",
       "      <td>437</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.752860</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>61.67</td>\n",
       "      <td>2379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text    source  \\\n",
       "0           0  Federal law supersedes state law, and cannabis...  Bloom-7B   \n",
       "1           1  Miles feels restless after working all day. He...  Bloom-7B   \n",
       "2           2  So first of I am danish. That means that I fol...  Bloom-7B   \n",
       "3           3  In this paper we present a novel rule-based ap...  Bloom-7B   \n",
       "4           4  Most social progressives, love democracy, and ...  Bloom-7B   \n",
       "\n",
       "   text_length  word_count     Prompt  lexical_diversity  avg_sentence_length  \\\n",
       "0          967         181  Undefined           0.806630            25.857143   \n",
       "1         5068         924  Undefined           0.661255            23.100000   \n",
       "2         1602         316  Undefined           0.718354            22.571429   \n",
       "3         5469        1015  Undefined           0.564532            40.600000   \n",
       "4         2379         437  Undefined           0.752860            23.000000   \n",
       "\n",
       "   readability_score  char_count  ...  embedding_40  embedding_41  \\\n",
       "0              57.30         967  ...     -0.035092     -0.001925   \n",
       "1              53.21        5068  ...     -0.003091     -0.043269   \n",
       "2              61.97        1602  ...      0.011013     -0.008409   \n",
       "3              27.86        5469  ...     -0.018165      0.012030   \n",
       "4              61.67        2379  ...      0.004131      0.014534   \n",
       "\n",
       "   embedding_42  embedding_43  embedding_44  embedding_45  embedding_46  \\\n",
       "0     -0.041666     -0.005266      0.034543      0.002532     -0.071304   \n",
       "1      0.003721     -0.005574      0.030584     -0.006616      0.030465   \n",
       "2      0.008066     -0.012316      0.007549     -0.000401     -0.001133   \n",
       "3     -0.020475     -0.006033      0.002823     -0.000594      0.000835   \n",
       "4      0.007382     -0.016189      0.007070      0.001430     -0.017871   \n",
       "\n",
       "   embedding_47  embedding_48  embedding_49  \n",
       "0      0.014727     -0.012865      0.004744  \n",
       "1      0.000941      0.020913      0.060853  \n",
       "2     -0.005499     -0.011693      0.000179  \n",
       "3      0.001109      0.009936     -0.019899  \n",
       "4      0.004868      0.010563      0.008097  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "final_df = pd.read_csv('corpus.csv')\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ddca9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>classification</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>readability_score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-2584.12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1254.80</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1213.51</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1005.10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-973.64</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118.78</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118.89</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118.99</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119.09</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206.84</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "classification     0  1\n",
       "readability_score      \n",
       "-2584.12           0  1\n",
       "-1254.80           1  0\n",
       "-1213.51           0  1\n",
       "-1005.10           1  0\n",
       "-973.64            0  1\n",
       "...               .. ..\n",
       " 118.78            0  1\n",
       " 118.89            0  4\n",
       " 118.99            0  1\n",
       " 119.09            0  2\n",
       " 206.84            0  1\n",
       "\n",
       "[6750 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(final_df.readability_score,final_df.classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cba99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "final_df = final_df.sample(frac=1).reset_index(drop=True)\n",
    "X = final_df.drop(['text','source', 'Prompt', 'classification'], axis=1)\n",
    "y = final_df['classification']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# model = RandomForestClassifier(n_estimators=100)\n",
    "# model.fit(X_train, y_train)\n",
    "# predictions = model.predict(X_test)\n",
    "# print(f\"Accuracy: {accuracy_score(y_test, predictions)}\")\n",
    "# print(f\"Precision: {precision_score(y_test, predictions)}\")\n",
    "# print(f\"Recall: {recall_score(y_test, predictions)}\")\n",
    "# print(f\"F1 Score: {f1_score(y_test, predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c65ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open('first_trained_rand_forest_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "348d7607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999873245238774\n",
      "Precision: 0.9999773324870795\n",
      "Recall: 1.0\n",
      "F1 Score: 0.9999886661150843\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open('first_trained_rand_forest_model.pkl', 'rb'))\n",
    "result = loaded_model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, result)}\")\n",
    "print(f\"Precision: {precision_score(y_test, result)}\")\n",
    "print(f\"Recall: {recall_score(y_test, result)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bd61104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (across 5 folds): 1.0000\n",
      "Standard Deviation in Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "cv_model = RandomForestClassifier(n_estimators = 100)\n",
    "num_folds = 5\n",
    "scoring_metric = 'accuracy'  \n",
    "scores = cross_val_score(cv_model, X, y, cv=num_folds, scoring=scoring_metric)\n",
    "mean_score = np.mean(scores)\n",
    "std_dev_score = np.std(scores)\n",
    "\n",
    "print(f\"Mean {scoring_metric.capitalize()} (across {num_folds} folds): {mean_score:.4f}\")\n",
    "print(f\"Standard Deviation in {scoring_metric.capitalize()}: {std_dev_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37b6668a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5983\n",
      "Precision: 0.5889\n",
      "Recall: 0.9340\n",
      "F1 Score: 0.7224\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize the SGD Classifier\n",
    "# You can adjust the loss function, penalty, and other hyperparameters as needed\n",
    "sgd_model = SGDClassifier(loss='hinge', penalty='l2', random_state=42, max_iter=1000, tol=1e-3)\n",
    "\n",
    "# Train the model\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = sgd_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2f82760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy (across 5 folds): 0.5831\n",
      "Standard Deviation in Accuracy: 0.0553\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "cv_sdg_model = SGDClassifier(loss='hinge', penalty='l2', random_state=42, max_iter=5000,tol=1e-3)\n",
    "num_folds = 5\n",
    "scoring_metric = 'accuracy'  \n",
    "scores = cross_val_score(cv_sdg_model, X, y, cv=num_folds, scoring=scoring_metric)\n",
    "mean_score = np.mean(scores)\n",
    "std_dev_score = np.std(scores)\n",
    "\n",
    "print(f\"Mean {scoring_metric.capitalize()} (across {num_folds} folds): {mean_score:.4f}\")\n",
    "print(f\"Standard Deviation in {scoring_metric.capitalize()}: {std_dev_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "468bcc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(sgd_model, open('first_trained_sgd_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caee816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'loss': ['hinge', 'log', 'modified_huber'],  # Different loss functions\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],  # Different penalties for regularization\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],  # Regularization strength\n",
    "    'max_iter': [1000],  # Number of epochs; adjust as necessary\n",
    "    'tol': [1e-3],  # Tolerance for stopping criteria\n",
    "    'random_state': [42]  # Ensure reproducibility\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1462bbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39msgd_clf, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, \n\u001b[1;32m      2\u001b[0m                            n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/Sample_ML_Project/env/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/Developer/Sample_ML_Project/env/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=sgd_clf, param_grid=param_grid, \n",
    "                           n_jobs=-1, cv=5, scoring='accuracy', verbose=2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebaf70d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1', 'random_state': 42, 'tol': 0.001}\n",
      "Best cross-validation accuracy: 0.6938984618777874\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", grid_search.best_score_)\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95a3a77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_clf = LogisticRegression()\n",
    "log_clf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11c0286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = log_clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fcb62d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "                         ~~^~~~~~~~~~\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.63166318 0.63165367        nan 0.63166793 0.63166318 0.63166793\n",
      "        nan 0.63166318 0.63166793 0.63166318        nan 0.63165842\n",
      " 0.63166159 0.63166159        nan 0.63166476 0.63166159 0.63166159\n",
      "        nan 0.63166793 0.63166159 0.63165684        nan 0.63166318]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;saga&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;saga&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
       "                         'solver': ['saga']},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "log_param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver': ['saga'] \n",
    "}\n",
    "log_grid_search = GridSearchCV(estimator=log_clf, param_grid=log_param_grid, n_jobs=-1, cv=5, scoring='accuracy', verbose=2)\n",
    "log_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bce797a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best cross-validation score: 0.6316679289887718\n",
      "Test set score: 0.6302310105523339\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found:\", log_grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", log_grid_search.best_score_)\n",
    "best_model = log_grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Test set score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c119b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.62      0.50     47567\n",
      "           1       0.79      0.63      0.71    110218\n",
      "\n",
      "    accuracy                           0.63    157785\n",
      "   macro avg       0.61      0.63      0.60    157785\n",
      "weighted avg       0.68      0.63      0.64    157785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a12ed9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('first_trained_sgd_model.pkl', 'rb') as file:\n",
    "    sgd_clf = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "884a2a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5971543556104826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.67      0.27     17730\n",
      "           1       0.93      0.59      0.72    140055\n",
      "\n",
      "    accuracy                           0.60    157785\n",
      "   macro avg       0.55      0.63      0.50    157785\n",
      "weighted avg       0.85      0.60      0.67    157785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = sgd_clf.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "svm = SVC(kernel='linear', C=1, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "support_vectors = svm.support_vectors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f9806d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>char_count</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Federal law supersedes state law, and cannabis...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>967</td>\n",
       "      <td>181</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>25.857143</td>\n",
       "      <td>57.30</td>\n",
       "      <td>967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035092</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>-0.041666</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.071304</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>0.004744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Miles feels restless after working all day. He...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>5068</td>\n",
       "      <td>924</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.661255</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>53.21</td>\n",
       "      <td>5068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003091</td>\n",
       "      <td>-0.043269</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.060853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>So first of I am danish. That means that I fol...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>1602</td>\n",
       "      <td>316</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.718354</td>\n",
       "      <td>22.571429</td>\n",
       "      <td>61.97</td>\n",
       "      <td>1602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.012316</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.005499</td>\n",
       "      <td>-0.011693</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>In this paper we present a novel rule-based ap...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>5469</td>\n",
       "      <td>1015</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.564532</td>\n",
       "      <td>40.600000</td>\n",
       "      <td>27.86</td>\n",
       "      <td>5469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018165</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>-0.006033</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>-0.019899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Most social progressives, love democracy, and ...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>2379</td>\n",
       "      <td>437</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.752860</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>61.67</td>\n",
       "      <td>2379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text    source  \\\n",
       "0           0  Federal law supersedes state law, and cannabis...  Bloom-7B   \n",
       "1           1  Miles feels restless after working all day. He...  Bloom-7B   \n",
       "2           2  So first of I am danish. That means that I fol...  Bloom-7B   \n",
       "3           3  In this paper we present a novel rule-based ap...  Bloom-7B   \n",
       "4           4  Most social progressives, love democracy, and ...  Bloom-7B   \n",
       "\n",
       "   text_length  word_count     Prompt  lexical_diversity  avg_sentence_length  \\\n",
       "0          967         181  Undefined           0.806630            25.857143   \n",
       "1         5068         924  Undefined           0.661255            23.100000   \n",
       "2         1602         316  Undefined           0.718354            22.571429   \n",
       "3         5469        1015  Undefined           0.564532            40.600000   \n",
       "4         2379         437  Undefined           0.752860            23.000000   \n",
       "\n",
       "   readability_score  char_count  ...  embedding_40  embedding_41  \\\n",
       "0              57.30         967  ...     -0.035092     -0.001925   \n",
       "1              53.21        5068  ...     -0.003091     -0.043269   \n",
       "2              61.97        1602  ...      0.011013     -0.008409   \n",
       "3              27.86        5469  ...     -0.018165      0.012030   \n",
       "4              61.67        2379  ...      0.004131      0.014534   \n",
       "\n",
       "   embedding_42  embedding_43  embedding_44  embedding_45  embedding_46  \\\n",
       "0     -0.041666     -0.005266      0.034543      0.002532     -0.071304   \n",
       "1      0.003721     -0.005574      0.030584     -0.006616      0.030465   \n",
       "2      0.008066     -0.012316      0.007549     -0.000401     -0.001133   \n",
       "3     -0.020475     -0.006033      0.002823     -0.000594      0.000835   \n",
       "4      0.007382     -0.016189      0.007070      0.001430     -0.017871   \n",
       "\n",
       "   embedding_47  embedding_48  embedding_49  \n",
       "0      0.014727     -0.012865      0.004744  \n",
       "1      0.000941      0.020913      0.060853  \n",
       "2     -0.005499     -0.011693      0.000179  \n",
       "3      0.001109      0.009936     -0.019899  \n",
       "4      0.004868      0.010563      0.008097  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('corpus.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ccc7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['text_length','word_count'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc370ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df.sample(frac=1).reset_index(drop=True)\n",
    "X = df.drop(['text','source','Prompt','prompt_length','avg_sentence_length','char_count','sentence_count','classification'],axis=1)\n",
    "y = df['classification']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "002461e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    441230\n",
       "0    347692\n",
       "Name: classification, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.classification.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a896b349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_resampled, y_resampled = adasyn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d06cc4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    353014\n",
       "1    353014\n",
       "Name: classification, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled_decoded = label_encoder.inverse_transform(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c291601",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg_clf = LogisticRegression()\n",
    "log_reg_clf.fit(X_resampled,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d518125",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55e72ecf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.723883765883956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.70     74536\n",
      "           1       0.72      0.77      0.75     83249\n",
      "\n",
      "    accuracy                           0.72    157785\n",
      "   macro avg       0.72      0.72      0.72    157785\n",
      "weighted avg       0.72      0.72      0.72    157785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "log_reg_y_pred = log_reg_clf.predict(X_test)\n",
    "print('Accuracy:',accuracy_score(log_reg_y_pred,y_test))\n",
    "print(classification_report(log_reg_y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd256d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier()\n",
    "sgd_clf.fit(X_resampled,y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "822673e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6939189403301962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.73      0.58     45460\n",
      "           1       0.86      0.68      0.76    112325\n",
      "\n",
      "    accuracy                           0.69    157785\n",
      "   macro avg       0.67      0.71      0.67    157785\n",
      "weighted avg       0.75      0.69      0.71    157785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "sgd_clf_y_pred = sgd_clf.predict(X_test)\n",
    "print('Accuracy:',accuracy_score(sgd_clf_y_pred,y_test))\n",
    "print(classification_report(sgd_clf_y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3a6f6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a84003d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8633076654941851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84     64701\n",
      "           1       0.91      0.86      0.88     93084\n",
      "\n",
      "    accuracy                           0.86    157785\n",
      "   macro avg       0.86      0.86      0.86    157785\n",
      "weighted avg       0.87      0.86      0.86    157785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_y_pred = mlp.predict(X_test)\n",
    "print('Accuracy:',accuracy_score(mlp_y_pred,y_test))\n",
    "print(classification_report(mlp_y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b2201b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "                         ~~^~~~~~~~~~\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.62852028 0.6418781         nan 0.64229735 0.64093763 0.64222795\n",
      "        nan 0.64229452 0.64214863 0.64227327        nan 0.64229168\n",
      " 0.64226336 0.64232426        nan 0.64231293 0.64230726 0.64229452\n",
      "        nan 0.64229593 0.64230868 0.64228035        nan 0.6423016 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abishekjoshuat/Developer/Sample_ML_Project/env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;saga&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;saga&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
       "                         'solver': ['saga']},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=0.001, penalty=l2, solver=saga; total time= 1.8min\n",
      "[CV] END ...................C=0.001, penalty=l2, solver=saga; total time= 1.7min\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time= 1.8min\n",
      "[CV] END ..................C=0.01, penalty=none, solver=saga; total time= 1.5min\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time= 1.8min\n",
      "[CV] END .............C=0.1, penalty=elasticnet, solver=saga; total time=   0.7s\n",
      "[CV] END .............C=0.1, penalty=elasticnet, solver=saga; total time=   0.4s\n",
      "[CV] END .............C=0.1, penalty=elasticnet, solver=saga; total time=   0.5s\n",
      "[CV] END .............C=0.1, penalty=elasticnet, solver=saga; total time=   0.4s\n",
      "[CV] END .............C=0.1, penalty=elasticnet, solver=saga; total time=   0.4s\n",
      "[CV] END ...................C=0.1, penalty=none, solver=saga; total time= 1.6min\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time= 1.7min\n",
      "[CV] END .....................C=1, penalty=none, solver=saga; total time= 1.5min\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time= 1.6min\n",
      "[CV] END ....................C=10, penalty=none, solver=saga; total time= 1.5min\n",
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 1.4min\n",
      "[CV] END ...................C=0.001, penalty=l2, solver=saga; total time= 1.8min\n",
      "[CV] END ...........C=0.001, penalty=elasticnet, solver=saga; total time=   0.8s\n",
      "[CV] END ...........C=0.001, penalty=elasticnet, solver=saga; total time=   0.9s\n",
      "[CV] END ...........C=0.001, penalty=elasticnet, solver=saga; total time=   0.7s\n",
      "[CV] END ...........C=0.001, penalty=elasticnet, solver=saga; total time=   0.5s\n",
      "[CV] END ...........C=0.001, penalty=elasticnet, solver=saga; total time=   0.5s\n",
      "[CV] END .................C=0.001, penalty=none, solver=saga; total time= 1.7min\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time= 1.9min\n",
      "[CV] END ..................C=0.01, penalty=none, solver=saga; total time= 1.5min\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time= 1.8min\n",
      "[CV] END ...................C=0.1, penalty=none, solver=saga; total time= 1.6min\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time= 1.5min\n",
      "[CV] END .....................C=1, penalty=none, solver=saga; total time= 1.5min\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 1.8min\n",
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time= 1.7min\n",
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 1.4min\n",
      "[CV] END ...................C=0.001, penalty=l2, solver=saga; total time= 1.8min\n",
      "[CV] END ...................C=0.001, penalty=l2, solver=saga; total time= 1.7min\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time= 1.9min\n",
      "[CV] END ..................C=0.01, penalty=none, solver=saga; total time= 1.5min\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time= 1.8min\n",
      "[CV] END ...................C=0.1, penalty=none, solver=saga; total time= 1.6min\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time= 1.7min\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 1.7min\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time= 1.6min\n",
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time= 1.7min\n",
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 1.4min\n",
      "[CV] END ...................C=0.001, penalty=l1, solver=saga; total time= 2.0min\n",
      "[CV] END .................C=0.001, penalty=none, solver=saga; total time= 1.7min\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time= 1.5min\n",
      "[CV] END ............C=0.01, penalty=elasticnet, solver=saga; total time=   0.5s\n",
      "[CV] END ............C=0.01, penalty=elasticnet, solver=saga; total time=   0.5s\n",
      "[CV] END ............C=0.01, penalty=elasticnet, solver=saga; total time=   0.5s\n",
      "[CV] END ..................C=0.01, penalty=none, solver=saga; total time= 1.6min\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time= 2.0min\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time= 1.8min\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time= 1.5min\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 1.7min\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time= 1.6min\n",
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time= 1.7min\n",
      "[CV] END .............C=100, penalty=elasticnet, solver=saga; total time=   0.5s\n",
      "[CV] END .............C=100, penalty=elasticnet, solver=saga; total time=   0.4s\n",
      "[CV] END .............C=100, penalty=elasticnet, solver=saga; total time=   0.5s\n",
      "[CV] END .............C=100, penalty=elasticnet, solver=saga; total time=   0.4s\n",
      "[CV] END .............C=100, penalty=elasticnet, solver=saga; total time=   0.4s\n",
      "[CV] END ...................C=100, penalty=none, solver=saga; total time= 1.3min\n",
      "[CV] END ...................C=0.001, penalty=l1, solver=saga; total time= 1.9min\n",
      "[CV] END .................C=0.001, penalty=none, solver=saga; total time= 1.7min\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time= 1.8min\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time= 1.8min\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time= 1.7min\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time= 1.8min\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time= 1.4min\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 1.7min\n",
      "[CV] END ..............C=10, penalty=elasticnet, solver=saga; total time=   0.6s\n",
      "[CV] END ..............C=10, penalty=elasticnet, solver=saga; total time=   0.5s\n",
      "[CV] END ..............C=10, penalty=elasticnet, solver=saga; total time=   0.4s\n",
      "[CV] END ..............C=10, penalty=elasticnet, solver=saga; total time=   0.5s\n",
      "[CV] END ..............C=10, penalty=elasticnet, solver=saga; total time=   0.5s\n",
      "[CV] END ....................C=10, penalty=none, solver=saga; total time= 1.5min\n",
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time= 1.7min\n",
      "[CV] END ...................C=100, penalty=none, solver=saga; total time= 1.2min\n",
      "[CV] END ...................C=0.001, penalty=l1, solver=saga; total time= 2.0min\n",
      "[CV] END ....................C=0.01, penalty=l1, solver=saga; total time= 2.0min\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time= 1.6min\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time= 1.8min\n",
      "[CV] END .....................C=0.1, penalty=l2, solver=saga; total time= 1.7min\n",
      "[CV] END .......................C=1, penalty=l1, solver=saga; total time= 1.8min\n",
      "[CV] END ...............C=1, penalty=elasticnet, solver=saga; total time=   0.5s\n",
      "[CV] END ...............C=1, penalty=elasticnet, solver=saga; total time=   0.5s\n",
      "[CV] END ...............C=1, penalty=elasticnet, solver=saga; total time=   0.4s\n",
      "[CV] END ...............C=1, penalty=elasticnet, solver=saga; total time=   0.4s\n",
      "[CV] END ...............C=1, penalty=elasticnet, solver=saga; total time=   0.4s\n",
      "[CV] END .....................C=1, penalty=none, solver=saga; total time= 1.4min\n",
      "[CV] END ......................C=10, penalty=l1, solver=saga; total time= 1.7min\n",
      "[CV] END ....................C=10, penalty=none, solver=saga; total time= 1.5min\n",
      "[CV] END .....................C=100, penalty=l1, solver=saga; total time= 1.7min\n",
      "[CV] END ...................C=100, penalty=none, solver=saga; total time= 1.2min\n",
      "[CV] END ...................C=0.001, penalty=l1, solver=saga; total time= 2.0min\n",
      "[CV] END .................C=0.001, penalty=none, solver=saga; total time= 1.7min\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time= 1.5min\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time= 1.6min\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time= 2.0min\n",
      "[CV] END ...................C=0.1, penalty=none, solver=saga; total time= 1.6min\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time= 1.5min\n",
      "[CV] END .....................C=1, penalty=none, solver=saga; total time= 1.5min\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time= 1.6min\n",
      "[CV] END ....................C=10, penalty=none, solver=saga; total time= 1.5min\n",
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 1.4min\n",
      "[CV] END ...................C=100, penalty=none, solver=saga; total time= 1.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...................C=0.001, penalty=l1, solver=saga; total time= 2.0min\n",
      "[CV] END .................C=0.001, penalty=none, solver=saga; total time= 1.7min\n",
      "[CV] END ....................C=0.01, penalty=l2, solver=saga; total time= 1.5min\n",
      "[CV] END ............C=0.01, penalty=elasticnet, solver=saga; total time=   0.5s\n",
      "[CV] END ............C=0.01, penalty=elasticnet, solver=saga; total time=   0.5s\n",
      "[CV] END ..................C=0.01, penalty=none, solver=saga; total time= 1.6min\n",
      "[CV] END .....................C=0.1, penalty=l1, solver=saga; total time= 2.0min\n",
      "[CV] END ...................C=0.1, penalty=none, solver=saga; total time= 1.6min\n",
      "[CV] END .......................C=1, penalty=l2, solver=saga; total time= 1.5min\n",
      "[CV] END .....................C=1, penalty=none, solver=saga; total time= 1.5min\n",
      "[CV] END ......................C=10, penalty=l2, solver=saga; total time= 1.6min\n",
      "[CV] END ....................C=10, penalty=none, solver=saga; total time= 1.5min\n",
      "[CV] END .....................C=100, penalty=l2, solver=saga; total time= 1.5min\n",
      "[CV] END ...................C=100, penalty=none, solver=saga; total time=  59.3s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "log_param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver': ['saga'] \n",
    "}\n",
    "log_grid_search = GridSearchCV(estimator=log_reg_clf, param_grid=log_param_grid, n_jobs=-1, cv=5, scoring='accuracy', verbose=2)\n",
    "log_grid_search.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6eea399d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'C': 1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Accuracy: 0.6671736857115695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.61      0.64     77312\n",
      "           1       0.66      0.72      0.69     80473\n",
      "\n",
      "    accuracy                           0.67    157785\n",
      "   macro avg       0.67      0.67      0.67    157785\n",
      "weighted avg       0.67      0.67      0.67    157785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found:\", log_grid_search.best_params_)\n",
    "#print(\"Best cross-validation score:\", log_grid_search.best_score_)\n",
    "log_reg_best_model = log_grid_search.best_estimator_\n",
    "log_reg_best_y_pred = log_reg_best_model.predict(X_test)\n",
    "print('Accuracy:',accuracy_score(log_reg_best_y_pred,y_test))\n",
    "print(classification_report(log_reg_best_y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d27707ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(mlp, open('mlp.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ddf73d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300033</td>\n",
       "      <td>18.990000</td>\n",
       "      <td>-0.248195</td>\n",
       "      <td>-0.179635</td>\n",
       "      <td>-0.083045</td>\n",
       "      <td>0.010855</td>\n",
       "      <td>0.105388</td>\n",
       "      <td>0.105773</td>\n",
       "      <td>-0.079635</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023005</td>\n",
       "      <td>-0.016056</td>\n",
       "      <td>0.010822</td>\n",
       "      <td>-0.000577</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>-0.007269</td>\n",
       "      <td>0.005182</td>\n",
       "      <td>-0.002655</td>\n",
       "      <td>-0.006325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.451613</td>\n",
       "      <td>80.820000</td>\n",
       "      <td>0.231140</td>\n",
       "      <td>0.214960</td>\n",
       "      <td>-0.056012</td>\n",
       "      <td>-0.057660</td>\n",
       "      <td>0.021940</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>-0.041915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.022504</td>\n",
       "      <td>-0.005386</td>\n",
       "      <td>-0.012064</td>\n",
       "      <td>0.011904</td>\n",
       "      <td>-0.018995</td>\n",
       "      <td>-0.023025</td>\n",
       "      <td>0.009447</td>\n",
       "      <td>0.014939</td>\n",
       "      <td>-0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.617284</td>\n",
       "      <td>50.330000</td>\n",
       "      <td>0.025687</td>\n",
       "      <td>-0.154967</td>\n",
       "      <td>0.035850</td>\n",
       "      <td>-0.040272</td>\n",
       "      <td>0.104272</td>\n",
       "      <td>-0.110137</td>\n",
       "      <td>-0.092216</td>\n",
       "      <td>-0.008114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>0.011762</td>\n",
       "      <td>0.025877</td>\n",
       "      <td>-0.010867</td>\n",
       "      <td>-0.044785</td>\n",
       "      <td>-0.003382</td>\n",
       "      <td>0.075150</td>\n",
       "      <td>-0.005372</td>\n",
       "      <td>0.008051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.372159</td>\n",
       "      <td>37.910000</td>\n",
       "      <td>-0.199305</td>\n",
       "      <td>0.011802</td>\n",
       "      <td>-0.067226</td>\n",
       "      <td>0.116867</td>\n",
       "      <td>0.031592</td>\n",
       "      <td>0.039090</td>\n",
       "      <td>-0.006330</td>\n",
       "      <td>-0.003103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021811</td>\n",
       "      <td>-0.007376</td>\n",
       "      <td>0.005410</td>\n",
       "      <td>-0.005284</td>\n",
       "      <td>-0.004893</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.026057</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>-0.006860</td>\n",
       "      <td>0.013506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.611940</td>\n",
       "      <td>38.250000</td>\n",
       "      <td>-0.145215</td>\n",
       "      <td>0.034901</td>\n",
       "      <td>-0.022185</td>\n",
       "      <td>-0.129232</td>\n",
       "      <td>0.024889</td>\n",
       "      <td>-0.006497</td>\n",
       "      <td>0.037708</td>\n",
       "      <td>0.038051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020041</td>\n",
       "      <td>0.014329</td>\n",
       "      <td>-0.025540</td>\n",
       "      <td>-0.030381</td>\n",
       "      <td>-0.037740</td>\n",
       "      <td>-0.022946</td>\n",
       "      <td>-0.014160</td>\n",
       "      <td>-0.014366</td>\n",
       "      <td>-0.005830</td>\n",
       "      <td>-0.026705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706023</th>\n",
       "      <td>0.499839</td>\n",
       "      <td>54.745171</td>\n",
       "      <td>0.082951</td>\n",
       "      <td>0.058508</td>\n",
       "      <td>-0.049192</td>\n",
       "      <td>0.108803</td>\n",
       "      <td>0.103551</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.042249</td>\n",
       "      <td>0.014440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>-0.000510</td>\n",
       "      <td>-0.019718</td>\n",
       "      <td>0.002946</td>\n",
       "      <td>-0.029177</td>\n",
       "      <td>-0.017638</td>\n",
       "      <td>-0.031907</td>\n",
       "      <td>-0.008844</td>\n",
       "      <td>0.020305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706024</th>\n",
       "      <td>0.541621</td>\n",
       "      <td>59.655854</td>\n",
       "      <td>0.075304</td>\n",
       "      <td>0.152936</td>\n",
       "      <td>-0.028156</td>\n",
       "      <td>0.059426</td>\n",
       "      <td>0.075589</td>\n",
       "      <td>-0.055549</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013487</td>\n",
       "      <td>-0.007866</td>\n",
       "      <td>0.030421</td>\n",
       "      <td>-0.012009</td>\n",
       "      <td>0.014661</td>\n",
       "      <td>-0.028032</td>\n",
       "      <td>-0.019619</td>\n",
       "      <td>-0.002625</td>\n",
       "      <td>-0.018203</td>\n",
       "      <td>0.009254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706025</th>\n",
       "      <td>0.502306</td>\n",
       "      <td>54.355693</td>\n",
       "      <td>0.078595</td>\n",
       "      <td>0.045208</td>\n",
       "      <td>-0.045423</td>\n",
       "      <td>0.101048</td>\n",
       "      <td>0.127583</td>\n",
       "      <td>-0.006447</td>\n",
       "      <td>0.050258</td>\n",
       "      <td>0.026254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019883</td>\n",
       "      <td>0.008003</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>-0.022577</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>-0.029919</td>\n",
       "      <td>-0.027532</td>\n",
       "      <td>-0.032977</td>\n",
       "      <td>-0.013356</td>\n",
       "      <td>0.015409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706026</th>\n",
       "      <td>0.508887</td>\n",
       "      <td>54.631433</td>\n",
       "      <td>0.091584</td>\n",
       "      <td>0.048740</td>\n",
       "      <td>-0.046034</td>\n",
       "      <td>0.109513</td>\n",
       "      <td>0.128275</td>\n",
       "      <td>-0.003456</td>\n",
       "      <td>0.053254</td>\n",
       "      <td>0.027267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022960</td>\n",
       "      <td>0.006409</td>\n",
       "      <td>0.008017</td>\n",
       "      <td>-0.024181</td>\n",
       "      <td>0.006599</td>\n",
       "      <td>-0.030657</td>\n",
       "      <td>-0.026145</td>\n",
       "      <td>-0.034481</td>\n",
       "      <td>-0.012717</td>\n",
       "      <td>0.016915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706027</th>\n",
       "      <td>0.522106</td>\n",
       "      <td>55.252727</td>\n",
       "      <td>0.116184</td>\n",
       "      <td>0.057433</td>\n",
       "      <td>-0.046877</td>\n",
       "      <td>0.124818</td>\n",
       "      <td>0.128629</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.058327</td>\n",
       "      <td>0.028699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028685</td>\n",
       "      <td>0.003089</td>\n",
       "      <td>0.005064</td>\n",
       "      <td>-0.027032</td>\n",
       "      <td>0.007142</td>\n",
       "      <td>-0.032023</td>\n",
       "      <td>-0.023367</td>\n",
       "      <td>-0.036778</td>\n",
       "      <td>-0.011594</td>\n",
       "      <td>0.019661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>706028 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lexical_diversity  readability_score  embedding_0  embedding_1  \\\n",
       "0                0.300033          18.990000    -0.248195    -0.179635   \n",
       "1                0.451613          80.820000     0.231140     0.214960   \n",
       "2                0.617284          50.330000     0.025687    -0.154967   \n",
       "3                0.372159          37.910000    -0.199305     0.011802   \n",
       "4                0.611940          38.250000    -0.145215     0.034901   \n",
       "...                   ...                ...          ...          ...   \n",
       "706023           0.499839          54.745171     0.082951     0.058508   \n",
       "706024           0.541621          59.655854     0.075304     0.152936   \n",
       "706025           0.502306          54.355693     0.078595     0.045208   \n",
       "706026           0.508887          54.631433     0.091584     0.048740   \n",
       "706027           0.522106          55.252727     0.116184     0.057433   \n",
       "\n",
       "        embedding_2  embedding_3  embedding_4  embedding_5  embedding_6  \\\n",
       "0         -0.083045     0.010855     0.105388     0.105773    -0.079635   \n",
       "1         -0.056012    -0.057660     0.021940     0.025757    -0.012500   \n",
       "2          0.035850    -0.040272     0.104272    -0.110137    -0.092216   \n",
       "3         -0.067226     0.116867     0.031592     0.039090    -0.006330   \n",
       "4         -0.022185    -0.129232     0.024889    -0.006497     0.037708   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "706023    -0.049192     0.108803     0.103551     0.000312     0.042249   \n",
       "706024    -0.028156     0.059426     0.075589    -0.055549     0.016988   \n",
       "706025    -0.045423     0.101048     0.127583    -0.006447     0.050258   \n",
       "706026    -0.046034     0.109513     0.128275    -0.003456     0.053254   \n",
       "706027    -0.046877     0.124818     0.128629     0.001318     0.058327   \n",
       "\n",
       "        embedding_7  ...  embedding_40  embedding_41  embedding_42  \\\n",
       "0          0.003656  ...      0.023005     -0.016056      0.010822   \n",
       "1         -0.041915  ...      0.007638      0.022504     -0.005386   \n",
       "2         -0.008114  ...      0.001428      0.002351      0.011762   \n",
       "3         -0.003103  ...      0.021811     -0.007376      0.005410   \n",
       "4          0.038051  ...      0.020041      0.014329     -0.025540   \n",
       "...             ...  ...           ...           ...           ...   \n",
       "706023     0.014440  ...     -0.026842      0.004354     -0.000510   \n",
       "706024    -0.000330  ...     -0.013487     -0.007866      0.030421   \n",
       "706025     0.026254  ...     -0.019883      0.008003      0.009772   \n",
       "706026     0.027267  ...     -0.022960      0.006409      0.008017   \n",
       "706027     0.028699  ...     -0.028685      0.003089      0.005064   \n",
       "\n",
       "        embedding_43  embedding_44  embedding_45  embedding_46  embedding_47  \\\n",
       "0          -0.000577      0.020482      0.000518     -0.007269      0.005182   \n",
       "1          -0.012064      0.011904     -0.018995     -0.023025      0.009447   \n",
       "2           0.025877     -0.010867     -0.044785     -0.003382      0.075150   \n",
       "3          -0.005284     -0.004893      0.004136      0.026057      0.014127   \n",
       "4          -0.030381     -0.037740     -0.022946     -0.014160     -0.014366   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "706023     -0.019718      0.002946     -0.029177     -0.017638     -0.031907   \n",
       "706024     -0.012009      0.014661     -0.028032     -0.019619     -0.002625   \n",
       "706025     -0.022577      0.006393     -0.029919     -0.027532     -0.032977   \n",
       "706026     -0.024181      0.006599     -0.030657     -0.026145     -0.034481   \n",
       "706027     -0.027032      0.007142     -0.032023     -0.023367     -0.036778   \n",
       "\n",
       "        embedding_48  embedding_49  \n",
       "0          -0.002655     -0.006325  \n",
       "1           0.014939     -0.000303  \n",
       "2          -0.005372      0.008051  \n",
       "3          -0.006860      0.013506  \n",
       "4          -0.005830     -0.026705  \n",
       "...              ...           ...  \n",
       "706023     -0.008844      0.020305  \n",
       "706024     -0.018203      0.009254  \n",
       "706025     -0.013356      0.015409  \n",
       "706026     -0.012717      0.016915  \n",
       "706027     -0.011594      0.019661  \n",
       "\n",
       "[706028 rows x 52 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d476fbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>char_count</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Federal law supersedes state law, and cannabis...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>967</td>\n",
       "      <td>181</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>25.857143</td>\n",
       "      <td>57.30</td>\n",
       "      <td>967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035092</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>-0.041666</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.071304</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>0.004744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Miles feels restless after working all day. He...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>5068</td>\n",
       "      <td>924</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.661255</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>53.21</td>\n",
       "      <td>5068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003091</td>\n",
       "      <td>-0.043269</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.060853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>So first of I am danish. That means that I fol...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>1602</td>\n",
       "      <td>316</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.718354</td>\n",
       "      <td>22.571429</td>\n",
       "      <td>61.97</td>\n",
       "      <td>1602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.012316</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.005499</td>\n",
       "      <td>-0.011693</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>In this paper we present a novel rule-based ap...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>5469</td>\n",
       "      <td>1015</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.564532</td>\n",
       "      <td>40.600000</td>\n",
       "      <td>27.86</td>\n",
       "      <td>5469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018165</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>-0.006033</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>-0.019899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Most social progressives, love democracy, and ...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>2379</td>\n",
       "      <td>437</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.752860</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>61.67</td>\n",
       "      <td>2379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text    source  \\\n",
       "0           0  Federal law supersedes state law, and cannabis...  Bloom-7B   \n",
       "1           1  Miles feels restless after working all day. He...  Bloom-7B   \n",
       "2           2  So first of I am danish. That means that I fol...  Bloom-7B   \n",
       "3           3  In this paper we present a novel rule-based ap...  Bloom-7B   \n",
       "4           4  Most social progressives, love democracy, and ...  Bloom-7B   \n",
       "\n",
       "   text_length  word_count     Prompt  lexical_diversity  avg_sentence_length  \\\n",
       "0          967         181  Undefined           0.806630            25.857143   \n",
       "1         5068         924  Undefined           0.661255            23.100000   \n",
       "2         1602         316  Undefined           0.718354            22.571429   \n",
       "3         5469        1015  Undefined           0.564532            40.600000   \n",
       "4         2379         437  Undefined           0.752860            23.000000   \n",
       "\n",
       "   readability_score  char_count  ...  embedding_40  embedding_41  \\\n",
       "0              57.30         967  ...     -0.035092     -0.001925   \n",
       "1              53.21        5068  ...     -0.003091     -0.043269   \n",
       "2              61.97        1602  ...      0.011013     -0.008409   \n",
       "3              27.86        5469  ...     -0.018165      0.012030   \n",
       "4              61.67        2379  ...      0.004131      0.014534   \n",
       "\n",
       "   embedding_42  embedding_43  embedding_44  embedding_45  embedding_46  \\\n",
       "0     -0.041666     -0.005266      0.034543      0.002532     -0.071304   \n",
       "1      0.003721     -0.005574      0.030584     -0.006616      0.030465   \n",
       "2      0.008066     -0.012316      0.007549     -0.000401     -0.001133   \n",
       "3     -0.020475     -0.006033      0.002823     -0.000594      0.000835   \n",
       "4      0.007382     -0.016189      0.007070      0.001430     -0.017871   \n",
       "\n",
       "   embedding_47  embedding_48  embedding_49  \n",
       "0      0.014727     -0.012865      0.004744  \n",
       "1      0.000941      0.020913      0.060853  \n",
       "2     -0.005499     -0.011693      0.000179  \n",
       "3      0.001109      0.009936     -0.019899  \n",
       "4      0.004868      0.010563      0.008097  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('corpus.csv')\n",
    "#df.source.unique()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "614a223b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(788922, 63)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58d24a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>char_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Federal law supersedes state law, and cannabis...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>967</td>\n",
       "      <td>181</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>25.857143</td>\n",
       "      <td>57.30</td>\n",
       "      <td>967</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035092</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>-0.041666</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.071304</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>0.004744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Miles feels restless after working all day. He...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>5068</td>\n",
       "      <td>924</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.661255</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>53.21</td>\n",
       "      <td>5068</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003091</td>\n",
       "      <td>-0.043269</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.060853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So first of I am danish. That means that I fol...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>1602</td>\n",
       "      <td>316</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.718354</td>\n",
       "      <td>22.571429</td>\n",
       "      <td>61.97</td>\n",
       "      <td>1602</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.012316</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.005499</td>\n",
       "      <td>-0.011693</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this paper we present a novel rule-based ap...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>5469</td>\n",
       "      <td>1015</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.564532</td>\n",
       "      <td>40.600000</td>\n",
       "      <td>27.86</td>\n",
       "      <td>5469</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018165</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>-0.006033</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>-0.019899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Most social progressives, love democracy, and ...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>2379</td>\n",
       "      <td>437</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.752860</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>61.67</td>\n",
       "      <td>2379</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788917</th>\n",
       "      <td>\\nIn the vast expanse of time, where the echoe...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>5523</td>\n",
       "      <td>951</td>\n",
       "      <td>The Ethics of De-extinction and Bringing Back ...</td>\n",
       "      <td>0.420610</td>\n",
       "      <td>28.818182</td>\n",
       "      <td>36.22</td>\n",
       "      <td>5523</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005222</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>-0.020148</td>\n",
       "      <td>-0.023085</td>\n",
       "      <td>-0.030199</td>\n",
       "      <td>-0.012152</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>-0.007202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788918</th>\n",
       "      <td>\\nThe phenomenon of brain drain, particularly ...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>4540</td>\n",
       "      <td>761</td>\n",
       "      <td>The Economic and Social Consequences of Brain ...</td>\n",
       "      <td>0.395532</td>\n",
       "      <td>28.185185</td>\n",
       "      <td>29.08</td>\n",
       "      <td>4540</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006157</td>\n",
       "      <td>-0.023404</td>\n",
       "      <td>0.037557</td>\n",
       "      <td>0.026361</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.023823</td>\n",
       "      <td>-0.009165</td>\n",
       "      <td>-0.004096</td>\n",
       "      <td>-0.016606</td>\n",
       "      <td>0.020802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788919</th>\n",
       "      <td>\\nThe Influence of Climate Change on Marine Ec...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>3889</td>\n",
       "      <td>670</td>\n",
       "      <td>The influence of climate change on marine ecos...</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>26.800000</td>\n",
       "      <td>47.22</td>\n",
       "      <td>3889</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>-0.001044</td>\n",
       "      <td>-0.037097</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>0.039127</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.072912</td>\n",
       "      <td>-0.009205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788920</th>\n",
       "      <td>\\nTitle: The Case for Limiting Car Usage: Navi...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>3560</td>\n",
       "      <td>592</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td>0.476351</td>\n",
       "      <td>28.190476</td>\n",
       "      <td>28.77</td>\n",
       "      <td>3560</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.035284</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.023736</td>\n",
       "      <td>0.030208</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>-0.011754</td>\n",
       "      <td>-0.010964</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.014060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788921</th>\n",
       "      <td>\\nIn the vast expanse of a globalized society,...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>4563</td>\n",
       "      <td>786</td>\n",
       "      <td>The Importance of Intercultural Communication ...</td>\n",
       "      <td>0.404580</td>\n",
       "      <td>25.354839</td>\n",
       "      <td>31.82</td>\n",
       "      <td>4563</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017204</td>\n",
       "      <td>-0.020792</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.019272</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>788922 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text    source  \\\n",
       "0       Federal law supersedes state law, and cannabis...  Bloom-7B   \n",
       "1       Miles feels restless after working all day. He...  Bloom-7B   \n",
       "2       So first of I am danish. That means that I fol...  Bloom-7B   \n",
       "3       In this paper we present a novel rule-based ap...  Bloom-7B   \n",
       "4       Most social progressives, love democracy, and ...  Bloom-7B   \n",
       "...                                                   ...       ...   \n",
       "788917  \\nIn the vast expanse of time, where the echoe...    YI-34B   \n",
       "788918  \\nThe phenomenon of brain drain, particularly ...    YI-34B   \n",
       "788919  \\nThe Influence of Climate Change on Marine Ec...    YI-34B   \n",
       "788920  \\nTitle: The Case for Limiting Car Usage: Navi...    YI-34B   \n",
       "788921  \\nIn the vast expanse of a globalized society,...    YI-34B   \n",
       "\n",
       "        text_length  word_count  \\\n",
       "0               967         181   \n",
       "1              5068         924   \n",
       "2              1602         316   \n",
       "3              5469        1015   \n",
       "4              2379         437   \n",
       "...             ...         ...   \n",
       "788917         5523         951   \n",
       "788918         4540         761   \n",
       "788919         3889         670   \n",
       "788920         3560         592   \n",
       "788921         4563         786   \n",
       "\n",
       "                                                   Prompt  lexical_diversity  \\\n",
       "0                                               Undefined           0.806630   \n",
       "1                                               Undefined           0.661255   \n",
       "2                                               Undefined           0.718354   \n",
       "3                                               Undefined           0.564532   \n",
       "4                                               Undefined           0.752860   \n",
       "...                                                   ...                ...   \n",
       "788917  The Ethics of De-extinction and Bringing Back ...           0.420610   \n",
       "788918  The Economic and Social Consequences of Brain ...           0.395532   \n",
       "788919  The influence of climate change on marine ecos...           0.447761   \n",
       "788920  Write an explanatory essay to inform fellow ci...           0.476351   \n",
       "788921  The Importance of Intercultural Communication ...           0.404580   \n",
       "\n",
       "        avg_sentence_length  readability_score  char_count  sentence_count  \\\n",
       "0                 25.857143              57.30         967               7   \n",
       "1                 23.100000              53.21        5068              40   \n",
       "2                 22.571429              61.97        1602              14   \n",
       "3                 40.600000              27.86        5469              25   \n",
       "4                 23.000000              61.67        2379              19   \n",
       "...                     ...                ...         ...             ...   \n",
       "788917            28.818182              36.22        5523              33   \n",
       "788918            28.185185              29.08        4540              27   \n",
       "788919            26.800000              47.22        3889              25   \n",
       "788920            28.190476              28.77        3560              21   \n",
       "788921            25.354839              31.82        4563              31   \n",
       "\n",
       "        ...  embedding_40  embedding_41  embedding_42  embedding_43  \\\n",
       "0       ...     -0.035092     -0.001925     -0.041666     -0.005266   \n",
       "1       ...     -0.003091     -0.043269      0.003721     -0.005574   \n",
       "2       ...      0.011013     -0.008409      0.008066     -0.012316   \n",
       "3       ...     -0.018165      0.012030     -0.020475     -0.006033   \n",
       "4       ...      0.004131      0.014534      0.007382     -0.016189   \n",
       "...     ...           ...           ...           ...           ...   \n",
       "788917  ...     -0.005222     -0.001365     -0.020148     -0.023085   \n",
       "788918  ...     -0.006157     -0.023404      0.037557      0.026361   \n",
       "788919  ...      0.010574     -0.008166      0.018903     -0.001044   \n",
       "788920  ...      0.013639      0.035284      0.000662      0.023736   \n",
       "788921  ...      0.017204     -0.020792      0.003079      0.026649   \n",
       "\n",
       "        embedding_44  embedding_45  embedding_46  embedding_47  embedding_48  \\\n",
       "0           0.034543      0.002532     -0.071304      0.014727     -0.012865   \n",
       "1           0.030584     -0.006616      0.030465      0.000941      0.020913   \n",
       "2           0.007549     -0.000401     -0.001133     -0.005499     -0.011693   \n",
       "3           0.002823     -0.000594      0.000835      0.001109      0.009936   \n",
       "4           0.007070      0.001430     -0.017871      0.004868      0.010563   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "788917     -0.030199     -0.012152      0.002733     -0.000128      0.022612   \n",
       "788918     -0.008231      0.023823     -0.009165     -0.004096     -0.016606   \n",
       "788919     -0.037097      0.025732      0.039127      0.018915      0.072912   \n",
       "788920      0.030208      0.013736     -0.011754     -0.010964      0.000265   \n",
       "788921      0.001552      0.009237      0.019272      0.000913      0.027279   \n",
       "\n",
       "        embedding_49  \n",
       "0           0.004744  \n",
       "1           0.060853  \n",
       "2           0.000179  \n",
       "3          -0.019899  \n",
       "4           0.008097  \n",
       "...              ...  \n",
       "788917     -0.007202  \n",
       "788918      0.020802  \n",
       "788919     -0.009205  \n",
       "788920      0.014060  \n",
       "788921      0.002167  \n",
       "\n",
       "[788922 rows x 62 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Unnamed: 0'], axis=1, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38ec9a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>classification</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Federal law supersedes state law, and cannabis...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>57.30</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008560</td>\n",
       "      <td>0.095722</td>\n",
       "      <td>-0.049095</td>\n",
       "      <td>-0.118440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035092</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>-0.041666</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.071304</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>0.004744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Miles feels restless after working all day. He...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0.661255</td>\n",
       "      <td>53.21</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>-0.099866</td>\n",
       "      <td>0.107777</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003091</td>\n",
       "      <td>-0.043269</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.060853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So first of I am danish. That means that I fol...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0.718354</td>\n",
       "      <td>61.97</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164173</td>\n",
       "      <td>0.117847</td>\n",
       "      <td>-0.012992</td>\n",
       "      <td>0.088472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.012316</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.005499</td>\n",
       "      <td>-0.011693</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this paper we present a novel rule-based ap...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0.564532</td>\n",
       "      <td>27.86</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.179447</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>0.155961</td>\n",
       "      <td>0.029293</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018165</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>-0.006033</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>-0.019899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Most social progressives, love democracy, and ...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0.752860</td>\n",
       "      <td>61.67</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159706</td>\n",
       "      <td>0.083560</td>\n",
       "      <td>-0.074277</td>\n",
       "      <td>0.031704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788917</th>\n",
       "      <td>\\nIn the vast expanse of time, where the echoe...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>0.420610</td>\n",
       "      <td>36.22</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.157033</td>\n",
       "      <td>-0.008564</td>\n",
       "      <td>-0.079678</td>\n",
       "      <td>0.104863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005222</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>-0.020148</td>\n",
       "      <td>-0.023085</td>\n",
       "      <td>-0.030199</td>\n",
       "      <td>-0.012152</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>-0.007202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788918</th>\n",
       "      <td>\\nThe phenomenon of brain drain, particularly ...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>0.395532</td>\n",
       "      <td>29.08</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.282313</td>\n",
       "      <td>0.034885</td>\n",
       "      <td>-0.078380</td>\n",
       "      <td>-0.014602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006157</td>\n",
       "      <td>-0.023404</td>\n",
       "      <td>0.037557</td>\n",
       "      <td>0.026361</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.023823</td>\n",
       "      <td>-0.009165</td>\n",
       "      <td>-0.004096</td>\n",
       "      <td>-0.016606</td>\n",
       "      <td>0.020802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788919</th>\n",
       "      <td>\\nThe Influence of Climate Change on Marine Ec...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>47.22</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.264905</td>\n",
       "      <td>-0.011840</td>\n",
       "      <td>0.106972</td>\n",
       "      <td>0.034591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>-0.001044</td>\n",
       "      <td>-0.037097</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>0.039127</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.072912</td>\n",
       "      <td>-0.009205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788920</th>\n",
       "      <td>\\nTitle: The Case for Limiting Car Usage: Navi...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>0.476351</td>\n",
       "      <td>28.77</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.263766</td>\n",
       "      <td>0.064379</td>\n",
       "      <td>-0.021544</td>\n",
       "      <td>-0.112702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.035284</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.023736</td>\n",
       "      <td>0.030208</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>-0.011754</td>\n",
       "      <td>-0.010964</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.014060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788921</th>\n",
       "      <td>\\nIn the vast expanse of a globalized society,...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>0.404580</td>\n",
       "      <td>31.82</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.193548</td>\n",
       "      <td>0.069151</td>\n",
       "      <td>-0.109348</td>\n",
       "      <td>0.181288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017204</td>\n",
       "      <td>-0.020792</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.019272</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>788922 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text    source  \\\n",
       "0       Federal law supersedes state law, and cannabis...  Bloom-7B   \n",
       "1       Miles feels restless after working all day. He...  Bloom-7B   \n",
       "2       So first of I am danish. That means that I fol...  Bloom-7B   \n",
       "3       In this paper we present a novel rule-based ap...  Bloom-7B   \n",
       "4       Most social progressives, love democracy, and ...  Bloom-7B   \n",
       "...                                                   ...       ...   \n",
       "788917  \\nIn the vast expanse of time, where the echoe...    YI-34B   \n",
       "788918  \\nThe phenomenon of brain drain, particularly ...    YI-34B   \n",
       "788919  \\nThe Influence of Climate Change on Marine Ec...    YI-34B   \n",
       "788920  \\nTitle: The Case for Limiting Car Usage: Navi...    YI-34B   \n",
       "788921  \\nIn the vast expanse of a globalized society,...    YI-34B   \n",
       "\n",
       "        lexical_diversity  readability_score  prompt_length  classification  \\\n",
       "0                0.806630              57.30              9               1   \n",
       "1                0.661255              53.21              9               1   \n",
       "2                0.718354              61.97              9               1   \n",
       "3                0.564532              27.86              9               1   \n",
       "4                0.752860              61.67              9               1   \n",
       "...                   ...                ...            ...             ...   \n",
       "788917           0.420610              36.22             61               1   \n",
       "788918           0.395532              29.08             66               1   \n",
       "788919           0.447761              47.22             52               1   \n",
       "788920           0.476351              28.77            512               1   \n",
       "788921           0.404580              31.82             67               1   \n",
       "\n",
       "        embedding_0  embedding_1  embedding_2  embedding_3  ...  embedding_40  \\\n",
       "0          0.008560     0.095722    -0.049095    -0.118440  ...     -0.035092   \n",
       "1          0.070761    -0.099866     0.107777     0.008168  ...     -0.003091   \n",
       "2          0.164173     0.117847    -0.012992     0.088472  ...      0.011013   \n",
       "3         -0.179447     0.010308     0.155961     0.029293  ...     -0.018165   \n",
       "4          0.159706     0.083560    -0.074277     0.031704  ...      0.004131   \n",
       "...             ...          ...          ...          ...  ...           ...   \n",
       "788917    -0.157033    -0.008564    -0.079678     0.104863  ...     -0.005222   \n",
       "788918    -0.282313     0.034885    -0.078380    -0.014602  ...     -0.006157   \n",
       "788919    -0.264905    -0.011840     0.106972     0.034591  ...      0.010574   \n",
       "788920    -0.263766     0.064379    -0.021544    -0.112702  ...      0.013639   \n",
       "788921    -0.193548     0.069151    -0.109348     0.181288  ...      0.017204   \n",
       "\n",
       "        embedding_41  embedding_42  embedding_43  embedding_44  embedding_45  \\\n",
       "0          -0.001925     -0.041666     -0.005266      0.034543      0.002532   \n",
       "1          -0.043269      0.003721     -0.005574      0.030584     -0.006616   \n",
       "2          -0.008409      0.008066     -0.012316      0.007549     -0.000401   \n",
       "3           0.012030     -0.020475     -0.006033      0.002823     -0.000594   \n",
       "4           0.014534      0.007382     -0.016189      0.007070      0.001430   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "788917     -0.001365     -0.020148     -0.023085     -0.030199     -0.012152   \n",
       "788918     -0.023404      0.037557      0.026361     -0.008231      0.023823   \n",
       "788919     -0.008166      0.018903     -0.001044     -0.037097      0.025732   \n",
       "788920      0.035284      0.000662      0.023736      0.030208      0.013736   \n",
       "788921     -0.020792      0.003079      0.026649      0.001552      0.009237   \n",
       "\n",
       "        embedding_46  embedding_47  embedding_48  embedding_49  \n",
       "0          -0.071304      0.014727     -0.012865      0.004744  \n",
       "1           0.030465      0.000941      0.020913      0.060853  \n",
       "2          -0.001133     -0.005499     -0.011693      0.000179  \n",
       "3           0.000835      0.001109      0.009936     -0.019899  \n",
       "4          -0.017871      0.004868      0.010563      0.008097  \n",
       "...              ...           ...           ...           ...  \n",
       "788917      0.002733     -0.000128      0.022612     -0.007202  \n",
       "788918     -0.009165     -0.004096     -0.016606      0.020802  \n",
       "788919      0.039127      0.018915      0.072912     -0.009205  \n",
       "788920     -0.011754     -0.010964      0.000265      0.014060  \n",
       "788921      0.019272      0.000913      0.027279      0.002167  \n",
       "\n",
       "[788922 rows x 56 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['text_length', 'word_count', 'Prompt', 'avg_sentence_length', 'char_count', 'sentence_count'], axis=1, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bced9947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>classification</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Federal law supersedes state law, and cannabis...</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>57.30</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008560</td>\n",
       "      <td>0.095722</td>\n",
       "      <td>-0.049095</td>\n",
       "      <td>-0.118440</td>\n",
       "      <td>-0.004019</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035092</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>-0.041666</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.071304</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>0.004744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Miles feels restless after working all day. He...</td>\n",
       "      <td>0.661255</td>\n",
       "      <td>53.21</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>-0.099866</td>\n",
       "      <td>0.107777</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>-0.063522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003091</td>\n",
       "      <td>-0.043269</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.060853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So first of I am danish. That means that I fol...</td>\n",
       "      <td>0.718354</td>\n",
       "      <td>61.97</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164173</td>\n",
       "      <td>0.117847</td>\n",
       "      <td>-0.012992</td>\n",
       "      <td>0.088472</td>\n",
       "      <td>0.097658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.012316</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.005499</td>\n",
       "      <td>-0.011693</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this paper we present a novel rule-based ap...</td>\n",
       "      <td>0.564532</td>\n",
       "      <td>27.86</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.179447</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>0.155961</td>\n",
       "      <td>0.029293</td>\n",
       "      <td>0.099195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018165</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>-0.006033</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>-0.019899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Most social progressives, love democracy, and ...</td>\n",
       "      <td>0.752860</td>\n",
       "      <td>61.67</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159706</td>\n",
       "      <td>0.083560</td>\n",
       "      <td>-0.074277</td>\n",
       "      <td>0.031704</td>\n",
       "      <td>0.066774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788917</th>\n",
       "      <td>\\nIn the vast expanse of time, where the echoe...</td>\n",
       "      <td>0.420610</td>\n",
       "      <td>36.22</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.157033</td>\n",
       "      <td>-0.008564</td>\n",
       "      <td>-0.079678</td>\n",
       "      <td>0.104863</td>\n",
       "      <td>-0.095362</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005222</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>-0.020148</td>\n",
       "      <td>-0.023085</td>\n",
       "      <td>-0.030199</td>\n",
       "      <td>-0.012152</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>-0.007202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788918</th>\n",
       "      <td>\\nThe phenomenon of brain drain, particularly ...</td>\n",
       "      <td>0.395532</td>\n",
       "      <td>29.08</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.282313</td>\n",
       "      <td>0.034885</td>\n",
       "      <td>-0.078380</td>\n",
       "      <td>-0.014602</td>\n",
       "      <td>-0.034506</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006157</td>\n",
       "      <td>-0.023404</td>\n",
       "      <td>0.037557</td>\n",
       "      <td>0.026361</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.023823</td>\n",
       "      <td>-0.009165</td>\n",
       "      <td>-0.004096</td>\n",
       "      <td>-0.016606</td>\n",
       "      <td>0.020802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788919</th>\n",
       "      <td>\\nThe Influence of Climate Change on Marine Ec...</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>47.22</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.264905</td>\n",
       "      <td>-0.011840</td>\n",
       "      <td>0.106972</td>\n",
       "      <td>0.034591</td>\n",
       "      <td>-0.192508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>-0.001044</td>\n",
       "      <td>-0.037097</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>0.039127</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.072912</td>\n",
       "      <td>-0.009205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788920</th>\n",
       "      <td>\\nTitle: The Case for Limiting Car Usage: Navi...</td>\n",
       "      <td>0.476351</td>\n",
       "      <td>28.77</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.263766</td>\n",
       "      <td>0.064379</td>\n",
       "      <td>-0.021544</td>\n",
       "      <td>-0.112702</td>\n",
       "      <td>-0.044006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.035284</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.023736</td>\n",
       "      <td>0.030208</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>-0.011754</td>\n",
       "      <td>-0.010964</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.014060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788921</th>\n",
       "      <td>\\nIn the vast expanse of a globalized society,...</td>\n",
       "      <td>0.404580</td>\n",
       "      <td>31.82</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.193548</td>\n",
       "      <td>0.069151</td>\n",
       "      <td>-0.109348</td>\n",
       "      <td>0.181288</td>\n",
       "      <td>-0.049860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017204</td>\n",
       "      <td>-0.020792</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.019272</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>788922 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  lexical_diversity  \\\n",
       "0       Federal law supersedes state law, and cannabis...           0.806630   \n",
       "1       Miles feels restless after working all day. He...           0.661255   \n",
       "2       So first of I am danish. That means that I fol...           0.718354   \n",
       "3       In this paper we present a novel rule-based ap...           0.564532   \n",
       "4       Most social progressives, love democracy, and ...           0.752860   \n",
       "...                                                   ...                ...   \n",
       "788917  \\nIn the vast expanse of time, where the echoe...           0.420610   \n",
       "788918  \\nThe phenomenon of brain drain, particularly ...           0.395532   \n",
       "788919  \\nThe Influence of Climate Change on Marine Ec...           0.447761   \n",
       "788920  \\nTitle: The Case for Limiting Car Usage: Navi...           0.476351   \n",
       "788921  \\nIn the vast expanse of a globalized society,...           0.404580   \n",
       "\n",
       "        readability_score  prompt_length  classification  embedding_0  \\\n",
       "0                   57.30              9               1     0.008560   \n",
       "1                   53.21              9               1     0.070761   \n",
       "2                   61.97              9               1     0.164173   \n",
       "3                   27.86              9               1    -0.179447   \n",
       "4                   61.67              9               1     0.159706   \n",
       "...                   ...            ...             ...          ...   \n",
       "788917              36.22             61               1    -0.157033   \n",
       "788918              29.08             66               1    -0.282313   \n",
       "788919              47.22             52               1    -0.264905   \n",
       "788920              28.77            512               1    -0.263766   \n",
       "788921              31.82             67               1    -0.193548   \n",
       "\n",
       "        embedding_1  embedding_2  embedding_3  embedding_4  ...  embedding_40  \\\n",
       "0          0.095722    -0.049095    -0.118440    -0.004019  ...     -0.035092   \n",
       "1         -0.099866     0.107777     0.008168    -0.063522  ...     -0.003091   \n",
       "2          0.117847    -0.012992     0.088472     0.097658  ...      0.011013   \n",
       "3          0.010308     0.155961     0.029293     0.099195  ...     -0.018165   \n",
       "4          0.083560    -0.074277     0.031704     0.066774  ...      0.004131   \n",
       "...             ...          ...          ...          ...  ...           ...   \n",
       "788917    -0.008564    -0.079678     0.104863    -0.095362  ...     -0.005222   \n",
       "788918     0.034885    -0.078380    -0.014602    -0.034506  ...     -0.006157   \n",
       "788919    -0.011840     0.106972     0.034591    -0.192508  ...      0.010574   \n",
       "788920     0.064379    -0.021544    -0.112702    -0.044006  ...      0.013639   \n",
       "788921     0.069151    -0.109348     0.181288    -0.049860  ...      0.017204   \n",
       "\n",
       "        embedding_41  embedding_42  embedding_43  embedding_44  embedding_45  \\\n",
       "0          -0.001925     -0.041666     -0.005266      0.034543      0.002532   \n",
       "1          -0.043269      0.003721     -0.005574      0.030584     -0.006616   \n",
       "2          -0.008409      0.008066     -0.012316      0.007549     -0.000401   \n",
       "3           0.012030     -0.020475     -0.006033      0.002823     -0.000594   \n",
       "4           0.014534      0.007382     -0.016189      0.007070      0.001430   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "788917     -0.001365     -0.020148     -0.023085     -0.030199     -0.012152   \n",
       "788918     -0.023404      0.037557      0.026361     -0.008231      0.023823   \n",
       "788919     -0.008166      0.018903     -0.001044     -0.037097      0.025732   \n",
       "788920      0.035284      0.000662      0.023736      0.030208      0.013736   \n",
       "788921     -0.020792      0.003079      0.026649      0.001552      0.009237   \n",
       "\n",
       "        embedding_46  embedding_47  embedding_48  embedding_49  \n",
       "0          -0.071304      0.014727     -0.012865      0.004744  \n",
       "1           0.030465      0.000941      0.020913      0.060853  \n",
       "2          -0.001133     -0.005499     -0.011693      0.000179  \n",
       "3           0.000835      0.001109      0.009936     -0.019899  \n",
       "4          -0.017871      0.004868      0.010563      0.008097  \n",
       "...              ...           ...           ...           ...  \n",
       "788917      0.002733     -0.000128      0.022612     -0.007202  \n",
       "788918     -0.009165     -0.004096     -0.016606      0.020802  \n",
       "788919      0.039127      0.018915      0.072912     -0.009205  \n",
       "788920     -0.011754     -0.010964      0.000265      0.014060  \n",
       "788921      0.019272      0.000913      0.027279      0.002167  \n",
       "\n",
       "[788922 rows x 55 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['source'], axis=1, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c10d82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>classification</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Federal law supersedes state law, and cannabis...</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>57.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008560</td>\n",
       "      <td>0.095722</td>\n",
       "      <td>-0.049095</td>\n",
       "      <td>-0.118440</td>\n",
       "      <td>-0.004019</td>\n",
       "      <td>0.043696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035092</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>-0.041666</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.071304</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>0.004744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Miles feels restless after working all day. He...</td>\n",
       "      <td>0.661255</td>\n",
       "      <td>53.21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>-0.099866</td>\n",
       "      <td>0.107777</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>-0.063522</td>\n",
       "      <td>0.097034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003091</td>\n",
       "      <td>-0.043269</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.060853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So first of I am danish. That means that I fol...</td>\n",
       "      <td>0.718354</td>\n",
       "      <td>61.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164173</td>\n",
       "      <td>0.117847</td>\n",
       "      <td>-0.012992</td>\n",
       "      <td>0.088472</td>\n",
       "      <td>0.097658</td>\n",
       "      <td>-0.002207</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.012316</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.005499</td>\n",
       "      <td>-0.011693</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this paper we present a novel rule-based ap...</td>\n",
       "      <td>0.564532</td>\n",
       "      <td>27.86</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.179447</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>0.155961</td>\n",
       "      <td>0.029293</td>\n",
       "      <td>0.099195</td>\n",
       "      <td>-0.101426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018165</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>-0.006033</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>-0.019899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Most social progressives, love democracy, and ...</td>\n",
       "      <td>0.752860</td>\n",
       "      <td>61.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159706</td>\n",
       "      <td>0.083560</td>\n",
       "      <td>-0.074277</td>\n",
       "      <td>0.031704</td>\n",
       "      <td>0.066774</td>\n",
       "      <td>0.062544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788917</th>\n",
       "      <td>\\nIn the vast expanse of time, where the echoe...</td>\n",
       "      <td>0.420610</td>\n",
       "      <td>36.22</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.157033</td>\n",
       "      <td>-0.008564</td>\n",
       "      <td>-0.079678</td>\n",
       "      <td>0.104863</td>\n",
       "      <td>-0.095362</td>\n",
       "      <td>0.039880</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005222</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>-0.020148</td>\n",
       "      <td>-0.023085</td>\n",
       "      <td>-0.030199</td>\n",
       "      <td>-0.012152</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>-0.007202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788918</th>\n",
       "      <td>\\nThe phenomenon of brain drain, particularly ...</td>\n",
       "      <td>0.395532</td>\n",
       "      <td>29.08</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.282313</td>\n",
       "      <td>0.034885</td>\n",
       "      <td>-0.078380</td>\n",
       "      <td>-0.014602</td>\n",
       "      <td>-0.034506</td>\n",
       "      <td>0.077010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006157</td>\n",
       "      <td>-0.023404</td>\n",
       "      <td>0.037557</td>\n",
       "      <td>0.026361</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.023823</td>\n",
       "      <td>-0.009165</td>\n",
       "      <td>-0.004096</td>\n",
       "      <td>-0.016606</td>\n",
       "      <td>0.020802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788919</th>\n",
       "      <td>\\nThe Influence of Climate Change on Marine Ec...</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>47.22</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.264905</td>\n",
       "      <td>-0.011840</td>\n",
       "      <td>0.106972</td>\n",
       "      <td>0.034591</td>\n",
       "      <td>-0.192508</td>\n",
       "      <td>0.167850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>-0.001044</td>\n",
       "      <td>-0.037097</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>0.039127</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.072912</td>\n",
       "      <td>-0.009205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788920</th>\n",
       "      <td>\\nTitle: The Case for Limiting Car Usage: Navi...</td>\n",
       "      <td>0.476351</td>\n",
       "      <td>28.77</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.263766</td>\n",
       "      <td>0.064379</td>\n",
       "      <td>-0.021544</td>\n",
       "      <td>-0.112702</td>\n",
       "      <td>-0.044006</td>\n",
       "      <td>0.123673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.035284</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.023736</td>\n",
       "      <td>0.030208</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>-0.011754</td>\n",
       "      <td>-0.010964</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.014060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788921</th>\n",
       "      <td>\\nIn the vast expanse of a globalized society,...</td>\n",
       "      <td>0.404580</td>\n",
       "      <td>31.82</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.193548</td>\n",
       "      <td>0.069151</td>\n",
       "      <td>-0.109348</td>\n",
       "      <td>0.181288</td>\n",
       "      <td>-0.049860</td>\n",
       "      <td>0.040569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017204</td>\n",
       "      <td>-0.020792</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.019272</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>788922 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  lexical_diversity  \\\n",
       "0       Federal law supersedes state law, and cannabis...           0.806630   \n",
       "1       Miles feels restless after working all day. He...           0.661255   \n",
       "2       So first of I am danish. That means that I fol...           0.718354   \n",
       "3       In this paper we present a novel rule-based ap...           0.564532   \n",
       "4       Most social progressives, love democracy, and ...           0.752860   \n",
       "...                                                   ...                ...   \n",
       "788917  \\nIn the vast expanse of time, where the echoe...           0.420610   \n",
       "788918  \\nThe phenomenon of brain drain, particularly ...           0.395532   \n",
       "788919  \\nThe Influence of Climate Change on Marine Ec...           0.447761   \n",
       "788920  \\nTitle: The Case for Limiting Car Usage: Navi...           0.476351   \n",
       "788921  \\nIn the vast expanse of a globalized society,...           0.404580   \n",
       "\n",
       "        readability_score  classification  embedding_0  embedding_1  \\\n",
       "0                   57.30               1     0.008560     0.095722   \n",
       "1                   53.21               1     0.070761    -0.099866   \n",
       "2                   61.97               1     0.164173     0.117847   \n",
       "3                   27.86               1    -0.179447     0.010308   \n",
       "4                   61.67               1     0.159706     0.083560   \n",
       "...                   ...             ...          ...          ...   \n",
       "788917              36.22               1    -0.157033    -0.008564   \n",
       "788918              29.08               1    -0.282313     0.034885   \n",
       "788919              47.22               1    -0.264905    -0.011840   \n",
       "788920              28.77               1    -0.263766     0.064379   \n",
       "788921              31.82               1    -0.193548     0.069151   \n",
       "\n",
       "        embedding_2  embedding_3  embedding_4  embedding_5  ...  embedding_40  \\\n",
       "0         -0.049095    -0.118440    -0.004019     0.043696  ...     -0.035092   \n",
       "1          0.107777     0.008168    -0.063522     0.097034  ...     -0.003091   \n",
       "2         -0.012992     0.088472     0.097658    -0.002207  ...      0.011013   \n",
       "3          0.155961     0.029293     0.099195    -0.101426  ...     -0.018165   \n",
       "4         -0.074277     0.031704     0.066774     0.062544  ...      0.004131   \n",
       "...             ...          ...          ...          ...  ...           ...   \n",
       "788917    -0.079678     0.104863    -0.095362     0.039880  ...     -0.005222   \n",
       "788918    -0.078380    -0.014602    -0.034506     0.077010  ...     -0.006157   \n",
       "788919     0.106972     0.034591    -0.192508     0.167850  ...      0.010574   \n",
       "788920    -0.021544    -0.112702    -0.044006     0.123673  ...      0.013639   \n",
       "788921    -0.109348     0.181288    -0.049860     0.040569  ...      0.017204   \n",
       "\n",
       "        embedding_41  embedding_42  embedding_43  embedding_44  embedding_45  \\\n",
       "0          -0.001925     -0.041666     -0.005266      0.034543      0.002532   \n",
       "1          -0.043269      0.003721     -0.005574      0.030584     -0.006616   \n",
       "2          -0.008409      0.008066     -0.012316      0.007549     -0.000401   \n",
       "3           0.012030     -0.020475     -0.006033      0.002823     -0.000594   \n",
       "4           0.014534      0.007382     -0.016189      0.007070      0.001430   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "788917     -0.001365     -0.020148     -0.023085     -0.030199     -0.012152   \n",
       "788918     -0.023404      0.037557      0.026361     -0.008231      0.023823   \n",
       "788919     -0.008166      0.018903     -0.001044     -0.037097      0.025732   \n",
       "788920      0.035284      0.000662      0.023736      0.030208      0.013736   \n",
       "788921     -0.020792      0.003079      0.026649      0.001552      0.009237   \n",
       "\n",
       "        embedding_46  embedding_47  embedding_48  embedding_49  \n",
       "0          -0.071304      0.014727     -0.012865      0.004744  \n",
       "1           0.030465      0.000941      0.020913      0.060853  \n",
       "2          -0.001133     -0.005499     -0.011693      0.000179  \n",
       "3           0.000835      0.001109      0.009936     -0.019899  \n",
       "4          -0.017871      0.004868      0.010563      0.008097  \n",
       "...              ...           ...           ...           ...  \n",
       "788917      0.002733     -0.000128      0.022612     -0.007202  \n",
       "788918     -0.009165     -0.004096     -0.016606      0.020802  \n",
       "788919      0.039127      0.018915      0.072912     -0.009205  \n",
       "788920     -0.011754     -0.010964      0.000265      0.014060  \n",
       "788921      0.019272      0.000913      0.027279      0.002167  \n",
       "\n",
       "[788922 rows x 54 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['prompt_length'], axis=1, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e060c06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>classification</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.806630</td>\n",
       "      <td>57.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008560</td>\n",
       "      <td>0.095722</td>\n",
       "      <td>-0.049095</td>\n",
       "      <td>-0.118440</td>\n",
       "      <td>-0.004019</td>\n",
       "      <td>0.043696</td>\n",
       "      <td>-0.116908</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035092</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>-0.041666</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.071304</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>0.004744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.661255</td>\n",
       "      <td>53.21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>-0.099866</td>\n",
       "      <td>0.107777</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>-0.063522</td>\n",
       "      <td>0.097034</td>\n",
       "      <td>0.091039</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003091</td>\n",
       "      <td>-0.043269</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.060853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.718354</td>\n",
       "      <td>61.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164173</td>\n",
       "      <td>0.117847</td>\n",
       "      <td>-0.012992</td>\n",
       "      <td>0.088472</td>\n",
       "      <td>0.097658</td>\n",
       "      <td>-0.002207</td>\n",
       "      <td>-0.073280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.012316</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.005499</td>\n",
       "      <td>-0.011693</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.564532</td>\n",
       "      <td>27.86</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.179447</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>0.155961</td>\n",
       "      <td>0.029293</td>\n",
       "      <td>0.099195</td>\n",
       "      <td>-0.101426</td>\n",
       "      <td>-0.038001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018165</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>-0.006033</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>-0.019899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.752860</td>\n",
       "      <td>61.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.159706</td>\n",
       "      <td>0.083560</td>\n",
       "      <td>-0.074277</td>\n",
       "      <td>0.031704</td>\n",
       "      <td>0.066774</td>\n",
       "      <td>0.062544</td>\n",
       "      <td>-0.055907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788917</th>\n",
       "      <td>0.420610</td>\n",
       "      <td>36.22</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.157033</td>\n",
       "      <td>-0.008564</td>\n",
       "      <td>-0.079678</td>\n",
       "      <td>0.104863</td>\n",
       "      <td>-0.095362</td>\n",
       "      <td>0.039880</td>\n",
       "      <td>-0.053883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005222</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>-0.020148</td>\n",
       "      <td>-0.023085</td>\n",
       "      <td>-0.030199</td>\n",
       "      <td>-0.012152</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>-0.007202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788918</th>\n",
       "      <td>0.395532</td>\n",
       "      <td>29.08</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.282313</td>\n",
       "      <td>0.034885</td>\n",
       "      <td>-0.078380</td>\n",
       "      <td>-0.014602</td>\n",
       "      <td>-0.034506</td>\n",
       "      <td>0.077010</td>\n",
       "      <td>0.023160</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006157</td>\n",
       "      <td>-0.023404</td>\n",
       "      <td>0.037557</td>\n",
       "      <td>0.026361</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.023823</td>\n",
       "      <td>-0.009165</td>\n",
       "      <td>-0.004096</td>\n",
       "      <td>-0.016606</td>\n",
       "      <td>0.020802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788919</th>\n",
       "      <td>0.447761</td>\n",
       "      <td>47.22</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.264905</td>\n",
       "      <td>-0.011840</td>\n",
       "      <td>0.106972</td>\n",
       "      <td>0.034591</td>\n",
       "      <td>-0.192508</td>\n",
       "      <td>0.167850</td>\n",
       "      <td>-0.146308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>-0.001044</td>\n",
       "      <td>-0.037097</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>0.039127</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.072912</td>\n",
       "      <td>-0.009205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788920</th>\n",
       "      <td>0.476351</td>\n",
       "      <td>28.77</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.263766</td>\n",
       "      <td>0.064379</td>\n",
       "      <td>-0.021544</td>\n",
       "      <td>-0.112702</td>\n",
       "      <td>-0.044006</td>\n",
       "      <td>0.123673</td>\n",
       "      <td>0.041577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.035284</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.023736</td>\n",
       "      <td>0.030208</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>-0.011754</td>\n",
       "      <td>-0.010964</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.014060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788921</th>\n",
       "      <td>0.404580</td>\n",
       "      <td>31.82</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.193548</td>\n",
       "      <td>0.069151</td>\n",
       "      <td>-0.109348</td>\n",
       "      <td>0.181288</td>\n",
       "      <td>-0.049860</td>\n",
       "      <td>0.040569</td>\n",
       "      <td>0.085691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017204</td>\n",
       "      <td>-0.020792</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.019272</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>788922 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lexical_diversity  readability_score  classification  embedding_0  \\\n",
       "0                0.806630              57.30               1     0.008560   \n",
       "1                0.661255              53.21               1     0.070761   \n",
       "2                0.718354              61.97               1     0.164173   \n",
       "3                0.564532              27.86               1    -0.179447   \n",
       "4                0.752860              61.67               1     0.159706   \n",
       "...                   ...                ...             ...          ...   \n",
       "788917           0.420610              36.22               1    -0.157033   \n",
       "788918           0.395532              29.08               1    -0.282313   \n",
       "788919           0.447761              47.22               1    -0.264905   \n",
       "788920           0.476351              28.77               1    -0.263766   \n",
       "788921           0.404580              31.82               1    -0.193548   \n",
       "\n",
       "        embedding_1  embedding_2  embedding_3  embedding_4  embedding_5  \\\n",
       "0          0.095722    -0.049095    -0.118440    -0.004019     0.043696   \n",
       "1         -0.099866     0.107777     0.008168    -0.063522     0.097034   \n",
       "2          0.117847    -0.012992     0.088472     0.097658    -0.002207   \n",
       "3          0.010308     0.155961     0.029293     0.099195    -0.101426   \n",
       "4          0.083560    -0.074277     0.031704     0.066774     0.062544   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "788917    -0.008564    -0.079678     0.104863    -0.095362     0.039880   \n",
       "788918     0.034885    -0.078380    -0.014602    -0.034506     0.077010   \n",
       "788919    -0.011840     0.106972     0.034591    -0.192508     0.167850   \n",
       "788920     0.064379    -0.021544    -0.112702    -0.044006     0.123673   \n",
       "788921     0.069151    -0.109348     0.181288    -0.049860     0.040569   \n",
       "\n",
       "        embedding_6  ...  embedding_40  embedding_41  embedding_42  \\\n",
       "0         -0.116908  ...     -0.035092     -0.001925     -0.041666   \n",
       "1          0.091039  ...     -0.003091     -0.043269      0.003721   \n",
       "2         -0.073280  ...      0.011013     -0.008409      0.008066   \n",
       "3         -0.038001  ...     -0.018165      0.012030     -0.020475   \n",
       "4         -0.055907  ...      0.004131      0.014534      0.007382   \n",
       "...             ...  ...           ...           ...           ...   \n",
       "788917    -0.053883  ...     -0.005222     -0.001365     -0.020148   \n",
       "788918     0.023160  ...     -0.006157     -0.023404      0.037557   \n",
       "788919    -0.146308  ...      0.010574     -0.008166      0.018903   \n",
       "788920     0.041577  ...      0.013639      0.035284      0.000662   \n",
       "788921     0.085691  ...      0.017204     -0.020792      0.003079   \n",
       "\n",
       "        embedding_43  embedding_44  embedding_45  embedding_46  embedding_47  \\\n",
       "0          -0.005266      0.034543      0.002532     -0.071304      0.014727   \n",
       "1          -0.005574      0.030584     -0.006616      0.030465      0.000941   \n",
       "2          -0.012316      0.007549     -0.000401     -0.001133     -0.005499   \n",
       "3          -0.006033      0.002823     -0.000594      0.000835      0.001109   \n",
       "4          -0.016189      0.007070      0.001430     -0.017871      0.004868   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "788917     -0.023085     -0.030199     -0.012152      0.002733     -0.000128   \n",
       "788918      0.026361     -0.008231      0.023823     -0.009165     -0.004096   \n",
       "788919     -0.001044     -0.037097      0.025732      0.039127      0.018915   \n",
       "788920      0.023736      0.030208      0.013736     -0.011754     -0.010964   \n",
       "788921      0.026649      0.001552      0.009237      0.019272      0.000913   \n",
       "\n",
       "        embedding_48  embedding_49  \n",
       "0          -0.012865      0.004744  \n",
       "1           0.020913      0.060853  \n",
       "2          -0.011693      0.000179  \n",
       "3           0.009936     -0.019899  \n",
       "4           0.010563      0.008097  \n",
       "...              ...           ...  \n",
       "788917      0.022612     -0.007202  \n",
       "788918     -0.016606      0.020802  \n",
       "788919      0.072912     -0.009205  \n",
       "788920      0.000265      0.014060  \n",
       "788921      0.027279      0.002167  \n",
       "\n",
       "[788922 rows x 53 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['text'], axis=1, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34988508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    441230\n",
       "0    347692\n",
       "Name: classification, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['classification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b40a3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.806630</td>\n",
       "      <td>57.30</td>\n",
       "      <td>0.008560</td>\n",
       "      <td>0.095722</td>\n",
       "      <td>-0.049095</td>\n",
       "      <td>-0.118440</td>\n",
       "      <td>-0.004019</td>\n",
       "      <td>0.043696</td>\n",
       "      <td>-0.116908</td>\n",
       "      <td>-0.008107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035092</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>-0.041666</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.071304</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>0.004744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.661255</td>\n",
       "      <td>53.21</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>-0.099866</td>\n",
       "      <td>0.107777</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>-0.063522</td>\n",
       "      <td>0.097034</td>\n",
       "      <td>0.091039</td>\n",
       "      <td>0.015570</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003091</td>\n",
       "      <td>-0.043269</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.060853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.718354</td>\n",
       "      <td>61.97</td>\n",
       "      <td>0.164173</td>\n",
       "      <td>0.117847</td>\n",
       "      <td>-0.012992</td>\n",
       "      <td>0.088472</td>\n",
       "      <td>0.097658</td>\n",
       "      <td>-0.002207</td>\n",
       "      <td>-0.073280</td>\n",
       "      <td>-0.042987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.012316</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.005499</td>\n",
       "      <td>-0.011693</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.564532</td>\n",
       "      <td>27.86</td>\n",
       "      <td>-0.179447</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>0.155961</td>\n",
       "      <td>0.029293</td>\n",
       "      <td>0.099195</td>\n",
       "      <td>-0.101426</td>\n",
       "      <td>-0.038001</td>\n",
       "      <td>0.011437</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018165</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>-0.006033</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>-0.019899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.752860</td>\n",
       "      <td>61.67</td>\n",
       "      <td>0.159706</td>\n",
       "      <td>0.083560</td>\n",
       "      <td>-0.074277</td>\n",
       "      <td>0.031704</td>\n",
       "      <td>0.066774</td>\n",
       "      <td>0.062544</td>\n",
       "      <td>-0.055907</td>\n",
       "      <td>-0.002149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788917</th>\n",
       "      <td>0.420610</td>\n",
       "      <td>36.22</td>\n",
       "      <td>-0.157033</td>\n",
       "      <td>-0.008564</td>\n",
       "      <td>-0.079678</td>\n",
       "      <td>0.104863</td>\n",
       "      <td>-0.095362</td>\n",
       "      <td>0.039880</td>\n",
       "      <td>-0.053883</td>\n",
       "      <td>-0.106344</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005222</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>-0.020148</td>\n",
       "      <td>-0.023085</td>\n",
       "      <td>-0.030199</td>\n",
       "      <td>-0.012152</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>-0.007202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788918</th>\n",
       "      <td>0.395532</td>\n",
       "      <td>29.08</td>\n",
       "      <td>-0.282313</td>\n",
       "      <td>0.034885</td>\n",
       "      <td>-0.078380</td>\n",
       "      <td>-0.014602</td>\n",
       "      <td>-0.034506</td>\n",
       "      <td>0.077010</td>\n",
       "      <td>0.023160</td>\n",
       "      <td>0.014074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006157</td>\n",
       "      <td>-0.023404</td>\n",
       "      <td>0.037557</td>\n",
       "      <td>0.026361</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.023823</td>\n",
       "      <td>-0.009165</td>\n",
       "      <td>-0.004096</td>\n",
       "      <td>-0.016606</td>\n",
       "      <td>0.020802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788919</th>\n",
       "      <td>0.447761</td>\n",
       "      <td>47.22</td>\n",
       "      <td>-0.264905</td>\n",
       "      <td>-0.011840</td>\n",
       "      <td>0.106972</td>\n",
       "      <td>0.034591</td>\n",
       "      <td>-0.192508</td>\n",
       "      <td>0.167850</td>\n",
       "      <td>-0.146308</td>\n",
       "      <td>-0.042047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>-0.001044</td>\n",
       "      <td>-0.037097</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>0.039127</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.072912</td>\n",
       "      <td>-0.009205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788920</th>\n",
       "      <td>0.476351</td>\n",
       "      <td>28.77</td>\n",
       "      <td>-0.263766</td>\n",
       "      <td>0.064379</td>\n",
       "      <td>-0.021544</td>\n",
       "      <td>-0.112702</td>\n",
       "      <td>-0.044006</td>\n",
       "      <td>0.123673</td>\n",
       "      <td>0.041577</td>\n",
       "      <td>-0.016348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.035284</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.023736</td>\n",
       "      <td>0.030208</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>-0.011754</td>\n",
       "      <td>-0.010964</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.014060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788921</th>\n",
       "      <td>0.404580</td>\n",
       "      <td>31.82</td>\n",
       "      <td>-0.193548</td>\n",
       "      <td>0.069151</td>\n",
       "      <td>-0.109348</td>\n",
       "      <td>0.181288</td>\n",
       "      <td>-0.049860</td>\n",
       "      <td>0.040569</td>\n",
       "      <td>0.085691</td>\n",
       "      <td>-0.085746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017204</td>\n",
       "      <td>-0.020792</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.019272</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>788922 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lexical_diversity  readability_score  embedding_0  embedding_1  \\\n",
       "0                0.806630              57.30     0.008560     0.095722   \n",
       "1                0.661255              53.21     0.070761    -0.099866   \n",
       "2                0.718354              61.97     0.164173     0.117847   \n",
       "3                0.564532              27.86    -0.179447     0.010308   \n",
       "4                0.752860              61.67     0.159706     0.083560   \n",
       "...                   ...                ...          ...          ...   \n",
       "788917           0.420610              36.22    -0.157033    -0.008564   \n",
       "788918           0.395532              29.08    -0.282313     0.034885   \n",
       "788919           0.447761              47.22    -0.264905    -0.011840   \n",
       "788920           0.476351              28.77    -0.263766     0.064379   \n",
       "788921           0.404580              31.82    -0.193548     0.069151   \n",
       "\n",
       "        embedding_2  embedding_3  embedding_4  embedding_5  embedding_6  \\\n",
       "0         -0.049095    -0.118440    -0.004019     0.043696    -0.116908   \n",
       "1          0.107777     0.008168    -0.063522     0.097034     0.091039   \n",
       "2         -0.012992     0.088472     0.097658    -0.002207    -0.073280   \n",
       "3          0.155961     0.029293     0.099195    -0.101426    -0.038001   \n",
       "4         -0.074277     0.031704     0.066774     0.062544    -0.055907   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "788917    -0.079678     0.104863    -0.095362     0.039880    -0.053883   \n",
       "788918    -0.078380    -0.014602    -0.034506     0.077010     0.023160   \n",
       "788919     0.106972     0.034591    -0.192508     0.167850    -0.146308   \n",
       "788920    -0.021544    -0.112702    -0.044006     0.123673     0.041577   \n",
       "788921    -0.109348     0.181288    -0.049860     0.040569     0.085691   \n",
       "\n",
       "        embedding_7  ...  embedding_40  embedding_41  embedding_42  \\\n",
       "0         -0.008107  ...     -0.035092     -0.001925     -0.041666   \n",
       "1          0.015570  ...     -0.003091     -0.043269      0.003721   \n",
       "2         -0.042987  ...      0.011013     -0.008409      0.008066   \n",
       "3          0.011437  ...     -0.018165      0.012030     -0.020475   \n",
       "4         -0.002149  ...      0.004131      0.014534      0.007382   \n",
       "...             ...  ...           ...           ...           ...   \n",
       "788917    -0.106344  ...     -0.005222     -0.001365     -0.020148   \n",
       "788918     0.014074  ...     -0.006157     -0.023404      0.037557   \n",
       "788919    -0.042047  ...      0.010574     -0.008166      0.018903   \n",
       "788920    -0.016348  ...      0.013639      0.035284      0.000662   \n",
       "788921    -0.085746  ...      0.017204     -0.020792      0.003079   \n",
       "\n",
       "        embedding_43  embedding_44  embedding_45  embedding_46  embedding_47  \\\n",
       "0          -0.005266      0.034543      0.002532     -0.071304      0.014727   \n",
       "1          -0.005574      0.030584     -0.006616      0.030465      0.000941   \n",
       "2          -0.012316      0.007549     -0.000401     -0.001133     -0.005499   \n",
       "3          -0.006033      0.002823     -0.000594      0.000835      0.001109   \n",
       "4          -0.016189      0.007070      0.001430     -0.017871      0.004868   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "788917     -0.023085     -0.030199     -0.012152      0.002733     -0.000128   \n",
       "788918      0.026361     -0.008231      0.023823     -0.009165     -0.004096   \n",
       "788919     -0.001044     -0.037097      0.025732      0.039127      0.018915   \n",
       "788920      0.023736      0.030208      0.013736     -0.011754     -0.010964   \n",
       "788921      0.026649      0.001552      0.009237      0.019272      0.000913   \n",
       "\n",
       "        embedding_48  embedding_49  \n",
       "0          -0.012865      0.004744  \n",
       "1           0.020913      0.060853  \n",
       "2          -0.011693      0.000179  \n",
       "3           0.009936     -0.019899  \n",
       "4           0.010563      0.008097  \n",
       "...              ...           ...  \n",
       "788917      0.022612     -0.007202  \n",
       "788918     -0.016606      0.020802  \n",
       "788919      0.072912     -0.009205  \n",
       "788920      0.000265      0.014060  \n",
       "788921      0.027279      0.002167  \n",
       "\n",
       "[788922 rows x 52 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['classification'], axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "685613a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "788917    1\n",
       "788918    1\n",
       "788919    1\n",
       "788920    1\n",
       "788921    1\n",
       "Name: classification, Length: 788922, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['classification']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1857e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f8c33d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(631137, 52)\n",
      "(157785, 52)\n",
      "(631137,)\n",
      "(157785,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a91ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "adasyn = ADASYN()\n",
    "X_resampled, y_resampled = adasyn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0123c8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.362340</td>\n",
       "      <td>19.810000</td>\n",
       "      <td>-0.313918</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>-0.037702</td>\n",
       "      <td>0.178112</td>\n",
       "      <td>-0.057451</td>\n",
       "      <td>0.010045</td>\n",
       "      <td>0.070563</td>\n",
       "      <td>-0.030519</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031118</td>\n",
       "      <td>-0.018364</td>\n",
       "      <td>-0.017552</td>\n",
       "      <td>-0.033377</td>\n",
       "      <td>0.010988</td>\n",
       "      <td>0.024157</td>\n",
       "      <td>0.016149</td>\n",
       "      <td>0.042856</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>-0.005194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.594340</td>\n",
       "      <td>72.460000</td>\n",
       "      <td>-0.028841</td>\n",
       "      <td>-0.119339</td>\n",
       "      <td>0.142218</td>\n",
       "      <td>-0.050424</td>\n",
       "      <td>0.123454</td>\n",
       "      <td>-0.044138</td>\n",
       "      <td>0.121926</td>\n",
       "      <td>-0.055619</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023218</td>\n",
       "      <td>0.030872</td>\n",
       "      <td>0.012089</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.044491</td>\n",
       "      <td>0.011058</td>\n",
       "      <td>0.017052</td>\n",
       "      <td>-0.009379</td>\n",
       "      <td>0.006174</td>\n",
       "      <td>-0.012802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.577206</td>\n",
       "      <td>69.920000</td>\n",
       "      <td>0.303838</td>\n",
       "      <td>-0.030253</td>\n",
       "      <td>-0.017719</td>\n",
       "      <td>-0.050776</td>\n",
       "      <td>-0.013972</td>\n",
       "      <td>-0.028626</td>\n",
       "      <td>0.036949</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019381</td>\n",
       "      <td>-0.002734</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>-0.002202</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>0.012343</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>-0.019975</td>\n",
       "      <td>0.016681</td>\n",
       "      <td>-0.009854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.397780</td>\n",
       "      <td>37.300000</td>\n",
       "      <td>-0.249733</td>\n",
       "      <td>-0.004098</td>\n",
       "      <td>0.011451</td>\n",
       "      <td>0.131737</td>\n",
       "      <td>0.081940</td>\n",
       "      <td>-0.027256</td>\n",
       "      <td>0.036708</td>\n",
       "      <td>0.097219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021817</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.001689</td>\n",
       "      <td>0.042396</td>\n",
       "      <td>-0.030133</td>\n",
       "      <td>-0.009946</td>\n",
       "      <td>0.038410</td>\n",
       "      <td>0.025292</td>\n",
       "      <td>0.023069</td>\n",
       "      <td>0.017276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.555921</td>\n",
       "      <td>37.640000</td>\n",
       "      <td>-0.118131</td>\n",
       "      <td>0.060025</td>\n",
       "      <td>-0.131267</td>\n",
       "      <td>0.049748</td>\n",
       "      <td>0.057296</td>\n",
       "      <td>-0.017713</td>\n",
       "      <td>-0.005860</td>\n",
       "      <td>0.073022</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017031</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.008881</td>\n",
       "      <td>-0.002948</td>\n",
       "      <td>-0.008303</td>\n",
       "      <td>0.021185</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>-0.030139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685751</th>\n",
       "      <td>0.865150</td>\n",
       "      <td>57.270000</td>\n",
       "      <td>0.040462</td>\n",
       "      <td>0.243818</td>\n",
       "      <td>-0.027323</td>\n",
       "      <td>-0.109279</td>\n",
       "      <td>0.062646</td>\n",
       "      <td>-0.006073</td>\n",
       "      <td>0.010005</td>\n",
       "      <td>-0.043090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060221</td>\n",
       "      <td>-0.010429</td>\n",
       "      <td>0.068361</td>\n",
       "      <td>0.049456</td>\n",
       "      <td>-0.042433</td>\n",
       "      <td>0.030335</td>\n",
       "      <td>-0.039211</td>\n",
       "      <td>-0.005996</td>\n",
       "      <td>-0.064874</td>\n",
       "      <td>0.008871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685752</th>\n",
       "      <td>0.591880</td>\n",
       "      <td>71.572360</td>\n",
       "      <td>0.051193</td>\n",
       "      <td>0.049561</td>\n",
       "      <td>0.031480</td>\n",
       "      <td>-0.024915</td>\n",
       "      <td>-0.133134</td>\n",
       "      <td>0.047781</td>\n",
       "      <td>-0.112202</td>\n",
       "      <td>-0.018199</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005299</td>\n",
       "      <td>-0.004613</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>-0.006393</td>\n",
       "      <td>-0.005214</td>\n",
       "      <td>-0.039298</td>\n",
       "      <td>-0.006475</td>\n",
       "      <td>0.007667</td>\n",
       "      <td>0.018191</td>\n",
       "      <td>0.038808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685753</th>\n",
       "      <td>0.611837</td>\n",
       "      <td>37.421336</td>\n",
       "      <td>-0.174576</td>\n",
       "      <td>0.029990</td>\n",
       "      <td>-0.020118</td>\n",
       "      <td>-0.119191</td>\n",
       "      <td>0.092546</td>\n",
       "      <td>0.062916</td>\n",
       "      <td>-0.005921</td>\n",
       "      <td>-0.010503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.004312</td>\n",
       "      <td>0.005187</td>\n",
       "      <td>0.011893</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.012220</td>\n",
       "      <td>-0.021409</td>\n",
       "      <td>0.006099</td>\n",
       "      <td>0.011928</td>\n",
       "      <td>-0.005967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685754</th>\n",
       "      <td>0.398512</td>\n",
       "      <td>69.393325</td>\n",
       "      <td>0.064953</td>\n",
       "      <td>-0.077371</td>\n",
       "      <td>-0.005291</td>\n",
       "      <td>-0.114237</td>\n",
       "      <td>-0.021544</td>\n",
       "      <td>-0.070255</td>\n",
       "      <td>-0.048984</td>\n",
       "      <td>-0.055847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007533</td>\n",
       "      <td>0.004589</td>\n",
       "      <td>0.017387</td>\n",
       "      <td>-0.031607</td>\n",
       "      <td>0.017932</td>\n",
       "      <td>-0.008081</td>\n",
       "      <td>0.023041</td>\n",
       "      <td>-0.008119</td>\n",
       "      <td>-0.009037</td>\n",
       "      <td>0.001978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685755</th>\n",
       "      <td>0.771622</td>\n",
       "      <td>38.004537</td>\n",
       "      <td>-0.275051</td>\n",
       "      <td>0.165094</td>\n",
       "      <td>0.249790</td>\n",
       "      <td>-0.027189</td>\n",
       "      <td>0.072839</td>\n",
       "      <td>-0.151323</td>\n",
       "      <td>-0.042824</td>\n",
       "      <td>0.048913</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010081</td>\n",
       "      <td>0.017342</td>\n",
       "      <td>-0.004876</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>-0.010054</td>\n",
       "      <td>-0.047796</td>\n",
       "      <td>-0.019683</td>\n",
       "      <td>-0.019378</td>\n",
       "      <td>-0.079506</td>\n",
       "      <td>0.032128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>685756 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lexical_diversity  readability_score  embedding_0  embedding_1  \\\n",
       "0                0.362340          19.810000    -0.313918     0.000198   \n",
       "1                0.594340          72.460000    -0.028841    -0.119339   \n",
       "2                0.577206          69.920000     0.303838    -0.030253   \n",
       "3                0.397780          37.300000    -0.249733    -0.004098   \n",
       "4                0.555921          37.640000    -0.118131     0.060025   \n",
       "...                   ...                ...          ...          ...   \n",
       "685751           0.865150          57.270000     0.040462     0.243818   \n",
       "685752           0.591880          71.572360     0.051193     0.049561   \n",
       "685753           0.611837          37.421336    -0.174576     0.029990   \n",
       "685754           0.398512          69.393325     0.064953    -0.077371   \n",
       "685755           0.771622          38.004537    -0.275051     0.165094   \n",
       "\n",
       "        embedding_2  embedding_3  embedding_4  embedding_5  embedding_6  \\\n",
       "0         -0.037702     0.178112    -0.057451     0.010045     0.070563   \n",
       "1          0.142218    -0.050424     0.123454    -0.044138     0.121926   \n",
       "2         -0.017719    -0.050776    -0.013972    -0.028626     0.036949   \n",
       "3          0.011451     0.131737     0.081940    -0.027256     0.036708   \n",
       "4         -0.131267     0.049748     0.057296    -0.017713    -0.005860   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "685751    -0.027323    -0.109279     0.062646    -0.006073     0.010005   \n",
       "685752     0.031480    -0.024915    -0.133134     0.047781    -0.112202   \n",
       "685753    -0.020118    -0.119191     0.092546     0.062916    -0.005921   \n",
       "685754    -0.005291    -0.114237    -0.021544    -0.070255    -0.048984   \n",
       "685755     0.249790    -0.027189     0.072839    -0.151323    -0.042824   \n",
       "\n",
       "        embedding_7  ...  embedding_40  embedding_41  embedding_42  \\\n",
       "0         -0.030519  ...     -0.031118     -0.018364     -0.017552   \n",
       "1         -0.055619  ...     -0.023218      0.030872      0.012089   \n",
       "2          0.004492  ...     -0.019381     -0.002734      0.002830   \n",
       "3          0.097219  ...      0.021817     -0.005670     -0.001689   \n",
       "4          0.073022  ...     -0.017031      0.005346      0.001600   \n",
       "...             ...  ...           ...           ...           ...   \n",
       "685751    -0.043090  ...     -0.060221     -0.010429      0.068361   \n",
       "685752    -0.018199  ...     -0.005299     -0.004613      0.009455   \n",
       "685753    -0.010503  ...      0.006864      0.004312      0.005187   \n",
       "685754    -0.055847  ...     -0.007533      0.004589      0.017387   \n",
       "685755     0.048913  ...     -0.010081      0.017342     -0.004876   \n",
       "\n",
       "        embedding_43  embedding_44  embedding_45  embedding_46  embedding_47  \\\n",
       "0          -0.033377      0.010988      0.024157      0.016149      0.042856   \n",
       "1           0.004924      0.044491      0.011058      0.017052     -0.009379   \n",
       "2          -0.002202      0.003834      0.012343      0.003326     -0.019975   \n",
       "3           0.042396     -0.030133     -0.009946      0.038410      0.025292   \n",
       "4           0.002799      0.008881     -0.002948     -0.008303      0.021185   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "685751      0.049456     -0.042433      0.030335     -0.039211     -0.005996   \n",
       "685752     -0.006393     -0.005214     -0.039298     -0.006475      0.007667   \n",
       "685753      0.011893      0.012100      0.012220     -0.021409      0.006099   \n",
       "685754     -0.031607      0.017932     -0.008081      0.023041     -0.008119   \n",
       "685755      0.011168     -0.010054     -0.047796     -0.019683     -0.019378   \n",
       "\n",
       "        embedding_48  embedding_49  \n",
       "0           0.000855     -0.005194  \n",
       "1           0.006174     -0.012802  \n",
       "2           0.016681     -0.009854  \n",
       "3           0.023069      0.017276  \n",
       "4           0.000295     -0.030139  \n",
       "...              ...           ...  \n",
       "685751     -0.064874      0.008871  \n",
       "685752      0.018191      0.038808  \n",
       "685753      0.011928     -0.005967  \n",
       "685754     -0.009037      0.001978  \n",
       "685755     -0.079506      0.032128  \n",
       "\n",
       "[685756 rows x 52 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88875996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    353097\n",
       "0    332659\n",
       "Name: classification, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afaab07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d70cb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8706404284310929\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85     68105\n",
      "           1       0.89      0.88      0.89     89680\n",
      "\n",
      "    accuracy                           0.87    157785\n",
      "   macro avg       0.87      0.87      0.87    157785\n",
      "weighted avg       0.87      0.87      0.87    157785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f685ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "knn_model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a9f65ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7814874671229838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78     69652\n",
      "           1       0.87      0.71      0.78     88133\n",
      "\n",
      "    accuracy                           0.78    157785\n",
      "   macro avg       0.79      0.79      0.78    157785\n",
      "weighted avg       0.80      0.78      0.78    157785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_pred_knn,y_test))\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2facd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d666977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.875 total time= 4.8min\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.875 total time= 4.7min\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.875 total time= 4.7min\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.875 total time= 4.4min\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50;, score=0.827 total time= 4.5min\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.880 total time= 8.7min\n",
      "[CV 2/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.881 total time= 8.6min\n",
      "[CV 3/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.881 total time= 8.6min\n",
      "[CV 4/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.880 total time= 8.6min\n",
      "[CV 5/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100;, score=0.831 total time=21.8min\n",
      "[CV 1/5] END criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200;, score=0.883 total time=58.1min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[1;32m      3\u001b[0m GCVRandomForest \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m GCVRandomForest\u001b[38;5;241m.\u001b[39mfit(X_resampled, y_resampled)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    475\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    476\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    477\u001b[0m )(\n\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    479\u001b[0m         t,\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[1;32m    481\u001b[0m         X,\n\u001b[1;32m    482\u001b[0m         y,\n\u001b[1;32m    483\u001b[0m         sample_weight,\n\u001b[1;32m    484\u001b[0m         i,\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[1;32m    486\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    487\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    489\u001b[0m     )\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    890\u001b[0m         X,\n\u001b[1;32m    891\u001b[0m         y,\n\u001b[1;32m    892\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    893\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "131bc27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_final = {\n",
    "    'n_estimators': [150, 200], # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20], # Maximum depth of the trees\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],  # Function to measure the quality of a split\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a98d143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END criterion=gini, max_depth=None, n_estimators=150;, score=0.883 total time=13.4min\n",
      "[CV 2/5] END criterion=gini, max_depth=None, n_estimators=150;, score=0.883 total time=13.9min\n",
      "[CV 3/5] END criterion=gini, max_depth=None, n_estimators=150;, score=0.884 total time=13.9min\n",
      "[CV 4/5] END criterion=gini, max_depth=None, n_estimators=150;, score=0.883 total time=13.8min\n",
      "[CV 5/5] END criterion=gini, max_depth=None, n_estimators=150;, score=0.831 total time=14.3min\n",
      "[CV 1/5] END criterion=gini, max_depth=None, n_estimators=200;, score=0.884 total time=18.3min\n",
      "[CV 2/5] END criterion=gini, max_depth=None, n_estimators=200;, score=0.885 total time=32.7min\n",
      "[CV 3/5] END criterion=gini, max_depth=None, n_estimators=200;, score=0.884 total time=19.5min\n",
      "[CV 4/5] END criterion=gini, max_depth=None, n_estimators=200;, score=0.883 total time=23.8min\n",
      "[CV 5/5] END criterion=gini, max_depth=None, n_estimators=200;, score=0.832 total time=41.9min\n",
      "[CV 1/5] END criterion=gini, max_depth=10, n_estimators=150;, score=0.796 total time= 6.7min\n",
      "[CV 2/5] END criterion=gini, max_depth=10, n_estimators=150;, score=0.796 total time= 6.7min\n",
      "[CV 3/5] END criterion=gini, max_depth=10, n_estimators=150;, score=0.798 total time= 6.8min\n",
      "[CV 4/5] END criterion=gini, max_depth=10, n_estimators=150;, score=0.797 total time= 6.8min\n",
      "[CV 5/5] END criterion=gini, max_depth=10, n_estimators=150;, score=0.691 total time= 6.8min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[1;32m      3\u001b[0m GCVRandomForest \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid_final, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m GCVRandomForest\u001b[38;5;241m.\u001b[39mfit(X_resampled, y_resampled)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    475\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    476\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    477\u001b[0m )(\n\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    479\u001b[0m         t,\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[1;32m    481\u001b[0m         X,\n\u001b[1;32m    482\u001b[0m         y,\n\u001b[1;32m    483\u001b[0m         sample_weight,\n\u001b[1;32m    484\u001b[0m         i,\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[1;32m    486\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    487\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    489\u001b[0m     )\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    890\u001b[0m         X,\n\u001b[1;32m    891\u001b[0m         y,\n\u001b[1;32m    892\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    893\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "GCVRandomForest = GridSearchCV(estimator=model, param_grid=param_grid_final, cv=5, scoring='accuracy', verbose=3)\n",
    "GCVRandomForest.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ff2b69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b4787c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[1;32m      3\u001b[0m GCVRandomForest \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid_final1, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m GCVRandomForest\u001b[38;5;241m.\u001b[39mfit(X_resampled, y_resampled)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    474\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    475\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    476\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    477\u001b[0m )(\n\u001b[1;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    479\u001b[0m         t,\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[1;32m    481\u001b[0m         X,\n\u001b[1;32m    482\u001b[0m         y,\n\u001b[1;32m    483\u001b[0m         sample_weight,\n\u001b[1;32m    484\u001b[0m         i,\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[1;32m    486\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    487\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m    488\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    489\u001b[0m     )\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    491\u001b[0m )\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    890\u001b[0m         X,\n\u001b[1;32m    891\u001b[0m         y,\n\u001b[1;32m    892\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    893\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff0993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
