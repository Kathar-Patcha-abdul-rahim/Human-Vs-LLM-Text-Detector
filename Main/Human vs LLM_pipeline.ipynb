{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e78d5fa",
   "metadata": {},
   "source": [
    "# Pipeline to process the user input and determine whether the given text is AI-generated or Human-written"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49fb115",
   "metadata": {},
   "source": [
    "We do the word embeddings and PCA on the user input to match it with our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5abb44f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textstat.textstat import textstatistics\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import numpy as np\n",
    "\n",
    "def lexical_diversity(text):\n",
    "    tokens = text.split()\n",
    "    if len(tokens) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(set(tokens)) / len(tokens)\n",
    "    \n",
    "def readability_score(text):\n",
    "    return textstatistics().flesch_reading_ease(text)\n",
    "\n",
    "def generate_word2vec_features(text, word2vec_model):\n",
    "    tokens = text.split()\n",
    "    embeddings = np.zeros((300,))\n",
    "    valid_tokens = 0\n",
    "    for token in tokens:\n",
    "        if token in word2vec_model:\n",
    "            embeddings += word2vec_model[token]\n",
    "            valid_tokens += 1\n",
    "    if valid_tokens > 0:\n",
    "        embeddings /= valid_tokens\n",
    "    return embeddings\n",
    "\n",
    "def text_to_features(text, word2vec_model, pca_model):\n",
    "    lex_div = lexical_diversity(text)\n",
    "    read_score = readability_score(text)\n",
    "    word2vec_features = generate_word2vec_features(text, word2vec_model)\n",
    "    word2vec_features_reshaped = word2vec_features.reshape(1, -1)\n",
    "    word2vec_features_reduced = pca_model.transform(word2vec_features_reshaped)\n",
    "    features = np.concatenate(([lex_div, read_score], word2vec_features_reduced.flatten()))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d718f14",
   "metadata": {},
   "source": [
    "# Function to perform binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f381b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text_classification(text, word2vec_model, pca_model, model):\n",
    "    features = text_to_features(text, word2vec_model, pca_model).reshape(1, -1)\n",
    "    prediction = model.predict(features)\n",
    "    return \"AI-generated\" if prediction == 1 else \"Human-written\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b199579",
   "metadata": {},
   "source": [
    "# Function to perform multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4f5d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text_classification_mc(text, word2vec_model, pca_model, model):\n",
    "    features = text_to_features(text, word2vec_model, pca_model).reshape(1, -1)\n",
    "    prediction = model.predict(features)\n",
    "    \n",
    "    if prediction == 13:\n",
    "        pred = \"GPT-3.5\"\n",
    "    elif prediction == 37:\n",
    "        pred = \"OPT-1.3B\"\n",
    "    elif prediction == 41:\n",
    "        pred = \"OPT-30B\"\n",
    "    elif prediction == 58:\n",
    "        pred = \"Text-Davinci-002\"\n",
    "    elif prediction == 59:\n",
    "        pred = \"Text-Davinci-003\"\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd261985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the text for classification: In the heart of Gotham City, a shadowy figure emerges from the darkness, a symbol of justice and fear. With the weight of the city's crime pressing upon his shoulders, Batman confronts a mugger in a desolate alley, his gravelly voice commanding respect and fear. Swiftly dispatching the criminal, he retreats to the heights of Gotham's skyline, contemplating the never-ending battle against the city's corruption. Yet, fueled by Alfred's unwavering support and a newfound lead on a case, Batman reaffirms his commitment to bringing light to the darkness that plagues his beloved city, disappearing once more into the night, a silent guardian watching over Gotham's restless streets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cibhibaskar/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/cibhibaskar/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is predicted as: AI-generated\n",
      "The text is from: GPT-3.5 Large Language Model\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    word2vec_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "    \n",
    "    with open('binaryclf_rf.pkl', 'rb') as fileA:\n",
    "        rf_clf = pickle.load(fileA)\n",
    "\n",
    "    with open('mlp_pca.pkl', 'rb') as fileB:\n",
    "        pca = pickle.load(fileB)\n",
    "    \n",
    "    user_input_text = input(\"Enter the text for classification: \")\n",
    "    \n",
    "    BinaryPrediction = predict_text_classification(user_input_text, word2vec_model, pca, rf_clf) \n",
    "    \n",
    "    if BinaryPrediction == \"Human-written\":\n",
    "        \n",
    "        print(f\"The text is predicted as: {BinaryPrediction}\")\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        with open('multiclassclf_mlp.pkl', 'rb') as f:\n",
    "            mlp_clf = pickle.load(f)\n",
    "        \n",
    "        MultiClassPrediction = predict_text_classification_mc(user_input_text, word2vec_model, pca, mlp_clf)\n",
    "        \n",
    "        print(f\"The text is predicted as: {BinaryPrediction}\")\n",
    "\n",
    "        print(f\"The text is from: {MultiClassPrediction} Large Language Model\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e0a5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
