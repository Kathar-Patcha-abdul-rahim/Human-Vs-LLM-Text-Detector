{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8a55817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30361e6",
   "metadata": {},
   "source": [
    "# Processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bdb73d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>char_count</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Federal law supersedes state law, and cannabis...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>967</td>\n",
       "      <td>181</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>25.857143</td>\n",
       "      <td>57.30</td>\n",
       "      <td>967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035092</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>-0.041666</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.071304</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>0.004744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Miles feels restless after working all day. He...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>5068</td>\n",
       "      <td>924</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.661255</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>53.21</td>\n",
       "      <td>5068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003091</td>\n",
       "      <td>-0.043269</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.060853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>So first of I am danish. That means that I fol...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>1602</td>\n",
       "      <td>316</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.718354</td>\n",
       "      <td>22.571429</td>\n",
       "      <td>61.97</td>\n",
       "      <td>1602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.012316</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.005499</td>\n",
       "      <td>-0.011693</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>In this paper we present a novel rule-based ap...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>5469</td>\n",
       "      <td>1015</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.564532</td>\n",
       "      <td>40.600000</td>\n",
       "      <td>27.86</td>\n",
       "      <td>5469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018165</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>-0.006033</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>-0.019899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Most social progressives, love democracy, and ...</td>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>2379</td>\n",
       "      <td>437</td>\n",
       "      <td>Undefined</td>\n",
       "      <td>0.752860</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>61.67</td>\n",
       "      <td>2379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788917</th>\n",
       "      <td>788917</td>\n",
       "      <td>\\nIn the vast expanse of time, where the echoe...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>5523</td>\n",
       "      <td>951</td>\n",
       "      <td>The Ethics of De-extinction and Bringing Back ...</td>\n",
       "      <td>0.420610</td>\n",
       "      <td>28.818182</td>\n",
       "      <td>36.22</td>\n",
       "      <td>5523</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005222</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>-0.020148</td>\n",
       "      <td>-0.023085</td>\n",
       "      <td>-0.030199</td>\n",
       "      <td>-0.012152</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>-0.007202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788918</th>\n",
       "      <td>788918</td>\n",
       "      <td>\\nThe phenomenon of brain drain, particularly ...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>4540</td>\n",
       "      <td>761</td>\n",
       "      <td>The Economic and Social Consequences of Brain ...</td>\n",
       "      <td>0.395532</td>\n",
       "      <td>28.185185</td>\n",
       "      <td>29.08</td>\n",
       "      <td>4540</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006157</td>\n",
       "      <td>-0.023404</td>\n",
       "      <td>0.037557</td>\n",
       "      <td>0.026361</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.023823</td>\n",
       "      <td>-0.009165</td>\n",
       "      <td>-0.004096</td>\n",
       "      <td>-0.016606</td>\n",
       "      <td>0.020802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788919</th>\n",
       "      <td>788919</td>\n",
       "      <td>\\nThe Influence of Climate Change on Marine Ec...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>3889</td>\n",
       "      <td>670</td>\n",
       "      <td>The influence of climate change on marine ecos...</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>26.800000</td>\n",
       "      <td>47.22</td>\n",
       "      <td>3889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>-0.001044</td>\n",
       "      <td>-0.037097</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>0.039127</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.072912</td>\n",
       "      <td>-0.009205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788920</th>\n",
       "      <td>788920</td>\n",
       "      <td>\\nTitle: The Case for Limiting Car Usage: Navi...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>3560</td>\n",
       "      <td>592</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td>0.476351</td>\n",
       "      <td>28.190476</td>\n",
       "      <td>28.77</td>\n",
       "      <td>3560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.035284</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.023736</td>\n",
       "      <td>0.030208</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>-0.011754</td>\n",
       "      <td>-0.010964</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.014060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788921</th>\n",
       "      <td>788921</td>\n",
       "      <td>\\nIn the vast expanse of a globalized society,...</td>\n",
       "      <td>YI-34B</td>\n",
       "      <td>4563</td>\n",
       "      <td>786</td>\n",
       "      <td>The Importance of Intercultural Communication ...</td>\n",
       "      <td>0.404580</td>\n",
       "      <td>25.354839</td>\n",
       "      <td>31.82</td>\n",
       "      <td>4563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017204</td>\n",
       "      <td>-0.020792</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.019272</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>788922 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  \\\n",
       "0                0  Federal law supersedes state law, and cannabis...   \n",
       "1                1  Miles feels restless after working all day. He...   \n",
       "2                2  So first of I am danish. That means that I fol...   \n",
       "3                3  In this paper we present a novel rule-based ap...   \n",
       "4                4  Most social progressives, love democracy, and ...   \n",
       "...            ...                                                ...   \n",
       "788917      788917  \\nIn the vast expanse of time, where the echoe...   \n",
       "788918      788918  \\nThe phenomenon of brain drain, particularly ...   \n",
       "788919      788919  \\nThe Influence of Climate Change on Marine Ec...   \n",
       "788920      788920  \\nTitle: The Case for Limiting Car Usage: Navi...   \n",
       "788921      788921  \\nIn the vast expanse of a globalized society,...   \n",
       "\n",
       "          source  text_length  word_count  \\\n",
       "0       Bloom-7B          967         181   \n",
       "1       Bloom-7B         5068         924   \n",
       "2       Bloom-7B         1602         316   \n",
       "3       Bloom-7B         5469        1015   \n",
       "4       Bloom-7B         2379         437   \n",
       "...          ...          ...         ...   \n",
       "788917    YI-34B         5523         951   \n",
       "788918    YI-34B         4540         761   \n",
       "788919    YI-34B         3889         670   \n",
       "788920    YI-34B         3560         592   \n",
       "788921    YI-34B         4563         786   \n",
       "\n",
       "                                                   Prompt  lexical_diversity  \\\n",
       "0                                               Undefined           0.806630   \n",
       "1                                               Undefined           0.661255   \n",
       "2                                               Undefined           0.718354   \n",
       "3                                               Undefined           0.564532   \n",
       "4                                               Undefined           0.752860   \n",
       "...                                                   ...                ...   \n",
       "788917  The Ethics of De-extinction and Bringing Back ...           0.420610   \n",
       "788918  The Economic and Social Consequences of Brain ...           0.395532   \n",
       "788919  The influence of climate change on marine ecos...           0.447761   \n",
       "788920  Write an explanatory essay to inform fellow ci...           0.476351   \n",
       "788921  The Importance of Intercultural Communication ...           0.404580   \n",
       "\n",
       "        avg_sentence_length  readability_score  char_count  ...  embedding_40  \\\n",
       "0                 25.857143              57.30         967  ...     -0.035092   \n",
       "1                 23.100000              53.21        5068  ...     -0.003091   \n",
       "2                 22.571429              61.97        1602  ...      0.011013   \n",
       "3                 40.600000              27.86        5469  ...     -0.018165   \n",
       "4                 23.000000              61.67        2379  ...      0.004131   \n",
       "...                     ...                ...         ...  ...           ...   \n",
       "788917            28.818182              36.22        5523  ...     -0.005222   \n",
       "788918            28.185185              29.08        4540  ...     -0.006157   \n",
       "788919            26.800000              47.22        3889  ...      0.010574   \n",
       "788920            28.190476              28.77        3560  ...      0.013639   \n",
       "788921            25.354839              31.82        4563  ...      0.017204   \n",
       "\n",
       "        embedding_41  embedding_42  embedding_43  embedding_44  embedding_45  \\\n",
       "0          -0.001925     -0.041666     -0.005266      0.034543      0.002532   \n",
       "1          -0.043269      0.003721     -0.005574      0.030584     -0.006616   \n",
       "2          -0.008409      0.008066     -0.012316      0.007549     -0.000401   \n",
       "3           0.012030     -0.020475     -0.006033      0.002823     -0.000594   \n",
       "4           0.014534      0.007382     -0.016189      0.007070      0.001430   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "788917     -0.001365     -0.020148     -0.023085     -0.030199     -0.012152   \n",
       "788918     -0.023404      0.037557      0.026361     -0.008231      0.023823   \n",
       "788919     -0.008166      0.018903     -0.001044     -0.037097      0.025732   \n",
       "788920      0.035284      0.000662      0.023736      0.030208      0.013736   \n",
       "788921     -0.020792      0.003079      0.026649      0.001552      0.009237   \n",
       "\n",
       "        embedding_46  embedding_47  embedding_48  embedding_49  \n",
       "0          -0.071304      0.014727     -0.012865      0.004744  \n",
       "1           0.030465      0.000941      0.020913      0.060853  \n",
       "2          -0.001133     -0.005499     -0.011693      0.000179  \n",
       "3           0.000835      0.001109      0.009936     -0.019899  \n",
       "4          -0.017871      0.004868      0.010563      0.008097  \n",
       "...              ...           ...           ...           ...  \n",
       "788917      0.002733     -0.000128      0.022612     -0.007202  \n",
       "788918     -0.009165     -0.004096     -0.016606      0.020802  \n",
       "788919      0.039127      0.018915      0.072912     -0.009205  \n",
       "788920     -0.011754     -0.010964      0.000265      0.014060  \n",
       "788921      0.019272      0.000913      0.027279      0.002167  \n",
       "\n",
       "[788922 rows x 63 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('corpus.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b576db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>57.30</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.008560</td>\n",
       "      <td>0.095722</td>\n",
       "      <td>-0.049095</td>\n",
       "      <td>-0.118440</td>\n",
       "      <td>-0.004019</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035092</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>-0.041666</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.071304</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>0.004744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0.661255</td>\n",
       "      <td>53.21</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>-0.099866</td>\n",
       "      <td>0.107777</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>-0.063522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003091</td>\n",
       "      <td>-0.043269</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.060853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0.718354</td>\n",
       "      <td>61.97</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>0.164173</td>\n",
       "      <td>0.117847</td>\n",
       "      <td>-0.012992</td>\n",
       "      <td>0.088472</td>\n",
       "      <td>0.097658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.012316</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.005499</td>\n",
       "      <td>-0.011693</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0.564532</td>\n",
       "      <td>27.86</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.179447</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>0.155961</td>\n",
       "      <td>0.029293</td>\n",
       "      <td>0.099195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018165</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>-0.006033</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>-0.019899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0.752860</td>\n",
       "      <td>61.67</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>0.159706</td>\n",
       "      <td>0.083560</td>\n",
       "      <td>-0.074277</td>\n",
       "      <td>0.031704</td>\n",
       "      <td>0.066774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.008097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788917</th>\n",
       "      <td>YI-34B</td>\n",
       "      <td>0.420610</td>\n",
       "      <td>36.22</td>\n",
       "      <td>33</td>\n",
       "      <td>61</td>\n",
       "      <td>-0.157033</td>\n",
       "      <td>-0.008564</td>\n",
       "      <td>-0.079678</td>\n",
       "      <td>0.104863</td>\n",
       "      <td>-0.095362</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005222</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>-0.020148</td>\n",
       "      <td>-0.023085</td>\n",
       "      <td>-0.030199</td>\n",
       "      <td>-0.012152</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>-0.007202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788918</th>\n",
       "      <td>YI-34B</td>\n",
       "      <td>0.395532</td>\n",
       "      <td>29.08</td>\n",
       "      <td>27</td>\n",
       "      <td>66</td>\n",
       "      <td>-0.282313</td>\n",
       "      <td>0.034885</td>\n",
       "      <td>-0.078380</td>\n",
       "      <td>-0.014602</td>\n",
       "      <td>-0.034506</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006157</td>\n",
       "      <td>-0.023404</td>\n",
       "      <td>0.037557</td>\n",
       "      <td>0.026361</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.023823</td>\n",
       "      <td>-0.009165</td>\n",
       "      <td>-0.004096</td>\n",
       "      <td>-0.016606</td>\n",
       "      <td>0.020802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788919</th>\n",
       "      <td>YI-34B</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>47.22</td>\n",
       "      <td>25</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.264905</td>\n",
       "      <td>-0.011840</td>\n",
       "      <td>0.106972</td>\n",
       "      <td>0.034591</td>\n",
       "      <td>-0.192508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>-0.001044</td>\n",
       "      <td>-0.037097</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>0.039127</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.072912</td>\n",
       "      <td>-0.009205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788920</th>\n",
       "      <td>YI-34B</td>\n",
       "      <td>0.476351</td>\n",
       "      <td>28.77</td>\n",
       "      <td>21</td>\n",
       "      <td>512</td>\n",
       "      <td>-0.263766</td>\n",
       "      <td>0.064379</td>\n",
       "      <td>-0.021544</td>\n",
       "      <td>-0.112702</td>\n",
       "      <td>-0.044006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.035284</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.023736</td>\n",
       "      <td>0.030208</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>-0.011754</td>\n",
       "      <td>-0.010964</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.014060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788921</th>\n",
       "      <td>YI-34B</td>\n",
       "      <td>0.404580</td>\n",
       "      <td>31.82</td>\n",
       "      <td>31</td>\n",
       "      <td>67</td>\n",
       "      <td>-0.193548</td>\n",
       "      <td>0.069151</td>\n",
       "      <td>-0.109348</td>\n",
       "      <td>0.181288</td>\n",
       "      <td>-0.049860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017204</td>\n",
       "      <td>-0.020792</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.019272</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>0.002167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>788922 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          source  lexical_diversity  readability_score  sentence_count  \\\n",
       "0       Bloom-7B           0.806630              57.30               7   \n",
       "1       Bloom-7B           0.661255              53.21              40   \n",
       "2       Bloom-7B           0.718354              61.97              14   \n",
       "3       Bloom-7B           0.564532              27.86              25   \n",
       "4       Bloom-7B           0.752860              61.67              19   \n",
       "...          ...                ...                ...             ...   \n",
       "788917    YI-34B           0.420610              36.22              33   \n",
       "788918    YI-34B           0.395532              29.08              27   \n",
       "788919    YI-34B           0.447761              47.22              25   \n",
       "788920    YI-34B           0.476351              28.77              21   \n",
       "788921    YI-34B           0.404580              31.82              31   \n",
       "\n",
       "        prompt_length  embedding_0  embedding_1  embedding_2  embedding_3  \\\n",
       "0                   9     0.008560     0.095722    -0.049095    -0.118440   \n",
       "1                   9     0.070761    -0.099866     0.107777     0.008168   \n",
       "2                   9     0.164173     0.117847    -0.012992     0.088472   \n",
       "3                   9    -0.179447     0.010308     0.155961     0.029293   \n",
       "4                   9     0.159706     0.083560    -0.074277     0.031704   \n",
       "...               ...          ...          ...          ...          ...   \n",
       "788917             61    -0.157033    -0.008564    -0.079678     0.104863   \n",
       "788918             66    -0.282313     0.034885    -0.078380    -0.014602   \n",
       "788919             52    -0.264905    -0.011840     0.106972     0.034591   \n",
       "788920            512    -0.263766     0.064379    -0.021544    -0.112702   \n",
       "788921             67    -0.193548     0.069151    -0.109348     0.181288   \n",
       "\n",
       "        embedding_4  ...  embedding_40  embedding_41  embedding_42  \\\n",
       "0         -0.004019  ...     -0.035092     -0.001925     -0.041666   \n",
       "1         -0.063522  ...     -0.003091     -0.043269      0.003721   \n",
       "2          0.097658  ...      0.011013     -0.008409      0.008066   \n",
       "3          0.099195  ...     -0.018165      0.012030     -0.020475   \n",
       "4          0.066774  ...      0.004131      0.014534      0.007382   \n",
       "...             ...  ...           ...           ...           ...   \n",
       "788917    -0.095362  ...     -0.005222     -0.001365     -0.020148   \n",
       "788918    -0.034506  ...     -0.006157     -0.023404      0.037557   \n",
       "788919    -0.192508  ...      0.010574     -0.008166      0.018903   \n",
       "788920    -0.044006  ...      0.013639      0.035284      0.000662   \n",
       "788921    -0.049860  ...      0.017204     -0.020792      0.003079   \n",
       "\n",
       "        embedding_43  embedding_44  embedding_45  embedding_46  embedding_47  \\\n",
       "0          -0.005266      0.034543      0.002532     -0.071304      0.014727   \n",
       "1          -0.005574      0.030584     -0.006616      0.030465      0.000941   \n",
       "2          -0.012316      0.007549     -0.000401     -0.001133     -0.005499   \n",
       "3          -0.006033      0.002823     -0.000594      0.000835      0.001109   \n",
       "4          -0.016189      0.007070      0.001430     -0.017871      0.004868   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "788917     -0.023085     -0.030199     -0.012152      0.002733     -0.000128   \n",
       "788918      0.026361     -0.008231      0.023823     -0.009165     -0.004096   \n",
       "788919     -0.001044     -0.037097      0.025732      0.039127      0.018915   \n",
       "788920      0.023736      0.030208      0.013736     -0.011754     -0.010964   \n",
       "788921      0.026649      0.001552      0.009237      0.019272      0.000913   \n",
       "\n",
       "        embedding_48  embedding_49  \n",
       "0          -0.012865      0.004744  \n",
       "1           0.020913      0.060853  \n",
       "2          -0.011693      0.000179  \n",
       "3           0.009936     -0.019899  \n",
       "4           0.010563      0.008097  \n",
       "...              ...           ...  \n",
       "788917      0.022612     -0.007202  \n",
       "788918     -0.016606      0.020802  \n",
       "788919      0.072912     -0.009205  \n",
       "788920      0.000265      0.014060  \n",
       "788921      0.027279      0.002167  \n",
       "\n",
       "[788922 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(['Unnamed: 0', 'text', 'text_length', 'word_count', 'Prompt', 'avg_sentence_length', 'classification', 'char_count'], axis=1, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74d58daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1adee695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode = LabelEncoder()\n",
    "encode.fit(data['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9525ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 62, 62, 62])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedSource = encode.transform(data['source'])\n",
    "encodedSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67a3c343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "          ..\n",
       "788917    62\n",
       "788918    62\n",
       "788919    62\n",
       "788920    62\n",
       "788921    62\n",
       "Length: 788922, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataSeries = pd.Series(encodedSource)\n",
    "dataSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2dda305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "      <th>sourceEncoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>57.30</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.008560</td>\n",
       "      <td>0.095722</td>\n",
       "      <td>-0.049095</td>\n",
       "      <td>-0.118440</td>\n",
       "      <td>-0.004019</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>-0.041666</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.071304</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0.661255</td>\n",
       "      <td>53.21</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>-0.099866</td>\n",
       "      <td>0.107777</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>-0.063522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043269</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.060853</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0.718354</td>\n",
       "      <td>61.97</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>0.164173</td>\n",
       "      <td>0.117847</td>\n",
       "      <td>-0.012992</td>\n",
       "      <td>0.088472</td>\n",
       "      <td>0.097658</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.012316</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.005499</td>\n",
       "      <td>-0.011693</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0.564532</td>\n",
       "      <td>27.86</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.179447</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>0.155961</td>\n",
       "      <td>0.029293</td>\n",
       "      <td>0.099195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>-0.006033</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>-0.019899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bloom-7B</td>\n",
       "      <td>0.752860</td>\n",
       "      <td>61.67</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>0.159706</td>\n",
       "      <td>0.083560</td>\n",
       "      <td>-0.074277</td>\n",
       "      <td>0.031704</td>\n",
       "      <td>0.066774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.008097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788917</th>\n",
       "      <td>YI-34B</td>\n",
       "      <td>0.420610</td>\n",
       "      <td>36.22</td>\n",
       "      <td>33</td>\n",
       "      <td>61</td>\n",
       "      <td>-0.157033</td>\n",
       "      <td>-0.008564</td>\n",
       "      <td>-0.079678</td>\n",
       "      <td>0.104863</td>\n",
       "      <td>-0.095362</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>-0.020148</td>\n",
       "      <td>-0.023085</td>\n",
       "      <td>-0.030199</td>\n",
       "      <td>-0.012152</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>-0.007202</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788918</th>\n",
       "      <td>YI-34B</td>\n",
       "      <td>0.395532</td>\n",
       "      <td>29.08</td>\n",
       "      <td>27</td>\n",
       "      <td>66</td>\n",
       "      <td>-0.282313</td>\n",
       "      <td>0.034885</td>\n",
       "      <td>-0.078380</td>\n",
       "      <td>-0.014602</td>\n",
       "      <td>-0.034506</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023404</td>\n",
       "      <td>0.037557</td>\n",
       "      <td>0.026361</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.023823</td>\n",
       "      <td>-0.009165</td>\n",
       "      <td>-0.004096</td>\n",
       "      <td>-0.016606</td>\n",
       "      <td>0.020802</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788919</th>\n",
       "      <td>YI-34B</td>\n",
       "      <td>0.447761</td>\n",
       "      <td>47.22</td>\n",
       "      <td>25</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.264905</td>\n",
       "      <td>-0.011840</td>\n",
       "      <td>0.106972</td>\n",
       "      <td>0.034591</td>\n",
       "      <td>-0.192508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>-0.001044</td>\n",
       "      <td>-0.037097</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>0.039127</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.072912</td>\n",
       "      <td>-0.009205</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788920</th>\n",
       "      <td>YI-34B</td>\n",
       "      <td>0.476351</td>\n",
       "      <td>28.77</td>\n",
       "      <td>21</td>\n",
       "      <td>512</td>\n",
       "      <td>-0.263766</td>\n",
       "      <td>0.064379</td>\n",
       "      <td>-0.021544</td>\n",
       "      <td>-0.112702</td>\n",
       "      <td>-0.044006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035284</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.023736</td>\n",
       "      <td>0.030208</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>-0.011754</td>\n",
       "      <td>-0.010964</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.014060</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788921</th>\n",
       "      <td>YI-34B</td>\n",
       "      <td>0.404580</td>\n",
       "      <td>31.82</td>\n",
       "      <td>31</td>\n",
       "      <td>67</td>\n",
       "      <td>-0.193548</td>\n",
       "      <td>0.069151</td>\n",
       "      <td>-0.109348</td>\n",
       "      <td>0.181288</td>\n",
       "      <td>-0.049860</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020792</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.019272</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>788922 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          source  lexical_diversity  readability_score  sentence_count  \\\n",
       "0       Bloom-7B           0.806630              57.30               7   \n",
       "1       Bloom-7B           0.661255              53.21              40   \n",
       "2       Bloom-7B           0.718354              61.97              14   \n",
       "3       Bloom-7B           0.564532              27.86              25   \n",
       "4       Bloom-7B           0.752860              61.67              19   \n",
       "...          ...                ...                ...             ...   \n",
       "788917    YI-34B           0.420610              36.22              33   \n",
       "788918    YI-34B           0.395532              29.08              27   \n",
       "788919    YI-34B           0.447761              47.22              25   \n",
       "788920    YI-34B           0.476351              28.77              21   \n",
       "788921    YI-34B           0.404580              31.82              31   \n",
       "\n",
       "        prompt_length  embedding_0  embedding_1  embedding_2  embedding_3  \\\n",
       "0                   9     0.008560     0.095722    -0.049095    -0.118440   \n",
       "1                   9     0.070761    -0.099866     0.107777     0.008168   \n",
       "2                   9     0.164173     0.117847    -0.012992     0.088472   \n",
       "3                   9    -0.179447     0.010308     0.155961     0.029293   \n",
       "4                   9     0.159706     0.083560    -0.074277     0.031704   \n",
       "...               ...          ...          ...          ...          ...   \n",
       "788917             61    -0.157033    -0.008564    -0.079678     0.104863   \n",
       "788918             66    -0.282313     0.034885    -0.078380    -0.014602   \n",
       "788919             52    -0.264905    -0.011840     0.106972     0.034591   \n",
       "788920            512    -0.263766     0.064379    -0.021544    -0.112702   \n",
       "788921             67    -0.193548     0.069151    -0.109348     0.181288   \n",
       "\n",
       "        embedding_4  ...  embedding_41  embedding_42  embedding_43  \\\n",
       "0         -0.004019  ...     -0.001925     -0.041666     -0.005266   \n",
       "1         -0.063522  ...     -0.043269      0.003721     -0.005574   \n",
       "2          0.097658  ...     -0.008409      0.008066     -0.012316   \n",
       "3          0.099195  ...      0.012030     -0.020475     -0.006033   \n",
       "4          0.066774  ...      0.014534      0.007382     -0.016189   \n",
       "...             ...  ...           ...           ...           ...   \n",
       "788917    -0.095362  ...     -0.001365     -0.020148     -0.023085   \n",
       "788918    -0.034506  ...     -0.023404      0.037557      0.026361   \n",
       "788919    -0.192508  ...     -0.008166      0.018903     -0.001044   \n",
       "788920    -0.044006  ...      0.035284      0.000662      0.023736   \n",
       "788921    -0.049860  ...     -0.020792      0.003079      0.026649   \n",
       "\n",
       "        embedding_44  embedding_45  embedding_46  embedding_47  embedding_48  \\\n",
       "0           0.034543      0.002532     -0.071304      0.014727     -0.012865   \n",
       "1           0.030584     -0.006616      0.030465      0.000941      0.020913   \n",
       "2           0.007549     -0.000401     -0.001133     -0.005499     -0.011693   \n",
       "3           0.002823     -0.000594      0.000835      0.001109      0.009936   \n",
       "4           0.007070      0.001430     -0.017871      0.004868      0.010563   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "788917     -0.030199     -0.012152      0.002733     -0.000128      0.022612   \n",
       "788918     -0.008231      0.023823     -0.009165     -0.004096     -0.016606   \n",
       "788919     -0.037097      0.025732      0.039127      0.018915      0.072912   \n",
       "788920      0.030208      0.013736     -0.011754     -0.010964      0.000265   \n",
       "788921      0.001552      0.009237      0.019272      0.000913      0.027279   \n",
       "\n",
       "        embedding_49  sourceEncoded  \n",
       "0           0.004744              0  \n",
       "1           0.060853              0  \n",
       "2           0.000179              0  \n",
       "3          -0.019899              0  \n",
       "4           0.008097              0  \n",
       "...              ...            ...  \n",
       "788917     -0.007202             62  \n",
       "788918      0.020802             62  \n",
       "788919     -0.009205             62  \n",
       "788920      0.014060             62  \n",
       "788921      0.002167             62  \n",
       "\n",
       "[788922 rows x 56 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sourceEncoded'] = dataSeries\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e3cb65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th>sourceEncoded</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bloom-7B</th>\n",
       "      <th>0</th>\n",
       "      <td>8812</td>\n",
       "      <td>8812</td>\n",
       "      <td>8812</td>\n",
       "      <td>8812</td>\n",
       "      <td>8812</td>\n",
       "      <td>8812</td>\n",
       "      <td>8812</td>\n",
       "      <td>8812</td>\n",
       "      <td>8812</td>\n",
       "      <td>8812</td>\n",
       "      <td>...</td>\n",
       "      <td>8812</td>\n",
       "      <td>8812</td>\n",
       "      <td>8812</td>\n",
       "      <td>8812</td>\n",
       "      <td>8812</td>\n",
       "      <td>8812</td>\n",
       "      <td>8812</td>\n",
       "      <td>8812</td>\n",
       "      <td>8812</td>\n",
       "      <td>8812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claude-Instant-v1</th>\n",
       "      <th>1</th>\n",
       "      <td>7147</td>\n",
       "      <td>7147</td>\n",
       "      <td>7147</td>\n",
       "      <td>7147</td>\n",
       "      <td>7147</td>\n",
       "      <td>7147</td>\n",
       "      <td>7147</td>\n",
       "      <td>7147</td>\n",
       "      <td>7147</td>\n",
       "      <td>7147</td>\n",
       "      <td>...</td>\n",
       "      <td>7147</td>\n",
       "      <td>7147</td>\n",
       "      <td>7147</td>\n",
       "      <td>7147</td>\n",
       "      <td>7147</td>\n",
       "      <td>7147</td>\n",
       "      <td>7147</td>\n",
       "      <td>7147</td>\n",
       "      <td>7147</td>\n",
       "      <td>7147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claude-v1</th>\n",
       "      <th>2</th>\n",
       "      <td>3158</td>\n",
       "      <td>3158</td>\n",
       "      <td>3158</td>\n",
       "      <td>3158</td>\n",
       "      <td>3158</td>\n",
       "      <td>3158</td>\n",
       "      <td>3158</td>\n",
       "      <td>3158</td>\n",
       "      <td>3158</td>\n",
       "      <td>3158</td>\n",
       "      <td>...</td>\n",
       "      <td>3158</td>\n",
       "      <td>3158</td>\n",
       "      <td>3158</td>\n",
       "      <td>3158</td>\n",
       "      <td>3158</td>\n",
       "      <td>3158</td>\n",
       "      <td>3158</td>\n",
       "      <td>3158</td>\n",
       "      <td>3158</td>\n",
       "      <td>3158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohere-Command</th>\n",
       "      <th>3</th>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>...</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dolphin-2.5-Mixtral-8x7B</th>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>...</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dolphin-Mixtral-8x7B</th>\n",
       "      <th>5</th>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>...</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Falcon-180B</th>\n",
       "      <th>6</th>\n",
       "      <td>4745</td>\n",
       "      <td>4745</td>\n",
       "      <td>4745</td>\n",
       "      <td>4745</td>\n",
       "      <td>4745</td>\n",
       "      <td>4745</td>\n",
       "      <td>4745</td>\n",
       "      <td>4745</td>\n",
       "      <td>4745</td>\n",
       "      <td>4745</td>\n",
       "      <td>...</td>\n",
       "      <td>4745</td>\n",
       "      <td>4745</td>\n",
       "      <td>4745</td>\n",
       "      <td>4745</td>\n",
       "      <td>4745</td>\n",
       "      <td>4745</td>\n",
       "      <td>4745</td>\n",
       "      <td>4745</td>\n",
       "      <td>4745</td>\n",
       "      <td>4745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flan-T5-Base</th>\n",
       "      <th>7</th>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>...</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "      <td>9201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flan-T5-Large</th>\n",
       "      <th>8</th>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>...</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "      <td>9164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flan-T5-Small</th>\n",
       "      <th>9</th>\n",
       "      <td>9144</td>\n",
       "      <td>9144</td>\n",
       "      <td>9144</td>\n",
       "      <td>9144</td>\n",
       "      <td>9144</td>\n",
       "      <td>9144</td>\n",
       "      <td>9144</td>\n",
       "      <td>9144</td>\n",
       "      <td>9144</td>\n",
       "      <td>9144</td>\n",
       "      <td>...</td>\n",
       "      <td>9144</td>\n",
       "      <td>9144</td>\n",
       "      <td>9144</td>\n",
       "      <td>9144</td>\n",
       "      <td>9144</td>\n",
       "      <td>9144</td>\n",
       "      <td>9144</td>\n",
       "      <td>9144</td>\n",
       "      <td>9144</td>\n",
       "      <td>9144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flan-T5-XL</th>\n",
       "      <th>10</th>\n",
       "      <td>8986</td>\n",
       "      <td>8986</td>\n",
       "      <td>8986</td>\n",
       "      <td>8986</td>\n",
       "      <td>8986</td>\n",
       "      <td>8986</td>\n",
       "      <td>8986</td>\n",
       "      <td>8986</td>\n",
       "      <td>8986</td>\n",
       "      <td>8986</td>\n",
       "      <td>...</td>\n",
       "      <td>8986</td>\n",
       "      <td>8986</td>\n",
       "      <td>8986</td>\n",
       "      <td>8986</td>\n",
       "      <td>8986</td>\n",
       "      <td>8986</td>\n",
       "      <td>8986</td>\n",
       "      <td>8986</td>\n",
       "      <td>8986</td>\n",
       "      <td>8986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flan-T5-XXL</th>\n",
       "      <th>11</th>\n",
       "      <td>9113</td>\n",
       "      <td>9113</td>\n",
       "      <td>9113</td>\n",
       "      <td>9113</td>\n",
       "      <td>9113</td>\n",
       "      <td>9113</td>\n",
       "      <td>9113</td>\n",
       "      <td>9113</td>\n",
       "      <td>9113</td>\n",
       "      <td>9113</td>\n",
       "      <td>...</td>\n",
       "      <td>9113</td>\n",
       "      <td>9113</td>\n",
       "      <td>9113</td>\n",
       "      <td>9113</td>\n",
       "      <td>9113</td>\n",
       "      <td>9113</td>\n",
       "      <td>9113</td>\n",
       "      <td>9113</td>\n",
       "      <td>9113</td>\n",
       "      <td>9113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLM-130B</th>\n",
       "      <th>12</th>\n",
       "      <td>9071</td>\n",
       "      <td>9071</td>\n",
       "      <td>9071</td>\n",
       "      <td>9071</td>\n",
       "      <td>9071</td>\n",
       "      <td>9071</td>\n",
       "      <td>9071</td>\n",
       "      <td>9071</td>\n",
       "      <td>9071</td>\n",
       "      <td>9071</td>\n",
       "      <td>...</td>\n",
       "      <td>9071</td>\n",
       "      <td>9071</td>\n",
       "      <td>9071</td>\n",
       "      <td>9071</td>\n",
       "      <td>9071</td>\n",
       "      <td>9071</td>\n",
       "      <td>9071</td>\n",
       "      <td>9071</td>\n",
       "      <td>9071</td>\n",
       "      <td>9071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-3.5</th>\n",
       "      <th>13</th>\n",
       "      <td>52346</td>\n",
       "      <td>52346</td>\n",
       "      <td>52346</td>\n",
       "      <td>52346</td>\n",
       "      <td>52346</td>\n",
       "      <td>52346</td>\n",
       "      <td>52346</td>\n",
       "      <td>52346</td>\n",
       "      <td>52346</td>\n",
       "      <td>52346</td>\n",
       "      <td>...</td>\n",
       "      <td>52346</td>\n",
       "      <td>52346</td>\n",
       "      <td>52346</td>\n",
       "      <td>52346</td>\n",
       "      <td>52346</td>\n",
       "      <td>52346</td>\n",
       "      <td>52346</td>\n",
       "      <td>52346</td>\n",
       "      <td>52346</td>\n",
       "      <td>52346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-4</th>\n",
       "      <th>14</th>\n",
       "      <td>8852</td>\n",
       "      <td>8852</td>\n",
       "      <td>8852</td>\n",
       "      <td>8852</td>\n",
       "      <td>8852</td>\n",
       "      <td>8852</td>\n",
       "      <td>8852</td>\n",
       "      <td>8852</td>\n",
       "      <td>8852</td>\n",
       "      <td>8852</td>\n",
       "      <td>...</td>\n",
       "      <td>8852</td>\n",
       "      <td>8852</td>\n",
       "      <td>8852</td>\n",
       "      <td>8852</td>\n",
       "      <td>8852</td>\n",
       "      <td>8852</td>\n",
       "      <td>8852</td>\n",
       "      <td>8852</td>\n",
       "      <td>8852</td>\n",
       "      <td>8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-J</th>\n",
       "      <th>15</th>\n",
       "      <td>7580</td>\n",
       "      <td>7580</td>\n",
       "      <td>7580</td>\n",
       "      <td>7580</td>\n",
       "      <td>7580</td>\n",
       "      <td>7580</td>\n",
       "      <td>7580</td>\n",
       "      <td>7580</td>\n",
       "      <td>7580</td>\n",
       "      <td>7580</td>\n",
       "      <td>...</td>\n",
       "      <td>7580</td>\n",
       "      <td>7580</td>\n",
       "      <td>7580</td>\n",
       "      <td>7580</td>\n",
       "      <td>7580</td>\n",
       "      <td>7580</td>\n",
       "      <td>7580</td>\n",
       "      <td>7580</td>\n",
       "      <td>7580</td>\n",
       "      <td>7580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT-NeoX</th>\n",
       "      <th>16</th>\n",
       "      <td>6821</td>\n",
       "      <td>6821</td>\n",
       "      <td>6821</td>\n",
       "      <td>6821</td>\n",
       "      <td>6821</td>\n",
       "      <td>6821</td>\n",
       "      <td>6821</td>\n",
       "      <td>6821</td>\n",
       "      <td>6821</td>\n",
       "      <td>6821</td>\n",
       "      <td>...</td>\n",
       "      <td>6821</td>\n",
       "      <td>6821</td>\n",
       "      <td>6821</td>\n",
       "      <td>6821</td>\n",
       "      <td>6821</td>\n",
       "      <td>6821</td>\n",
       "      <td>6821</td>\n",
       "      <td>6821</td>\n",
       "      <td>6821</td>\n",
       "      <td>6821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gemini-Pro</th>\n",
       "      <th>17</th>\n",
       "      <td>613</td>\n",
       "      <td>613</td>\n",
       "      <td>613</td>\n",
       "      <td>613</td>\n",
       "      <td>613</td>\n",
       "      <td>613</td>\n",
       "      <td>613</td>\n",
       "      <td>613</td>\n",
       "      <td>613</td>\n",
       "      <td>613</td>\n",
       "      <td>...</td>\n",
       "      <td>613</td>\n",
       "      <td>613</td>\n",
       "      <td>613</td>\n",
       "      <td>613</td>\n",
       "      <td>613</td>\n",
       "      <td>613</td>\n",
       "      <td>613</td>\n",
       "      <td>613</td>\n",
       "      <td>613</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goliath-120B</th>\n",
       "      <th>18</th>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "      <td>...</td>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Human</th>\n",
       "      <th>19</th>\n",
       "      <td>347692</td>\n",
       "      <td>347692</td>\n",
       "      <td>347692</td>\n",
       "      <td>347692</td>\n",
       "      <td>347692</td>\n",
       "      <td>347692</td>\n",
       "      <td>347692</td>\n",
       "      <td>347692</td>\n",
       "      <td>347692</td>\n",
       "      <td>347692</td>\n",
       "      <td>...</td>\n",
       "      <td>347692</td>\n",
       "      <td>347692</td>\n",
       "      <td>347692</td>\n",
       "      <td>347692</td>\n",
       "      <td>347692</td>\n",
       "      <td>347692</td>\n",
       "      <td>347692</td>\n",
       "      <td>347692</td>\n",
       "      <td>347692</td>\n",
       "      <td>347692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLaMA-13B</th>\n",
       "      <th>20</th>\n",
       "      <td>9282</td>\n",
       "      <td>9282</td>\n",
       "      <td>9282</td>\n",
       "      <td>9282</td>\n",
       "      <td>9282</td>\n",
       "      <td>9282</td>\n",
       "      <td>9282</td>\n",
       "      <td>9282</td>\n",
       "      <td>9282</td>\n",
       "      <td>9282</td>\n",
       "      <td>...</td>\n",
       "      <td>9282</td>\n",
       "      <td>9282</td>\n",
       "      <td>9282</td>\n",
       "      <td>9282</td>\n",
       "      <td>9282</td>\n",
       "      <td>9282</td>\n",
       "      <td>9282</td>\n",
       "      <td>9282</td>\n",
       "      <td>9282</td>\n",
       "      <td>9282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLaMA-2-70B</th>\n",
       "      <th>21</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>...</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLaMA-2-7B</th>\n",
       "      <th>22</th>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>...</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLaMA-30B</th>\n",
       "      <th>23</th>\n",
       "      <td>9340</td>\n",
       "      <td>9340</td>\n",
       "      <td>9340</td>\n",
       "      <td>9340</td>\n",
       "      <td>9340</td>\n",
       "      <td>9340</td>\n",
       "      <td>9340</td>\n",
       "      <td>9340</td>\n",
       "      <td>9340</td>\n",
       "      <td>9340</td>\n",
       "      <td>...</td>\n",
       "      <td>9340</td>\n",
       "      <td>9340</td>\n",
       "      <td>9340</td>\n",
       "      <td>9340</td>\n",
       "      <td>9340</td>\n",
       "      <td>9340</td>\n",
       "      <td>9340</td>\n",
       "      <td>9340</td>\n",
       "      <td>9340</td>\n",
       "      <td>9340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLaMA-65B</th>\n",
       "      <th>24</th>\n",
       "      <td>9321</td>\n",
       "      <td>9321</td>\n",
       "      <td>9321</td>\n",
       "      <td>9321</td>\n",
       "      <td>9321</td>\n",
       "      <td>9321</td>\n",
       "      <td>9321</td>\n",
       "      <td>9321</td>\n",
       "      <td>9321</td>\n",
       "      <td>9321</td>\n",
       "      <td>...</td>\n",
       "      <td>9321</td>\n",
       "      <td>9321</td>\n",
       "      <td>9321</td>\n",
       "      <td>9321</td>\n",
       "      <td>9321</td>\n",
       "      <td>9321</td>\n",
       "      <td>9321</td>\n",
       "      <td>9321</td>\n",
       "      <td>9321</td>\n",
       "      <td>9321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLaMA-7B</th>\n",
       "      <th>25</th>\n",
       "      <td>9271</td>\n",
       "      <td>9271</td>\n",
       "      <td>9271</td>\n",
       "      <td>9271</td>\n",
       "      <td>9271</td>\n",
       "      <td>9271</td>\n",
       "      <td>9271</td>\n",
       "      <td>9271</td>\n",
       "      <td>9271</td>\n",
       "      <td>9271</td>\n",
       "      <td>...</td>\n",
       "      <td>9271</td>\n",
       "      <td>9271</td>\n",
       "      <td>9271</td>\n",
       "      <td>9271</td>\n",
       "      <td>9271</td>\n",
       "      <td>9271</td>\n",
       "      <td>9271</td>\n",
       "      <td>9271</td>\n",
       "      <td>9271</td>\n",
       "      <td>9271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LZLV-70B</th>\n",
       "      <th>26</th>\n",
       "      <td>5143</td>\n",
       "      <td>5143</td>\n",
       "      <td>5143</td>\n",
       "      <td>5143</td>\n",
       "      <td>5143</td>\n",
       "      <td>5143</td>\n",
       "      <td>5143</td>\n",
       "      <td>5143</td>\n",
       "      <td>5143</td>\n",
       "      <td>5143</td>\n",
       "      <td>...</td>\n",
       "      <td>5143</td>\n",
       "      <td>5143</td>\n",
       "      <td>5143</td>\n",
       "      <td>5143</td>\n",
       "      <td>5143</td>\n",
       "      <td>5143</td>\n",
       "      <td>5143</td>\n",
       "      <td>5143</td>\n",
       "      <td>5143</td>\n",
       "      <td>5143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B</th>\n",
       "      <th>27</th>\n",
       "      <td>10439</td>\n",
       "      <td>10439</td>\n",
       "      <td>10439</td>\n",
       "      <td>10439</td>\n",
       "      <td>10439</td>\n",
       "      <td>10439</td>\n",
       "      <td>10439</td>\n",
       "      <td>10439</td>\n",
       "      <td>10439</td>\n",
       "      <td>10439</td>\n",
       "      <td>...</td>\n",
       "      <td>10439</td>\n",
       "      <td>10439</td>\n",
       "      <td>10439</td>\n",
       "      <td>10439</td>\n",
       "      <td>10439</td>\n",
       "      <td>10439</td>\n",
       "      <td>10439</td>\n",
       "      <td>10439</td>\n",
       "      <td>10439</td>\n",
       "      <td>10439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-OpenOrca</th>\n",
       "      <th>28</th>\n",
       "      <td>3058</td>\n",
       "      <td>3058</td>\n",
       "      <td>3058</td>\n",
       "      <td>3058</td>\n",
       "      <td>3058</td>\n",
       "      <td>3058</td>\n",
       "      <td>3058</td>\n",
       "      <td>3058</td>\n",
       "      <td>3058</td>\n",
       "      <td>3058</td>\n",
       "      <td>...</td>\n",
       "      <td>3058</td>\n",
       "      <td>3058</td>\n",
       "      <td>3058</td>\n",
       "      <td>3058</td>\n",
       "      <td>3058</td>\n",
       "      <td>3058</td>\n",
       "      <td>3058</td>\n",
       "      <td>3058</td>\n",
       "      <td>3058</td>\n",
       "      <td>3058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixtral-8x7B</th>\n",
       "      <th>29</th>\n",
       "      <td>2865</td>\n",
       "      <td>2865</td>\n",
       "      <td>2865</td>\n",
       "      <td>2865</td>\n",
       "      <td>2865</td>\n",
       "      <td>2865</td>\n",
       "      <td>2865</td>\n",
       "      <td>2865</td>\n",
       "      <td>2865</td>\n",
       "      <td>2865</td>\n",
       "      <td>...</td>\n",
       "      <td>2865</td>\n",
       "      <td>2865</td>\n",
       "      <td>2865</td>\n",
       "      <td>2865</td>\n",
       "      <td>2865</td>\n",
       "      <td>2865</td>\n",
       "      <td>2865</td>\n",
       "      <td>2865</td>\n",
       "      <td>2865</td>\n",
       "      <td>2865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MythoMax-L2-13B</th>\n",
       "      <th>30</th>\n",
       "      <td>6147</td>\n",
       "      <td>6147</td>\n",
       "      <td>6147</td>\n",
       "      <td>6147</td>\n",
       "      <td>6147</td>\n",
       "      <td>6147</td>\n",
       "      <td>6147</td>\n",
       "      <td>6147</td>\n",
       "      <td>6147</td>\n",
       "      <td>6147</td>\n",
       "      <td>...</td>\n",
       "      <td>6147</td>\n",
       "      <td>6147</td>\n",
       "      <td>6147</td>\n",
       "      <td>6147</td>\n",
       "      <td>6147</td>\n",
       "      <td>6147</td>\n",
       "      <td>6147</td>\n",
       "      <td>6147</td>\n",
       "      <td>6147</td>\n",
       "      <td>6147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural-Chat-7B</th>\n",
       "      <th>31</th>\n",
       "      <td>5858</td>\n",
       "      <td>5858</td>\n",
       "      <td>5858</td>\n",
       "      <td>5858</td>\n",
       "      <td>5858</td>\n",
       "      <td>5858</td>\n",
       "      <td>5858</td>\n",
       "      <td>5858</td>\n",
       "      <td>5858</td>\n",
       "      <td>5858</td>\n",
       "      <td>...</td>\n",
       "      <td>5858</td>\n",
       "      <td>5858</td>\n",
       "      <td>5858</td>\n",
       "      <td>5858</td>\n",
       "      <td>5858</td>\n",
       "      <td>5858</td>\n",
       "      <td>5858</td>\n",
       "      <td>5858</td>\n",
       "      <td>5858</td>\n",
       "      <td>5858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Noromaid-20B</th>\n",
       "      <th>32</th>\n",
       "      <td>1326</td>\n",
       "      <td>1326</td>\n",
       "      <td>1326</td>\n",
       "      <td>1326</td>\n",
       "      <td>1326</td>\n",
       "      <td>1326</td>\n",
       "      <td>1326</td>\n",
       "      <td>1326</td>\n",
       "      <td>1326</td>\n",
       "      <td>1326</td>\n",
       "      <td>...</td>\n",
       "      <td>1326</td>\n",
       "      <td>1326</td>\n",
       "      <td>1326</td>\n",
       "      <td>1326</td>\n",
       "      <td>1326</td>\n",
       "      <td>1326</td>\n",
       "      <td>1326</td>\n",
       "      <td>1326</td>\n",
       "      <td>1326</td>\n",
       "      <td>1326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nous-Capybara-34B</th>\n",
       "      <th>33</th>\n",
       "      <td>3327</td>\n",
       "      <td>3327</td>\n",
       "      <td>3327</td>\n",
       "      <td>3327</td>\n",
       "      <td>3327</td>\n",
       "      <td>3327</td>\n",
       "      <td>3327</td>\n",
       "      <td>3327</td>\n",
       "      <td>3327</td>\n",
       "      <td>3327</td>\n",
       "      <td>...</td>\n",
       "      <td>3327</td>\n",
       "      <td>3327</td>\n",
       "      <td>3327</td>\n",
       "      <td>3327</td>\n",
       "      <td>3327</td>\n",
       "      <td>3327</td>\n",
       "      <td>3327</td>\n",
       "      <td>3327</td>\n",
       "      <td>3327</td>\n",
       "      <td>3327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nous-Capybara-7B</th>\n",
       "      <th>34</th>\n",
       "      <td>3204</td>\n",
       "      <td>3204</td>\n",
       "      <td>3204</td>\n",
       "      <td>3204</td>\n",
       "      <td>3204</td>\n",
       "      <td>3204</td>\n",
       "      <td>3204</td>\n",
       "      <td>3204</td>\n",
       "      <td>3204</td>\n",
       "      <td>3204</td>\n",
       "      <td>...</td>\n",
       "      <td>3204</td>\n",
       "      <td>3204</td>\n",
       "      <td>3204</td>\n",
       "      <td>3204</td>\n",
       "      <td>3204</td>\n",
       "      <td>3204</td>\n",
       "      <td>3204</td>\n",
       "      <td>3204</td>\n",
       "      <td>3204</td>\n",
       "      <td>3204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nous-Hermes-LLaMA-2-13B</th>\n",
       "      <th>35</th>\n",
       "      <td>12686</td>\n",
       "      <td>12686</td>\n",
       "      <td>12686</td>\n",
       "      <td>12686</td>\n",
       "      <td>12686</td>\n",
       "      <td>12686</td>\n",
       "      <td>12686</td>\n",
       "      <td>12686</td>\n",
       "      <td>12686</td>\n",
       "      <td>12686</td>\n",
       "      <td>...</td>\n",
       "      <td>12686</td>\n",
       "      <td>12686</td>\n",
       "      <td>12686</td>\n",
       "      <td>12686</td>\n",
       "      <td>12686</td>\n",
       "      <td>12686</td>\n",
       "      <td>12686</td>\n",
       "      <td>12686</td>\n",
       "      <td>12686</td>\n",
       "      <td>12686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nous-Hermes-LLaMA-2-70B</th>\n",
       "      <th>36</th>\n",
       "      <td>650</td>\n",
       "      <td>650</td>\n",
       "      <td>650</td>\n",
       "      <td>650</td>\n",
       "      <td>650</td>\n",
       "      <td>650</td>\n",
       "      <td>650</td>\n",
       "      <td>650</td>\n",
       "      <td>650</td>\n",
       "      <td>650</td>\n",
       "      <td>...</td>\n",
       "      <td>650</td>\n",
       "      <td>650</td>\n",
       "      <td>650</td>\n",
       "      <td>650</td>\n",
       "      <td>650</td>\n",
       "      <td>650</td>\n",
       "      <td>650</td>\n",
       "      <td>650</td>\n",
       "      <td>650</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPT-1.3B</th>\n",
       "      <th>37</th>\n",
       "      <td>18467</td>\n",
       "      <td>18467</td>\n",
       "      <td>18467</td>\n",
       "      <td>18467</td>\n",
       "      <td>18467</td>\n",
       "      <td>18467</td>\n",
       "      <td>18467</td>\n",
       "      <td>18467</td>\n",
       "      <td>18467</td>\n",
       "      <td>18467</td>\n",
       "      <td>...</td>\n",
       "      <td>18467</td>\n",
       "      <td>18467</td>\n",
       "      <td>18467</td>\n",
       "      <td>18467</td>\n",
       "      <td>18467</td>\n",
       "      <td>18467</td>\n",
       "      <td>18467</td>\n",
       "      <td>18467</td>\n",
       "      <td>18467</td>\n",
       "      <td>18467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPT-125M</th>\n",
       "      <th>38</th>\n",
       "      <td>8823</td>\n",
       "      <td>8823</td>\n",
       "      <td>8823</td>\n",
       "      <td>8823</td>\n",
       "      <td>8823</td>\n",
       "      <td>8823</td>\n",
       "      <td>8823</td>\n",
       "      <td>8823</td>\n",
       "      <td>8823</td>\n",
       "      <td>8823</td>\n",
       "      <td>...</td>\n",
       "      <td>8823</td>\n",
       "      <td>8823</td>\n",
       "      <td>8823</td>\n",
       "      <td>8823</td>\n",
       "      <td>8823</td>\n",
       "      <td>8823</td>\n",
       "      <td>8823</td>\n",
       "      <td>8823</td>\n",
       "      <td>8823</td>\n",
       "      <td>8823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPT-13B</th>\n",
       "      <th>39</th>\n",
       "      <td>8087</td>\n",
       "      <td>8087</td>\n",
       "      <td>8087</td>\n",
       "      <td>8087</td>\n",
       "      <td>8087</td>\n",
       "      <td>8087</td>\n",
       "      <td>8087</td>\n",
       "      <td>8087</td>\n",
       "      <td>8087</td>\n",
       "      <td>8087</td>\n",
       "      <td>...</td>\n",
       "      <td>8087</td>\n",
       "      <td>8087</td>\n",
       "      <td>8087</td>\n",
       "      <td>8087</td>\n",
       "      <td>8087</td>\n",
       "      <td>8087</td>\n",
       "      <td>8087</td>\n",
       "      <td>8087</td>\n",
       "      <td>8087</td>\n",
       "      <td>8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPT-2.7B</th>\n",
       "      <th>40</th>\n",
       "      <td>9134</td>\n",
       "      <td>9134</td>\n",
       "      <td>9134</td>\n",
       "      <td>9134</td>\n",
       "      <td>9134</td>\n",
       "      <td>9134</td>\n",
       "      <td>9134</td>\n",
       "      <td>9134</td>\n",
       "      <td>9134</td>\n",
       "      <td>9134</td>\n",
       "      <td>...</td>\n",
       "      <td>9134</td>\n",
       "      <td>9134</td>\n",
       "      <td>9134</td>\n",
       "      <td>9134</td>\n",
       "      <td>9134</td>\n",
       "      <td>9134</td>\n",
       "      <td>9134</td>\n",
       "      <td>9134</td>\n",
       "      <td>9134</td>\n",
       "      <td>9134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPT-30B</th>\n",
       "      <th>41</th>\n",
       "      <td>18055</td>\n",
       "      <td>18055</td>\n",
       "      <td>18055</td>\n",
       "      <td>18055</td>\n",
       "      <td>18055</td>\n",
       "      <td>18055</td>\n",
       "      <td>18055</td>\n",
       "      <td>18055</td>\n",
       "      <td>18055</td>\n",
       "      <td>18055</td>\n",
       "      <td>...</td>\n",
       "      <td>18055</td>\n",
       "      <td>18055</td>\n",
       "      <td>18055</td>\n",
       "      <td>18055</td>\n",
       "      <td>18055</td>\n",
       "      <td>18055</td>\n",
       "      <td>18055</td>\n",
       "      <td>18055</td>\n",
       "      <td>18055</td>\n",
       "      <td>18055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPT-350M</th>\n",
       "      <th>42</th>\n",
       "      <td>8747</td>\n",
       "      <td>8747</td>\n",
       "      <td>8747</td>\n",
       "      <td>8747</td>\n",
       "      <td>8747</td>\n",
       "      <td>8747</td>\n",
       "      <td>8747</td>\n",
       "      <td>8747</td>\n",
       "      <td>8747</td>\n",
       "      <td>8747</td>\n",
       "      <td>...</td>\n",
       "      <td>8747</td>\n",
       "      <td>8747</td>\n",
       "      <td>8747</td>\n",
       "      <td>8747</td>\n",
       "      <td>8747</td>\n",
       "      <td>8747</td>\n",
       "      <td>8747</td>\n",
       "      <td>8747</td>\n",
       "      <td>8747</td>\n",
       "      <td>8747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OPT-6.7B</th>\n",
       "      <th>43</th>\n",
       "      <td>8838</td>\n",
       "      <td>8838</td>\n",
       "      <td>8838</td>\n",
       "      <td>8838</td>\n",
       "      <td>8838</td>\n",
       "      <td>8838</td>\n",
       "      <td>8838</td>\n",
       "      <td>8838</td>\n",
       "      <td>8838</td>\n",
       "      <td>8838</td>\n",
       "      <td>...</td>\n",
       "      <td>8838</td>\n",
       "      <td>8838</td>\n",
       "      <td>8838</td>\n",
       "      <td>8838</td>\n",
       "      <td>8838</td>\n",
       "      <td>8838</td>\n",
       "      <td>8838</td>\n",
       "      <td>8838</td>\n",
       "      <td>8838</td>\n",
       "      <td>8838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenChat-3.5</th>\n",
       "      <th>44</th>\n",
       "      <td>9402</td>\n",
       "      <td>9402</td>\n",
       "      <td>9402</td>\n",
       "      <td>9402</td>\n",
       "      <td>9402</td>\n",
       "      <td>9402</td>\n",
       "      <td>9402</td>\n",
       "      <td>9402</td>\n",
       "      <td>9402</td>\n",
       "      <td>9402</td>\n",
       "      <td>...</td>\n",
       "      <td>9402</td>\n",
       "      <td>9402</td>\n",
       "      <td>9402</td>\n",
       "      <td>9402</td>\n",
       "      <td>9402</td>\n",
       "      <td>9402</td>\n",
       "      <td>9402</td>\n",
       "      <td>9402</td>\n",
       "      <td>9402</td>\n",
       "      <td>9402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenHermes-2-Mistral-7B</th>\n",
       "      <th>45</th>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>...</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenHermes-2.5-Mistral-7B</th>\n",
       "      <th>46</th>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>...</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaLM-2</th>\n",
       "      <th>47</th>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>...</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "      <td>9510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Psyfighter-13B</th>\n",
       "      <th>48</th>\n",
       "      <td>4375</td>\n",
       "      <td>4375</td>\n",
       "      <td>4375</td>\n",
       "      <td>4375</td>\n",
       "      <td>4375</td>\n",
       "      <td>4375</td>\n",
       "      <td>4375</td>\n",
       "      <td>4375</td>\n",
       "      <td>4375</td>\n",
       "      <td>4375</td>\n",
       "      <td>...</td>\n",
       "      <td>4375</td>\n",
       "      <td>4375</td>\n",
       "      <td>4375</td>\n",
       "      <td>4375</td>\n",
       "      <td>4375</td>\n",
       "      <td>4375</td>\n",
       "      <td>4375</td>\n",
       "      <td>4375</td>\n",
       "      <td>4375</td>\n",
       "      <td>4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Psyfighter-2-13B</th>\n",
       "      <th>49</th>\n",
       "      <td>2743</td>\n",
       "      <td>2743</td>\n",
       "      <td>2743</td>\n",
       "      <td>2743</td>\n",
       "      <td>2743</td>\n",
       "      <td>2743</td>\n",
       "      <td>2743</td>\n",
       "      <td>2743</td>\n",
       "      <td>2743</td>\n",
       "      <td>2743</td>\n",
       "      <td>...</td>\n",
       "      <td>2743</td>\n",
       "      <td>2743</td>\n",
       "      <td>2743</td>\n",
       "      <td>2743</td>\n",
       "      <td>2743</td>\n",
       "      <td>2743</td>\n",
       "      <td>2743</td>\n",
       "      <td>2743</td>\n",
       "      <td>2743</td>\n",
       "      <td>2743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RWKV-5-World-3B</th>\n",
       "      <th>50</th>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>...</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StripedHyena-Nous-7B</th>\n",
       "      <th>51</th>\n",
       "      <td>3520</td>\n",
       "      <td>3520</td>\n",
       "      <td>3520</td>\n",
       "      <td>3520</td>\n",
       "      <td>3520</td>\n",
       "      <td>3520</td>\n",
       "      <td>3520</td>\n",
       "      <td>3520</td>\n",
       "      <td>3520</td>\n",
       "      <td>3520</td>\n",
       "      <td>...</td>\n",
       "      <td>3520</td>\n",
       "      <td>3520</td>\n",
       "      <td>3520</td>\n",
       "      <td>3520</td>\n",
       "      <td>3520</td>\n",
       "      <td>3520</td>\n",
       "      <td>3520</td>\n",
       "      <td>3520</td>\n",
       "      <td>3520</td>\n",
       "      <td>3520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T0-11B</th>\n",
       "      <th>52</th>\n",
       "      <td>8705</td>\n",
       "      <td>8705</td>\n",
       "      <td>8705</td>\n",
       "      <td>8705</td>\n",
       "      <td>8705</td>\n",
       "      <td>8705</td>\n",
       "      <td>8705</td>\n",
       "      <td>8705</td>\n",
       "      <td>8705</td>\n",
       "      <td>8705</td>\n",
       "      <td>...</td>\n",
       "      <td>8705</td>\n",
       "      <td>8705</td>\n",
       "      <td>8705</td>\n",
       "      <td>8705</td>\n",
       "      <td>8705</td>\n",
       "      <td>8705</td>\n",
       "      <td>8705</td>\n",
       "      <td>8705</td>\n",
       "      <td>8705</td>\n",
       "      <td>8705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T0-3B</th>\n",
       "      <th>53</th>\n",
       "      <td>9219</td>\n",
       "      <td>9219</td>\n",
       "      <td>9219</td>\n",
       "      <td>9219</td>\n",
       "      <td>9219</td>\n",
       "      <td>9219</td>\n",
       "      <td>9219</td>\n",
       "      <td>9219</td>\n",
       "      <td>9219</td>\n",
       "      <td>9219</td>\n",
       "      <td>...</td>\n",
       "      <td>9219</td>\n",
       "      <td>9219</td>\n",
       "      <td>9219</td>\n",
       "      <td>9219</td>\n",
       "      <td>9219</td>\n",
       "      <td>9219</td>\n",
       "      <td>9219</td>\n",
       "      <td>9219</td>\n",
       "      <td>9219</td>\n",
       "      <td>9219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text-Ada-001</th>\n",
       "      <th>54</th>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>...</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text-Babbage-001</th>\n",
       "      <th>55</th>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>...</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text-Curie-001</th>\n",
       "      <th>56</th>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>...</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text-Davinci-001</th>\n",
       "      <th>57</th>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>...</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "      <td>1120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text-Davinci-002</th>\n",
       "      <th>58</th>\n",
       "      <td>21436</td>\n",
       "      <td>21436</td>\n",
       "      <td>21436</td>\n",
       "      <td>21436</td>\n",
       "      <td>21436</td>\n",
       "      <td>21436</td>\n",
       "      <td>21436</td>\n",
       "      <td>21436</td>\n",
       "      <td>21436</td>\n",
       "      <td>21436</td>\n",
       "      <td>...</td>\n",
       "      <td>21436</td>\n",
       "      <td>21436</td>\n",
       "      <td>21436</td>\n",
       "      <td>21436</td>\n",
       "      <td>21436</td>\n",
       "      <td>21436</td>\n",
       "      <td>21436</td>\n",
       "      <td>21436</td>\n",
       "      <td>21436</td>\n",
       "      <td>21436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Text-Davinci-003</th>\n",
       "      <th>59</th>\n",
       "      <td>22860</td>\n",
       "      <td>22860</td>\n",
       "      <td>22860</td>\n",
       "      <td>22860</td>\n",
       "      <td>22860</td>\n",
       "      <td>22860</td>\n",
       "      <td>22860</td>\n",
       "      <td>22860</td>\n",
       "      <td>22860</td>\n",
       "      <td>22860</td>\n",
       "      <td>...</td>\n",
       "      <td>22860</td>\n",
       "      <td>22860</td>\n",
       "      <td>22860</td>\n",
       "      <td>22860</td>\n",
       "      <td>22860</td>\n",
       "      <td>22860</td>\n",
       "      <td>22860</td>\n",
       "      <td>22860</td>\n",
       "      <td>22860</td>\n",
       "      <td>22860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         lexical_diversity  readability_score  \\\n",
       "source                    sourceEncoded                                         \n",
       "Bloom-7B                  0                           8812               8812   \n",
       "Claude-Instant-v1         1                           7147               7147   \n",
       "Claude-v1                 2                           3158               3158   \n",
       "Cohere-Command            3                            390                390   \n",
       "Dolphin-2.5-Mixtral-8x7B  4                            228                228   \n",
       "Dolphin-Mixtral-8x7B      5                            407                407   \n",
       "Falcon-180B               6                           4745               4745   \n",
       "Flan-T5-Base              7                           9201               9201   \n",
       "Flan-T5-Large             8                           9164               9164   \n",
       "Flan-T5-Small             9                           9144               9144   \n",
       "Flan-T5-XL                10                          8986               8986   \n",
       "Flan-T5-XXL               11                          9113               9113   \n",
       "GLM-130B                  12                          9071               9071   \n",
       "GPT-3.5                   13                         52346              52346   \n",
       "GPT-4                     14                          8852               8852   \n",
       "GPT-J                     15                          7580               7580   \n",
       "GPT-NeoX                  16                          6821               6821   \n",
       "Gemini-Pro                17                           613                613   \n",
       "Goliath-120B              18                           734                734   \n",
       "Human                     19                        347692             347692   \n",
       "LLaMA-13B                 20                          9282               9282   \n",
       "LLaMA-2-70B               21                          5000               5000   \n",
       "LLaMA-2-7B                22                           409                409   \n",
       "LLaMA-30B                 23                          9340               9340   \n",
       "LLaMA-65B                 24                          9321               9321   \n",
       "LLaMA-7B                  25                          9271               9271   \n",
       "LZLV-70B                  26                          5143               5143   \n",
       "Mistral-7B                27                         10439              10439   \n",
       "Mistral-7B-OpenOrca       28                          3058               3058   \n",
       "Mixtral-8x7B              29                          2865               2865   \n",
       "MythoMax-L2-13B           30                          6147               6147   \n",
       "Neural-Chat-7B            31                          5858               5858   \n",
       "Noromaid-20B              32                          1326               1326   \n",
       "Nous-Capybara-34B         33                          3327               3327   \n",
       "Nous-Capybara-7B          34                          3204               3204   \n",
       "Nous-Hermes-LLaMA-2-13B   35                         12686              12686   \n",
       "Nous-Hermes-LLaMA-2-70B   36                           650                650   \n",
       "OPT-1.3B                  37                         18467              18467   \n",
       "OPT-125M                  38                          8823               8823   \n",
       "OPT-13B                   39                          8087               8087   \n",
       "OPT-2.7B                  40                          9134               9134   \n",
       "OPT-30B                   41                         18055              18055   \n",
       "OPT-350M                  42                          8747               8747   \n",
       "OPT-6.7B                  43                          8838               8838   \n",
       "OpenChat-3.5              44                          9402               9402   \n",
       "OpenHermes-2-Mistral-7B   45                           623                623   \n",
       "OpenHermes-2.5-Mistral-7B 46                           612                612   \n",
       "PaLM-2                    47                          9510               9510   \n",
       "Psyfighter-13B            48                          4375               4375   \n",
       "Psyfighter-2-13B          49                          2743               2743   \n",
       "RWKV-5-World-3B           50                           496                496   \n",
       "StripedHyena-Nous-7B      51                          3520               3520   \n",
       "T0-11B                    52                          8705               8705   \n",
       "T0-3B                     53                          9219               9219   \n",
       "Text-Ada-001              54                           691                691   \n",
       "Text-Babbage-001          55                           875                875   \n",
       "Text-Curie-001            56                          1008               1008   \n",
       "Text-Davinci-001          57                          1120               1120   \n",
       "Text-Davinci-002          58                         21436              21436   \n",
       "Text-Davinci-003          59                         22860              22860   \n",
       "\n",
       "                                         sentence_count  prompt_length  \\\n",
       "source                    sourceEncoded                                  \n",
       "Bloom-7B                  0                        8812           8812   \n",
       "Claude-Instant-v1         1                        7147           7147   \n",
       "Claude-v1                 2                        3158           3158   \n",
       "Cohere-Command            3                         390            390   \n",
       "Dolphin-2.5-Mixtral-8x7B  4                         228            228   \n",
       "Dolphin-Mixtral-8x7B      5                         407            407   \n",
       "Falcon-180B               6                        4745           4745   \n",
       "Flan-T5-Base              7                        9201           9201   \n",
       "Flan-T5-Large             8                        9164           9164   \n",
       "Flan-T5-Small             9                        9144           9144   \n",
       "Flan-T5-XL                10                       8986           8986   \n",
       "Flan-T5-XXL               11                       9113           9113   \n",
       "GLM-130B                  12                       9071           9071   \n",
       "GPT-3.5                   13                      52346          52346   \n",
       "GPT-4                     14                       8852           8852   \n",
       "GPT-J                     15                       7580           7580   \n",
       "GPT-NeoX                  16                       6821           6821   \n",
       "Gemini-Pro                17                        613            613   \n",
       "Goliath-120B              18                        734            734   \n",
       "Human                     19                     347692         347692   \n",
       "LLaMA-13B                 20                       9282           9282   \n",
       "LLaMA-2-70B               21                       5000           5000   \n",
       "LLaMA-2-7B                22                        409            409   \n",
       "LLaMA-30B                 23                       9340           9340   \n",
       "LLaMA-65B                 24                       9321           9321   \n",
       "LLaMA-7B                  25                       9271           9271   \n",
       "LZLV-70B                  26                       5143           5143   \n",
       "Mistral-7B                27                      10439          10439   \n",
       "Mistral-7B-OpenOrca       28                       3058           3058   \n",
       "Mixtral-8x7B              29                       2865           2865   \n",
       "MythoMax-L2-13B           30                       6147           6147   \n",
       "Neural-Chat-7B            31                       5858           5858   \n",
       "Noromaid-20B              32                       1326           1326   \n",
       "Nous-Capybara-34B         33                       3327           3327   \n",
       "Nous-Capybara-7B          34                       3204           3204   \n",
       "Nous-Hermes-LLaMA-2-13B   35                      12686          12686   \n",
       "Nous-Hermes-LLaMA-2-70B   36                        650            650   \n",
       "OPT-1.3B                  37                      18467          18467   \n",
       "OPT-125M                  38                       8823           8823   \n",
       "OPT-13B                   39                       8087           8087   \n",
       "OPT-2.7B                  40                       9134           9134   \n",
       "OPT-30B                   41                      18055          18055   \n",
       "OPT-350M                  42                       8747           8747   \n",
       "OPT-6.7B                  43                       8838           8838   \n",
       "OpenChat-3.5              44                       9402           9402   \n",
       "OpenHermes-2-Mistral-7B   45                        623            623   \n",
       "OpenHermes-2.5-Mistral-7B 46                        612            612   \n",
       "PaLM-2                    47                       9510           9510   \n",
       "Psyfighter-13B            48                       4375           4375   \n",
       "Psyfighter-2-13B          49                       2743           2743   \n",
       "RWKV-5-World-3B           50                        496            496   \n",
       "StripedHyena-Nous-7B      51                       3520           3520   \n",
       "T0-11B                    52                       8705           8705   \n",
       "T0-3B                     53                       9219           9219   \n",
       "Text-Ada-001              54                        691            691   \n",
       "Text-Babbage-001          55                        875            875   \n",
       "Text-Curie-001            56                       1008           1008   \n",
       "Text-Davinci-001          57                       1120           1120   \n",
       "Text-Davinci-002          58                      21436          21436   \n",
       "Text-Davinci-003          59                      22860          22860   \n",
       "\n",
       "                                         embedding_0  embedding_1  \\\n",
       "source                    sourceEncoded                             \n",
       "Bloom-7B                  0                     8812         8812   \n",
       "Claude-Instant-v1         1                     7147         7147   \n",
       "Claude-v1                 2                     3158         3158   \n",
       "Cohere-Command            3                      390          390   \n",
       "Dolphin-2.5-Mixtral-8x7B  4                      228          228   \n",
       "Dolphin-Mixtral-8x7B      5                      407          407   \n",
       "Falcon-180B               6                     4745         4745   \n",
       "Flan-T5-Base              7                     9201         9201   \n",
       "Flan-T5-Large             8                     9164         9164   \n",
       "Flan-T5-Small             9                     9144         9144   \n",
       "Flan-T5-XL                10                    8986         8986   \n",
       "Flan-T5-XXL               11                    9113         9113   \n",
       "GLM-130B                  12                    9071         9071   \n",
       "GPT-3.5                   13                   52346        52346   \n",
       "GPT-4                     14                    8852         8852   \n",
       "GPT-J                     15                    7580         7580   \n",
       "GPT-NeoX                  16                    6821         6821   \n",
       "Gemini-Pro                17                     613          613   \n",
       "Goliath-120B              18                     734          734   \n",
       "Human                     19                  347692       347692   \n",
       "LLaMA-13B                 20                    9282         9282   \n",
       "LLaMA-2-70B               21                    5000         5000   \n",
       "LLaMA-2-7B                22                     409          409   \n",
       "LLaMA-30B                 23                    9340         9340   \n",
       "LLaMA-65B                 24                    9321         9321   \n",
       "LLaMA-7B                  25                    9271         9271   \n",
       "LZLV-70B                  26                    5143         5143   \n",
       "Mistral-7B                27                   10439        10439   \n",
       "Mistral-7B-OpenOrca       28                    3058         3058   \n",
       "Mixtral-8x7B              29                    2865         2865   \n",
       "MythoMax-L2-13B           30                    6147         6147   \n",
       "Neural-Chat-7B            31                    5858         5858   \n",
       "Noromaid-20B              32                    1326         1326   \n",
       "Nous-Capybara-34B         33                    3327         3327   \n",
       "Nous-Capybara-7B          34                    3204         3204   \n",
       "Nous-Hermes-LLaMA-2-13B   35                   12686        12686   \n",
       "Nous-Hermes-LLaMA-2-70B   36                     650          650   \n",
       "OPT-1.3B                  37                   18467        18467   \n",
       "OPT-125M                  38                    8823         8823   \n",
       "OPT-13B                   39                    8087         8087   \n",
       "OPT-2.7B                  40                    9134         9134   \n",
       "OPT-30B                   41                   18055        18055   \n",
       "OPT-350M                  42                    8747         8747   \n",
       "OPT-6.7B                  43                    8838         8838   \n",
       "OpenChat-3.5              44                    9402         9402   \n",
       "OpenHermes-2-Mistral-7B   45                     623          623   \n",
       "OpenHermes-2.5-Mistral-7B 46                     612          612   \n",
       "PaLM-2                    47                    9510         9510   \n",
       "Psyfighter-13B            48                    4375         4375   \n",
       "Psyfighter-2-13B          49                    2743         2743   \n",
       "RWKV-5-World-3B           50                     496          496   \n",
       "StripedHyena-Nous-7B      51                    3520         3520   \n",
       "T0-11B                    52                    8705         8705   \n",
       "T0-3B                     53                    9219         9219   \n",
       "Text-Ada-001              54                     691          691   \n",
       "Text-Babbage-001          55                     875          875   \n",
       "Text-Curie-001            56                    1008         1008   \n",
       "Text-Davinci-001          57                    1120         1120   \n",
       "Text-Davinci-002          58                   21436        21436   \n",
       "Text-Davinci-003          59                   22860        22860   \n",
       "\n",
       "                                         embedding_2  embedding_3  \\\n",
       "source                    sourceEncoded                             \n",
       "Bloom-7B                  0                     8812         8812   \n",
       "Claude-Instant-v1         1                     7147         7147   \n",
       "Claude-v1                 2                     3158         3158   \n",
       "Cohere-Command            3                      390          390   \n",
       "Dolphin-2.5-Mixtral-8x7B  4                      228          228   \n",
       "Dolphin-Mixtral-8x7B      5                      407          407   \n",
       "Falcon-180B               6                     4745         4745   \n",
       "Flan-T5-Base              7                     9201         9201   \n",
       "Flan-T5-Large             8                     9164         9164   \n",
       "Flan-T5-Small             9                     9144         9144   \n",
       "Flan-T5-XL                10                    8986         8986   \n",
       "Flan-T5-XXL               11                    9113         9113   \n",
       "GLM-130B                  12                    9071         9071   \n",
       "GPT-3.5                   13                   52346        52346   \n",
       "GPT-4                     14                    8852         8852   \n",
       "GPT-J                     15                    7580         7580   \n",
       "GPT-NeoX                  16                    6821         6821   \n",
       "Gemini-Pro                17                     613          613   \n",
       "Goliath-120B              18                     734          734   \n",
       "Human                     19                  347692       347692   \n",
       "LLaMA-13B                 20                    9282         9282   \n",
       "LLaMA-2-70B               21                    5000         5000   \n",
       "LLaMA-2-7B                22                     409          409   \n",
       "LLaMA-30B                 23                    9340         9340   \n",
       "LLaMA-65B                 24                    9321         9321   \n",
       "LLaMA-7B                  25                    9271         9271   \n",
       "LZLV-70B                  26                    5143         5143   \n",
       "Mistral-7B                27                   10439        10439   \n",
       "Mistral-7B-OpenOrca       28                    3058         3058   \n",
       "Mixtral-8x7B              29                    2865         2865   \n",
       "MythoMax-L2-13B           30                    6147         6147   \n",
       "Neural-Chat-7B            31                    5858         5858   \n",
       "Noromaid-20B              32                    1326         1326   \n",
       "Nous-Capybara-34B         33                    3327         3327   \n",
       "Nous-Capybara-7B          34                    3204         3204   \n",
       "Nous-Hermes-LLaMA-2-13B   35                   12686        12686   \n",
       "Nous-Hermes-LLaMA-2-70B   36                     650          650   \n",
       "OPT-1.3B                  37                   18467        18467   \n",
       "OPT-125M                  38                    8823         8823   \n",
       "OPT-13B                   39                    8087         8087   \n",
       "OPT-2.7B                  40                    9134         9134   \n",
       "OPT-30B                   41                   18055        18055   \n",
       "OPT-350M                  42                    8747         8747   \n",
       "OPT-6.7B                  43                    8838         8838   \n",
       "OpenChat-3.5              44                    9402         9402   \n",
       "OpenHermes-2-Mistral-7B   45                     623          623   \n",
       "OpenHermes-2.5-Mistral-7B 46                     612          612   \n",
       "PaLM-2                    47                    9510         9510   \n",
       "Psyfighter-13B            48                    4375         4375   \n",
       "Psyfighter-2-13B          49                    2743         2743   \n",
       "RWKV-5-World-3B           50                     496          496   \n",
       "StripedHyena-Nous-7B      51                    3520         3520   \n",
       "T0-11B                    52                    8705         8705   \n",
       "T0-3B                     53                    9219         9219   \n",
       "Text-Ada-001              54                     691          691   \n",
       "Text-Babbage-001          55                     875          875   \n",
       "Text-Curie-001            56                    1008         1008   \n",
       "Text-Davinci-001          57                    1120         1120   \n",
       "Text-Davinci-002          58                   21436        21436   \n",
       "Text-Davinci-003          59                   22860        22860   \n",
       "\n",
       "                                         embedding_4  embedding_5  ...  \\\n",
       "source                    sourceEncoded                            ...   \n",
       "Bloom-7B                  0                     8812         8812  ...   \n",
       "Claude-Instant-v1         1                     7147         7147  ...   \n",
       "Claude-v1                 2                     3158         3158  ...   \n",
       "Cohere-Command            3                      390          390  ...   \n",
       "Dolphin-2.5-Mixtral-8x7B  4                      228          228  ...   \n",
       "Dolphin-Mixtral-8x7B      5                      407          407  ...   \n",
       "Falcon-180B               6                     4745         4745  ...   \n",
       "Flan-T5-Base              7                     9201         9201  ...   \n",
       "Flan-T5-Large             8                     9164         9164  ...   \n",
       "Flan-T5-Small             9                     9144         9144  ...   \n",
       "Flan-T5-XL                10                    8986         8986  ...   \n",
       "Flan-T5-XXL               11                    9113         9113  ...   \n",
       "GLM-130B                  12                    9071         9071  ...   \n",
       "GPT-3.5                   13                   52346        52346  ...   \n",
       "GPT-4                     14                    8852         8852  ...   \n",
       "GPT-J                     15                    7580         7580  ...   \n",
       "GPT-NeoX                  16                    6821         6821  ...   \n",
       "Gemini-Pro                17                     613          613  ...   \n",
       "Goliath-120B              18                     734          734  ...   \n",
       "Human                     19                  347692       347692  ...   \n",
       "LLaMA-13B                 20                    9282         9282  ...   \n",
       "LLaMA-2-70B               21                    5000         5000  ...   \n",
       "LLaMA-2-7B                22                     409          409  ...   \n",
       "LLaMA-30B                 23                    9340         9340  ...   \n",
       "LLaMA-65B                 24                    9321         9321  ...   \n",
       "LLaMA-7B                  25                    9271         9271  ...   \n",
       "LZLV-70B                  26                    5143         5143  ...   \n",
       "Mistral-7B                27                   10439        10439  ...   \n",
       "Mistral-7B-OpenOrca       28                    3058         3058  ...   \n",
       "Mixtral-8x7B              29                    2865         2865  ...   \n",
       "MythoMax-L2-13B           30                    6147         6147  ...   \n",
       "Neural-Chat-7B            31                    5858         5858  ...   \n",
       "Noromaid-20B              32                    1326         1326  ...   \n",
       "Nous-Capybara-34B         33                    3327         3327  ...   \n",
       "Nous-Capybara-7B          34                    3204         3204  ...   \n",
       "Nous-Hermes-LLaMA-2-13B   35                   12686        12686  ...   \n",
       "Nous-Hermes-LLaMA-2-70B   36                     650          650  ...   \n",
       "OPT-1.3B                  37                   18467        18467  ...   \n",
       "OPT-125M                  38                    8823         8823  ...   \n",
       "OPT-13B                   39                    8087         8087  ...   \n",
       "OPT-2.7B                  40                    9134         9134  ...   \n",
       "OPT-30B                   41                   18055        18055  ...   \n",
       "OPT-350M                  42                    8747         8747  ...   \n",
       "OPT-6.7B                  43                    8838         8838  ...   \n",
       "OpenChat-3.5              44                    9402         9402  ...   \n",
       "OpenHermes-2-Mistral-7B   45                     623          623  ...   \n",
       "OpenHermes-2.5-Mistral-7B 46                     612          612  ...   \n",
       "PaLM-2                    47                    9510         9510  ...   \n",
       "Psyfighter-13B            48                    4375         4375  ...   \n",
       "Psyfighter-2-13B          49                    2743         2743  ...   \n",
       "RWKV-5-World-3B           50                     496          496  ...   \n",
       "StripedHyena-Nous-7B      51                    3520         3520  ...   \n",
       "T0-11B                    52                    8705         8705  ...   \n",
       "T0-3B                     53                    9219         9219  ...   \n",
       "Text-Ada-001              54                     691          691  ...   \n",
       "Text-Babbage-001          55                     875          875  ...   \n",
       "Text-Curie-001            56                    1008         1008  ...   \n",
       "Text-Davinci-001          57                    1120         1120  ...   \n",
       "Text-Davinci-002          58                   21436        21436  ...   \n",
       "Text-Davinci-003          59                   22860        22860  ...   \n",
       "\n",
       "                                         embedding_40  embedding_41  \\\n",
       "source                    sourceEncoded                               \n",
       "Bloom-7B                  0                      8812          8812   \n",
       "Claude-Instant-v1         1                      7147          7147   \n",
       "Claude-v1                 2                      3158          3158   \n",
       "Cohere-Command            3                       390           390   \n",
       "Dolphin-2.5-Mixtral-8x7B  4                       228           228   \n",
       "Dolphin-Mixtral-8x7B      5                       407           407   \n",
       "Falcon-180B               6                      4745          4745   \n",
       "Flan-T5-Base              7                      9201          9201   \n",
       "Flan-T5-Large             8                      9164          9164   \n",
       "Flan-T5-Small             9                      9144          9144   \n",
       "Flan-T5-XL                10                     8986          8986   \n",
       "Flan-T5-XXL               11                     9113          9113   \n",
       "GLM-130B                  12                     9071          9071   \n",
       "GPT-3.5                   13                    52346         52346   \n",
       "GPT-4                     14                     8852          8852   \n",
       "GPT-J                     15                     7580          7580   \n",
       "GPT-NeoX                  16                     6821          6821   \n",
       "Gemini-Pro                17                      613           613   \n",
       "Goliath-120B              18                      734           734   \n",
       "Human                     19                   347692        347692   \n",
       "LLaMA-13B                 20                     9282          9282   \n",
       "LLaMA-2-70B               21                     5000          5000   \n",
       "LLaMA-2-7B                22                      409           409   \n",
       "LLaMA-30B                 23                     9340          9340   \n",
       "LLaMA-65B                 24                     9321          9321   \n",
       "LLaMA-7B                  25                     9271          9271   \n",
       "LZLV-70B                  26                     5143          5143   \n",
       "Mistral-7B                27                    10439         10439   \n",
       "Mistral-7B-OpenOrca       28                     3058          3058   \n",
       "Mixtral-8x7B              29                     2865          2865   \n",
       "MythoMax-L2-13B           30                     6147          6147   \n",
       "Neural-Chat-7B            31                     5858          5858   \n",
       "Noromaid-20B              32                     1326          1326   \n",
       "Nous-Capybara-34B         33                     3327          3327   \n",
       "Nous-Capybara-7B          34                     3204          3204   \n",
       "Nous-Hermes-LLaMA-2-13B   35                    12686         12686   \n",
       "Nous-Hermes-LLaMA-2-70B   36                      650           650   \n",
       "OPT-1.3B                  37                    18467         18467   \n",
       "OPT-125M                  38                     8823          8823   \n",
       "OPT-13B                   39                     8087          8087   \n",
       "OPT-2.7B                  40                     9134          9134   \n",
       "OPT-30B                   41                    18055         18055   \n",
       "OPT-350M                  42                     8747          8747   \n",
       "OPT-6.7B                  43                     8838          8838   \n",
       "OpenChat-3.5              44                     9402          9402   \n",
       "OpenHermes-2-Mistral-7B   45                      623           623   \n",
       "OpenHermes-2.5-Mistral-7B 46                      612           612   \n",
       "PaLM-2                    47                     9510          9510   \n",
       "Psyfighter-13B            48                     4375          4375   \n",
       "Psyfighter-2-13B          49                     2743          2743   \n",
       "RWKV-5-World-3B           50                      496           496   \n",
       "StripedHyena-Nous-7B      51                     3520          3520   \n",
       "T0-11B                    52                     8705          8705   \n",
       "T0-3B                     53                     9219          9219   \n",
       "Text-Ada-001              54                      691           691   \n",
       "Text-Babbage-001          55                      875           875   \n",
       "Text-Curie-001            56                     1008          1008   \n",
       "Text-Davinci-001          57                     1120          1120   \n",
       "Text-Davinci-002          58                    21436         21436   \n",
       "Text-Davinci-003          59                    22860         22860   \n",
       "\n",
       "                                         embedding_42  embedding_43  \\\n",
       "source                    sourceEncoded                               \n",
       "Bloom-7B                  0                      8812          8812   \n",
       "Claude-Instant-v1         1                      7147          7147   \n",
       "Claude-v1                 2                      3158          3158   \n",
       "Cohere-Command            3                       390           390   \n",
       "Dolphin-2.5-Mixtral-8x7B  4                       228           228   \n",
       "Dolphin-Mixtral-8x7B      5                       407           407   \n",
       "Falcon-180B               6                      4745          4745   \n",
       "Flan-T5-Base              7                      9201          9201   \n",
       "Flan-T5-Large             8                      9164          9164   \n",
       "Flan-T5-Small             9                      9144          9144   \n",
       "Flan-T5-XL                10                     8986          8986   \n",
       "Flan-T5-XXL               11                     9113          9113   \n",
       "GLM-130B                  12                     9071          9071   \n",
       "GPT-3.5                   13                    52346         52346   \n",
       "GPT-4                     14                     8852          8852   \n",
       "GPT-J                     15                     7580          7580   \n",
       "GPT-NeoX                  16                     6821          6821   \n",
       "Gemini-Pro                17                      613           613   \n",
       "Goliath-120B              18                      734           734   \n",
       "Human                     19                   347692        347692   \n",
       "LLaMA-13B                 20                     9282          9282   \n",
       "LLaMA-2-70B               21                     5000          5000   \n",
       "LLaMA-2-7B                22                      409           409   \n",
       "LLaMA-30B                 23                     9340          9340   \n",
       "LLaMA-65B                 24                     9321          9321   \n",
       "LLaMA-7B                  25                     9271          9271   \n",
       "LZLV-70B                  26                     5143          5143   \n",
       "Mistral-7B                27                    10439         10439   \n",
       "Mistral-7B-OpenOrca       28                     3058          3058   \n",
       "Mixtral-8x7B              29                     2865          2865   \n",
       "MythoMax-L2-13B           30                     6147          6147   \n",
       "Neural-Chat-7B            31                     5858          5858   \n",
       "Noromaid-20B              32                     1326          1326   \n",
       "Nous-Capybara-34B         33                     3327          3327   \n",
       "Nous-Capybara-7B          34                     3204          3204   \n",
       "Nous-Hermes-LLaMA-2-13B   35                    12686         12686   \n",
       "Nous-Hermes-LLaMA-2-70B   36                      650           650   \n",
       "OPT-1.3B                  37                    18467         18467   \n",
       "OPT-125M                  38                     8823          8823   \n",
       "OPT-13B                   39                     8087          8087   \n",
       "OPT-2.7B                  40                     9134          9134   \n",
       "OPT-30B                   41                    18055         18055   \n",
       "OPT-350M                  42                     8747          8747   \n",
       "OPT-6.7B                  43                     8838          8838   \n",
       "OpenChat-3.5              44                     9402          9402   \n",
       "OpenHermes-2-Mistral-7B   45                      623           623   \n",
       "OpenHermes-2.5-Mistral-7B 46                      612           612   \n",
       "PaLM-2                    47                     9510          9510   \n",
       "Psyfighter-13B            48                     4375          4375   \n",
       "Psyfighter-2-13B          49                     2743          2743   \n",
       "RWKV-5-World-3B           50                      496           496   \n",
       "StripedHyena-Nous-7B      51                     3520          3520   \n",
       "T0-11B                    52                     8705          8705   \n",
       "T0-3B                     53                     9219          9219   \n",
       "Text-Ada-001              54                      691           691   \n",
       "Text-Babbage-001          55                      875           875   \n",
       "Text-Curie-001            56                     1008          1008   \n",
       "Text-Davinci-001          57                     1120          1120   \n",
       "Text-Davinci-002          58                    21436         21436   \n",
       "Text-Davinci-003          59                    22860         22860   \n",
       "\n",
       "                                         embedding_44  embedding_45  \\\n",
       "source                    sourceEncoded                               \n",
       "Bloom-7B                  0                      8812          8812   \n",
       "Claude-Instant-v1         1                      7147          7147   \n",
       "Claude-v1                 2                      3158          3158   \n",
       "Cohere-Command            3                       390           390   \n",
       "Dolphin-2.5-Mixtral-8x7B  4                       228           228   \n",
       "Dolphin-Mixtral-8x7B      5                       407           407   \n",
       "Falcon-180B               6                      4745          4745   \n",
       "Flan-T5-Base              7                      9201          9201   \n",
       "Flan-T5-Large             8                      9164          9164   \n",
       "Flan-T5-Small             9                      9144          9144   \n",
       "Flan-T5-XL                10                     8986          8986   \n",
       "Flan-T5-XXL               11                     9113          9113   \n",
       "GLM-130B                  12                     9071          9071   \n",
       "GPT-3.5                   13                    52346         52346   \n",
       "GPT-4                     14                     8852          8852   \n",
       "GPT-J                     15                     7580          7580   \n",
       "GPT-NeoX                  16                     6821          6821   \n",
       "Gemini-Pro                17                      613           613   \n",
       "Goliath-120B              18                      734           734   \n",
       "Human                     19                   347692        347692   \n",
       "LLaMA-13B                 20                     9282          9282   \n",
       "LLaMA-2-70B               21                     5000          5000   \n",
       "LLaMA-2-7B                22                      409           409   \n",
       "LLaMA-30B                 23                     9340          9340   \n",
       "LLaMA-65B                 24                     9321          9321   \n",
       "LLaMA-7B                  25                     9271          9271   \n",
       "LZLV-70B                  26                     5143          5143   \n",
       "Mistral-7B                27                    10439         10439   \n",
       "Mistral-7B-OpenOrca       28                     3058          3058   \n",
       "Mixtral-8x7B              29                     2865          2865   \n",
       "MythoMax-L2-13B           30                     6147          6147   \n",
       "Neural-Chat-7B            31                     5858          5858   \n",
       "Noromaid-20B              32                     1326          1326   \n",
       "Nous-Capybara-34B         33                     3327          3327   \n",
       "Nous-Capybara-7B          34                     3204          3204   \n",
       "Nous-Hermes-LLaMA-2-13B   35                    12686         12686   \n",
       "Nous-Hermes-LLaMA-2-70B   36                      650           650   \n",
       "OPT-1.3B                  37                    18467         18467   \n",
       "OPT-125M                  38                     8823          8823   \n",
       "OPT-13B                   39                     8087          8087   \n",
       "OPT-2.7B                  40                     9134          9134   \n",
       "OPT-30B                   41                    18055         18055   \n",
       "OPT-350M                  42                     8747          8747   \n",
       "OPT-6.7B                  43                     8838          8838   \n",
       "OpenChat-3.5              44                     9402          9402   \n",
       "OpenHermes-2-Mistral-7B   45                      623           623   \n",
       "OpenHermes-2.5-Mistral-7B 46                      612           612   \n",
       "PaLM-2                    47                     9510          9510   \n",
       "Psyfighter-13B            48                     4375          4375   \n",
       "Psyfighter-2-13B          49                     2743          2743   \n",
       "RWKV-5-World-3B           50                      496           496   \n",
       "StripedHyena-Nous-7B      51                     3520          3520   \n",
       "T0-11B                    52                     8705          8705   \n",
       "T0-3B                     53                     9219          9219   \n",
       "Text-Ada-001              54                      691           691   \n",
       "Text-Babbage-001          55                      875           875   \n",
       "Text-Curie-001            56                     1008          1008   \n",
       "Text-Davinci-001          57                     1120          1120   \n",
       "Text-Davinci-002          58                    21436         21436   \n",
       "Text-Davinci-003          59                    22860         22860   \n",
       "\n",
       "                                         embedding_46  embedding_47  \\\n",
       "source                    sourceEncoded                               \n",
       "Bloom-7B                  0                      8812          8812   \n",
       "Claude-Instant-v1         1                      7147          7147   \n",
       "Claude-v1                 2                      3158          3158   \n",
       "Cohere-Command            3                       390           390   \n",
       "Dolphin-2.5-Mixtral-8x7B  4                       228           228   \n",
       "Dolphin-Mixtral-8x7B      5                       407           407   \n",
       "Falcon-180B               6                      4745          4745   \n",
       "Flan-T5-Base              7                      9201          9201   \n",
       "Flan-T5-Large             8                      9164          9164   \n",
       "Flan-T5-Small             9                      9144          9144   \n",
       "Flan-T5-XL                10                     8986          8986   \n",
       "Flan-T5-XXL               11                     9113          9113   \n",
       "GLM-130B                  12                     9071          9071   \n",
       "GPT-3.5                   13                    52346         52346   \n",
       "GPT-4                     14                     8852          8852   \n",
       "GPT-J                     15                     7580          7580   \n",
       "GPT-NeoX                  16                     6821          6821   \n",
       "Gemini-Pro                17                      613           613   \n",
       "Goliath-120B              18                      734           734   \n",
       "Human                     19                   347692        347692   \n",
       "LLaMA-13B                 20                     9282          9282   \n",
       "LLaMA-2-70B               21                     5000          5000   \n",
       "LLaMA-2-7B                22                      409           409   \n",
       "LLaMA-30B                 23                     9340          9340   \n",
       "LLaMA-65B                 24                     9321          9321   \n",
       "LLaMA-7B                  25                     9271          9271   \n",
       "LZLV-70B                  26                     5143          5143   \n",
       "Mistral-7B                27                    10439         10439   \n",
       "Mistral-7B-OpenOrca       28                     3058          3058   \n",
       "Mixtral-8x7B              29                     2865          2865   \n",
       "MythoMax-L2-13B           30                     6147          6147   \n",
       "Neural-Chat-7B            31                     5858          5858   \n",
       "Noromaid-20B              32                     1326          1326   \n",
       "Nous-Capybara-34B         33                     3327          3327   \n",
       "Nous-Capybara-7B          34                     3204          3204   \n",
       "Nous-Hermes-LLaMA-2-13B   35                    12686         12686   \n",
       "Nous-Hermes-LLaMA-2-70B   36                      650           650   \n",
       "OPT-1.3B                  37                    18467         18467   \n",
       "OPT-125M                  38                     8823          8823   \n",
       "OPT-13B                   39                     8087          8087   \n",
       "OPT-2.7B                  40                     9134          9134   \n",
       "OPT-30B                   41                    18055         18055   \n",
       "OPT-350M                  42                     8747          8747   \n",
       "OPT-6.7B                  43                     8838          8838   \n",
       "OpenChat-3.5              44                     9402          9402   \n",
       "OpenHermes-2-Mistral-7B   45                      623           623   \n",
       "OpenHermes-2.5-Mistral-7B 46                      612           612   \n",
       "PaLM-2                    47                     9510          9510   \n",
       "Psyfighter-13B            48                     4375          4375   \n",
       "Psyfighter-2-13B          49                     2743          2743   \n",
       "RWKV-5-World-3B           50                      496           496   \n",
       "StripedHyena-Nous-7B      51                     3520          3520   \n",
       "T0-11B                    52                     8705          8705   \n",
       "T0-3B                     53                     9219          9219   \n",
       "Text-Ada-001              54                      691           691   \n",
       "Text-Babbage-001          55                      875           875   \n",
       "Text-Curie-001            56                     1008          1008   \n",
       "Text-Davinci-001          57                     1120          1120   \n",
       "Text-Davinci-002          58                    21436         21436   \n",
       "Text-Davinci-003          59                    22860         22860   \n",
       "\n",
       "                                         embedding_48  embedding_49  \n",
       "source                    sourceEncoded                              \n",
       "Bloom-7B                  0                      8812          8812  \n",
       "Claude-Instant-v1         1                      7147          7147  \n",
       "Claude-v1                 2                      3158          3158  \n",
       "Cohere-Command            3                       390           390  \n",
       "Dolphin-2.5-Mixtral-8x7B  4                       228           228  \n",
       "Dolphin-Mixtral-8x7B      5                       407           407  \n",
       "Falcon-180B               6                      4745          4745  \n",
       "Flan-T5-Base              7                      9201          9201  \n",
       "Flan-T5-Large             8                      9164          9164  \n",
       "Flan-T5-Small             9                      9144          9144  \n",
       "Flan-T5-XL                10                     8986          8986  \n",
       "Flan-T5-XXL               11                     9113          9113  \n",
       "GLM-130B                  12                     9071          9071  \n",
       "GPT-3.5                   13                    52346         52346  \n",
       "GPT-4                     14                     8852          8852  \n",
       "GPT-J                     15                     7580          7580  \n",
       "GPT-NeoX                  16                     6821          6821  \n",
       "Gemini-Pro                17                      613           613  \n",
       "Goliath-120B              18                      734           734  \n",
       "Human                     19                   347692        347692  \n",
       "LLaMA-13B                 20                     9282          9282  \n",
       "LLaMA-2-70B               21                     5000          5000  \n",
       "LLaMA-2-7B                22                      409           409  \n",
       "LLaMA-30B                 23                     9340          9340  \n",
       "LLaMA-65B                 24                     9321          9321  \n",
       "LLaMA-7B                  25                     9271          9271  \n",
       "LZLV-70B                  26                     5143          5143  \n",
       "Mistral-7B                27                    10439         10439  \n",
       "Mistral-7B-OpenOrca       28                     3058          3058  \n",
       "Mixtral-8x7B              29                     2865          2865  \n",
       "MythoMax-L2-13B           30                     6147          6147  \n",
       "Neural-Chat-7B            31                     5858          5858  \n",
       "Noromaid-20B              32                     1326          1326  \n",
       "Nous-Capybara-34B         33                     3327          3327  \n",
       "Nous-Capybara-7B          34                     3204          3204  \n",
       "Nous-Hermes-LLaMA-2-13B   35                    12686         12686  \n",
       "Nous-Hermes-LLaMA-2-70B   36                      650           650  \n",
       "OPT-1.3B                  37                    18467         18467  \n",
       "OPT-125M                  38                     8823          8823  \n",
       "OPT-13B                   39                     8087          8087  \n",
       "OPT-2.7B                  40                     9134          9134  \n",
       "OPT-30B                   41                    18055         18055  \n",
       "OPT-350M                  42                     8747          8747  \n",
       "OPT-6.7B                  43                     8838          8838  \n",
       "OpenChat-3.5              44                     9402          9402  \n",
       "OpenHermes-2-Mistral-7B   45                      623           623  \n",
       "OpenHermes-2.5-Mistral-7B 46                      612           612  \n",
       "PaLM-2                    47                     9510          9510  \n",
       "Psyfighter-13B            48                     4375          4375  \n",
       "Psyfighter-2-13B          49                     2743          2743  \n",
       "RWKV-5-World-3B           50                      496           496  \n",
       "StripedHyena-Nous-7B      51                     3520          3520  \n",
       "T0-11B                    52                     8705          8705  \n",
       "T0-3B                     53                     9219          9219  \n",
       "Text-Ada-001              54                      691           691  \n",
       "Text-Babbage-001          55                      875           875  \n",
       "Text-Curie-001            56                     1008          1008  \n",
       "Text-Davinci-001          57                     1120          1120  \n",
       "Text-Davinci-002          58                    21436         21436  \n",
       "Text-Davinci-003          59                    22860         22860  \n",
       "\n",
       "[60 rows x 54 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = data.groupby(['source', 'sourceEncoded']).count()\n",
    "labels.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f205347e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "      <th>sourceEncoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.806630</td>\n",
       "      <td>57.30</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.008560</td>\n",
       "      <td>0.095722</td>\n",
       "      <td>-0.049095</td>\n",
       "      <td>-0.118440</td>\n",
       "      <td>-0.004019</td>\n",
       "      <td>0.043696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>-0.041666</td>\n",
       "      <td>-0.005266</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>-0.071304</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>-0.012865</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.661255</td>\n",
       "      <td>53.21</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>0.070761</td>\n",
       "      <td>-0.099866</td>\n",
       "      <td>0.107777</td>\n",
       "      <td>0.008168</td>\n",
       "      <td>-0.063522</td>\n",
       "      <td>0.097034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043269</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>-0.005574</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>0.030465</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.020913</td>\n",
       "      <td>0.060853</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.718354</td>\n",
       "      <td>61.97</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>0.164173</td>\n",
       "      <td>0.117847</td>\n",
       "      <td>-0.012992</td>\n",
       "      <td>0.088472</td>\n",
       "      <td>0.097658</td>\n",
       "      <td>-0.002207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008409</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>-0.012316</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.005499</td>\n",
       "      <td>-0.011693</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.564532</td>\n",
       "      <td>27.86</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.179447</td>\n",
       "      <td>0.010308</td>\n",
       "      <td>0.155961</td>\n",
       "      <td>0.029293</td>\n",
       "      <td>0.099195</td>\n",
       "      <td>-0.101426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>-0.020475</td>\n",
       "      <td>-0.006033</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>-0.019899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.752860</td>\n",
       "      <td>61.67</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>0.159706</td>\n",
       "      <td>0.083560</td>\n",
       "      <td>-0.074277</td>\n",
       "      <td>0.031704</td>\n",
       "      <td>0.066774</td>\n",
       "      <td>0.062544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.007070</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>-0.017871</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.008097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788917</th>\n",
       "      <td>0.420610</td>\n",
       "      <td>36.22</td>\n",
       "      <td>33</td>\n",
       "      <td>61</td>\n",
       "      <td>-0.157033</td>\n",
       "      <td>-0.008564</td>\n",
       "      <td>-0.079678</td>\n",
       "      <td>0.104863</td>\n",
       "      <td>-0.095362</td>\n",
       "      <td>0.039880</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>-0.020148</td>\n",
       "      <td>-0.023085</td>\n",
       "      <td>-0.030199</td>\n",
       "      <td>-0.012152</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>-0.007202</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788918</th>\n",
       "      <td>0.395532</td>\n",
       "      <td>29.08</td>\n",
       "      <td>27</td>\n",
       "      <td>66</td>\n",
       "      <td>-0.282313</td>\n",
       "      <td>0.034885</td>\n",
       "      <td>-0.078380</td>\n",
       "      <td>-0.014602</td>\n",
       "      <td>-0.034506</td>\n",
       "      <td>0.077010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023404</td>\n",
       "      <td>0.037557</td>\n",
       "      <td>0.026361</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.023823</td>\n",
       "      <td>-0.009165</td>\n",
       "      <td>-0.004096</td>\n",
       "      <td>-0.016606</td>\n",
       "      <td>0.020802</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788919</th>\n",
       "      <td>0.447761</td>\n",
       "      <td>47.22</td>\n",
       "      <td>25</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.264905</td>\n",
       "      <td>-0.011840</td>\n",
       "      <td>0.106972</td>\n",
       "      <td>0.034591</td>\n",
       "      <td>-0.192508</td>\n",
       "      <td>0.167850</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008166</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>-0.001044</td>\n",
       "      <td>-0.037097</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>0.039127</td>\n",
       "      <td>0.018915</td>\n",
       "      <td>0.072912</td>\n",
       "      <td>-0.009205</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788920</th>\n",
       "      <td>0.476351</td>\n",
       "      <td>28.77</td>\n",
       "      <td>21</td>\n",
       "      <td>512</td>\n",
       "      <td>-0.263766</td>\n",
       "      <td>0.064379</td>\n",
       "      <td>-0.021544</td>\n",
       "      <td>-0.112702</td>\n",
       "      <td>-0.044006</td>\n",
       "      <td>0.123673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035284</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.023736</td>\n",
       "      <td>0.030208</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>-0.011754</td>\n",
       "      <td>-0.010964</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.014060</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788921</th>\n",
       "      <td>0.404580</td>\n",
       "      <td>31.82</td>\n",
       "      <td>31</td>\n",
       "      <td>67</td>\n",
       "      <td>-0.193548</td>\n",
       "      <td>0.069151</td>\n",
       "      <td>-0.109348</td>\n",
       "      <td>0.181288</td>\n",
       "      <td>-0.049860</td>\n",
       "      <td>0.040569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020792</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>0.009237</td>\n",
       "      <td>0.019272</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.027279</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>788922 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lexical_diversity  readability_score  sentence_count  prompt_length  \\\n",
       "0                0.806630              57.30               7              9   \n",
       "1                0.661255              53.21              40              9   \n",
       "2                0.718354              61.97              14              9   \n",
       "3                0.564532              27.86              25              9   \n",
       "4                0.752860              61.67              19              9   \n",
       "...                   ...                ...             ...            ...   \n",
       "788917           0.420610              36.22              33             61   \n",
       "788918           0.395532              29.08              27             66   \n",
       "788919           0.447761              47.22              25             52   \n",
       "788920           0.476351              28.77              21            512   \n",
       "788921           0.404580              31.82              31             67   \n",
       "\n",
       "        embedding_0  embedding_1  embedding_2  embedding_3  embedding_4  \\\n",
       "0          0.008560     0.095722    -0.049095    -0.118440    -0.004019   \n",
       "1          0.070761    -0.099866     0.107777     0.008168    -0.063522   \n",
       "2          0.164173     0.117847    -0.012992     0.088472     0.097658   \n",
       "3         -0.179447     0.010308     0.155961     0.029293     0.099195   \n",
       "4          0.159706     0.083560    -0.074277     0.031704     0.066774   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "788917    -0.157033    -0.008564    -0.079678     0.104863    -0.095362   \n",
       "788918    -0.282313     0.034885    -0.078380    -0.014602    -0.034506   \n",
       "788919    -0.264905    -0.011840     0.106972     0.034591    -0.192508   \n",
       "788920    -0.263766     0.064379    -0.021544    -0.112702    -0.044006   \n",
       "788921    -0.193548     0.069151    -0.109348     0.181288    -0.049860   \n",
       "\n",
       "        embedding_5  ...  embedding_41  embedding_42  embedding_43  \\\n",
       "0          0.043696  ...     -0.001925     -0.041666     -0.005266   \n",
       "1          0.097034  ...     -0.043269      0.003721     -0.005574   \n",
       "2         -0.002207  ...     -0.008409      0.008066     -0.012316   \n",
       "3         -0.101426  ...      0.012030     -0.020475     -0.006033   \n",
       "4          0.062544  ...      0.014534      0.007382     -0.016189   \n",
       "...             ...  ...           ...           ...           ...   \n",
       "788917     0.039880  ...     -0.001365     -0.020148     -0.023085   \n",
       "788918     0.077010  ...     -0.023404      0.037557      0.026361   \n",
       "788919     0.167850  ...     -0.008166      0.018903     -0.001044   \n",
       "788920     0.123673  ...      0.035284      0.000662      0.023736   \n",
       "788921     0.040569  ...     -0.020792      0.003079      0.026649   \n",
       "\n",
       "        embedding_44  embedding_45  embedding_46  embedding_47  embedding_48  \\\n",
       "0           0.034543      0.002532     -0.071304      0.014727     -0.012865   \n",
       "1           0.030584     -0.006616      0.030465      0.000941      0.020913   \n",
       "2           0.007549     -0.000401     -0.001133     -0.005499     -0.011693   \n",
       "3           0.002823     -0.000594      0.000835      0.001109      0.009936   \n",
       "4           0.007070      0.001430     -0.017871      0.004868      0.010563   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "788917     -0.030199     -0.012152      0.002733     -0.000128      0.022612   \n",
       "788918     -0.008231      0.023823     -0.009165     -0.004096     -0.016606   \n",
       "788919     -0.037097      0.025732      0.039127      0.018915      0.072912   \n",
       "788920      0.030208      0.013736     -0.011754     -0.010964      0.000265   \n",
       "788921      0.001552      0.009237      0.019272      0.000913      0.027279   \n",
       "\n",
       "        embedding_49  sourceEncoded  \n",
       "0           0.004744              0  \n",
       "1           0.060853              0  \n",
       "2           0.000179              0  \n",
       "3          -0.019899              0  \n",
       "4           0.008097              0  \n",
       "...              ...            ...  \n",
       "788917     -0.007202             62  \n",
       "788918      0.020802             62  \n",
       "788919     -0.009205             62  \n",
       "788920      0.014060             62  \n",
       "788921      0.002167             62  \n",
       "\n",
       "[788922 rows x 55 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(['source'], axis=1, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "282d5937",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['sentence_count', 'prompt_length'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c57bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44c9b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f943a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "      <th>sourceEncoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.347368</td>\n",
       "      <td>63.80</td>\n",
       "      <td>-0.014933</td>\n",
       "      <td>-0.038845</td>\n",
       "      <td>-0.158053</td>\n",
       "      <td>0.004646</td>\n",
       "      <td>-0.042694</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>-0.054245</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002275</td>\n",
       "      <td>0.044455</td>\n",
       "      <td>-0.010944</td>\n",
       "      <td>0.006498</td>\n",
       "      <td>0.010042</td>\n",
       "      <td>-0.015255</td>\n",
       "      <td>-0.014940</td>\n",
       "      <td>-0.025007</td>\n",
       "      <td>0.015603</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.541850</td>\n",
       "      <td>74.90</td>\n",
       "      <td>0.217244</td>\n",
       "      <td>-0.104750</td>\n",
       "      <td>0.027835</td>\n",
       "      <td>0.139416</td>\n",
       "      <td>-0.114102</td>\n",
       "      <td>-0.058512</td>\n",
       "      <td>0.028179</td>\n",
       "      <td>0.040548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>-0.003890</td>\n",
       "      <td>0.028801</td>\n",
       "      <td>0.005993</td>\n",
       "      <td>-0.012156</td>\n",
       "      <td>-0.046456</td>\n",
       "      <td>-0.001898</td>\n",
       "      <td>-0.016560</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287444</td>\n",
       "      <td>50.46</td>\n",
       "      <td>-0.087677</td>\n",
       "      <td>-0.055495</td>\n",
       "      <td>-0.086990</td>\n",
       "      <td>-0.088636</td>\n",
       "      <td>0.046496</td>\n",
       "      <td>-0.093805</td>\n",
       "      <td>-0.117377</td>\n",
       "      <td>0.063579</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046124</td>\n",
       "      <td>-0.024574</td>\n",
       "      <td>0.012555</td>\n",
       "      <td>-0.005401</td>\n",
       "      <td>0.023001</td>\n",
       "      <td>-0.054847</td>\n",
       "      <td>-0.023912</td>\n",
       "      <td>0.021516</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.820896</td>\n",
       "      <td>81.83</td>\n",
       "      <td>0.218941</td>\n",
       "      <td>0.041171</td>\n",
       "      <td>0.088468</td>\n",
       "      <td>-0.016718</td>\n",
       "      <td>-0.048112</td>\n",
       "      <td>0.088717</td>\n",
       "      <td>0.053958</td>\n",
       "      <td>-0.093942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011755</td>\n",
       "      <td>0.023686</td>\n",
       "      <td>0.010145</td>\n",
       "      <td>-0.022993</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>-0.032522</td>\n",
       "      <td>0.050134</td>\n",
       "      <td>0.014272</td>\n",
       "      <td>0.004789</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.563025</td>\n",
       "      <td>58.62</td>\n",
       "      <td>0.012391</td>\n",
       "      <td>0.250100</td>\n",
       "      <td>0.019483</td>\n",
       "      <td>-0.127520</td>\n",
       "      <td>0.041142</td>\n",
       "      <td>0.128489</td>\n",
       "      <td>-0.001994</td>\n",
       "      <td>-0.089824</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028753</td>\n",
       "      <td>-0.013274</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>0.027242</td>\n",
       "      <td>-0.008143</td>\n",
       "      <td>0.025566</td>\n",
       "      <td>-0.036693</td>\n",
       "      <td>-0.029620</td>\n",
       "      <td>0.075345</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788917</th>\n",
       "      <td>0.293269</td>\n",
       "      <td>84.88</td>\n",
       "      <td>0.351386</td>\n",
       "      <td>0.202890</td>\n",
       "      <td>0.017317</td>\n",
       "      <td>0.103853</td>\n",
       "      <td>0.129875</td>\n",
       "      <td>0.044663</td>\n",
       "      <td>-0.118230</td>\n",
       "      <td>0.100095</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012970</td>\n",
       "      <td>0.028894</td>\n",
       "      <td>0.008365</td>\n",
       "      <td>0.023248</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>-0.014508</td>\n",
       "      <td>0.028956</td>\n",
       "      <td>-0.005257</td>\n",
       "      <td>-0.009287</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788918</th>\n",
       "      <td>0.448795</td>\n",
       "      <td>44.58</td>\n",
       "      <td>-0.193499</td>\n",
       "      <td>-0.113607</td>\n",
       "      <td>0.015833</td>\n",
       "      <td>0.152694</td>\n",
       "      <td>-0.143946</td>\n",
       "      <td>-0.001185</td>\n",
       "      <td>0.016983</td>\n",
       "      <td>-0.154293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028422</td>\n",
       "      <td>-0.003345</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.020102</td>\n",
       "      <td>0.026419</td>\n",
       "      <td>0.010614</td>\n",
       "      <td>-0.017537</td>\n",
       "      <td>-0.016065</td>\n",
       "      <td>-0.017739</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788919</th>\n",
       "      <td>0.862745</td>\n",
       "      <td>72.87</td>\n",
       "      <td>0.047090</td>\n",
       "      <td>-0.202783</td>\n",
       "      <td>-0.112934</td>\n",
       "      <td>-0.196180</td>\n",
       "      <td>-0.037219</td>\n",
       "      <td>-0.073335</td>\n",
       "      <td>-0.025841</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063111</td>\n",
       "      <td>0.020878</td>\n",
       "      <td>-0.027317</td>\n",
       "      <td>0.011153</td>\n",
       "      <td>-0.001443</td>\n",
       "      <td>-0.016620</td>\n",
       "      <td>-0.010329</td>\n",
       "      <td>0.011247</td>\n",
       "      <td>-0.003789</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788920</th>\n",
       "      <td>0.254355</td>\n",
       "      <td>48.54</td>\n",
       "      <td>-0.216230</td>\n",
       "      <td>-0.000708</td>\n",
       "      <td>-0.006520</td>\n",
       "      <td>-0.044850</td>\n",
       "      <td>0.029534</td>\n",
       "      <td>-0.020811</td>\n",
       "      <td>-0.040853</td>\n",
       "      <td>-0.017959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016097</td>\n",
       "      <td>-0.002862</td>\n",
       "      <td>0.019315</td>\n",
       "      <td>-0.000383</td>\n",
       "      <td>-0.005775</td>\n",
       "      <td>0.005119</td>\n",
       "      <td>-0.019875</td>\n",
       "      <td>0.008745</td>\n",
       "      <td>0.026813</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788921</th>\n",
       "      <td>0.467492</td>\n",
       "      <td>76.05</td>\n",
       "      <td>0.202857</td>\n",
       "      <td>-0.029768</td>\n",
       "      <td>-0.035080</td>\n",
       "      <td>-0.063095</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>-0.027869</td>\n",
       "      <td>0.005226</td>\n",
       "      <td>-0.081838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010569</td>\n",
       "      <td>-0.003877</td>\n",
       "      <td>-0.026599</td>\n",
       "      <td>0.026948</td>\n",
       "      <td>-0.004177</td>\n",
       "      <td>-0.012035</td>\n",
       "      <td>0.016049</td>\n",
       "      <td>0.013764</td>\n",
       "      <td>0.008026</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>788922 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lexical_diversity  readability_score  embedding_0  embedding_1  \\\n",
       "0                0.347368              63.80    -0.014933    -0.038845   \n",
       "1                0.541850              74.90     0.217244    -0.104750   \n",
       "2                0.287444              50.46    -0.087677    -0.055495   \n",
       "3                0.820896              81.83     0.218941     0.041171   \n",
       "4                0.563025              58.62     0.012391     0.250100   \n",
       "...                   ...                ...          ...          ...   \n",
       "788917           0.293269              84.88     0.351386     0.202890   \n",
       "788918           0.448795              44.58    -0.193499    -0.113607   \n",
       "788919           0.862745              72.87     0.047090    -0.202783   \n",
       "788920           0.254355              48.54    -0.216230    -0.000708   \n",
       "788921           0.467492              76.05     0.202857    -0.029768   \n",
       "\n",
       "        embedding_2  embedding_3  embedding_4  embedding_5  embedding_6  \\\n",
       "0         -0.158053     0.004646    -0.042694     0.012060    -0.054245   \n",
       "1          0.027835     0.139416    -0.114102    -0.058512     0.028179   \n",
       "2         -0.086990    -0.088636     0.046496    -0.093805    -0.117377   \n",
       "3          0.088468    -0.016718    -0.048112     0.088717     0.053958   \n",
       "4          0.019483    -0.127520     0.041142     0.128489    -0.001994   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "788917     0.017317     0.103853     0.129875     0.044663    -0.118230   \n",
       "788918     0.015833     0.152694    -0.143946    -0.001185     0.016983   \n",
       "788919    -0.112934    -0.196180    -0.037219    -0.073335    -0.025841   \n",
       "788920    -0.006520    -0.044850     0.029534    -0.020811    -0.040853   \n",
       "788921    -0.035080    -0.063095     0.001165    -0.027869     0.005226   \n",
       "\n",
       "        embedding_7  ...  embedding_41  embedding_42  embedding_43  \\\n",
       "0          0.000397  ...     -0.002275      0.044455     -0.010944   \n",
       "1          0.040548  ...      0.003751      0.010945     -0.003890   \n",
       "2          0.063579  ...     -0.046124     -0.024574      0.012555   \n",
       "3         -0.093942  ...      0.011755      0.023686      0.010145   \n",
       "4         -0.089824  ...     -0.028753     -0.013274      0.004695   \n",
       "...             ...  ...           ...           ...           ...   \n",
       "788917     0.100095  ...     -0.012970      0.028894      0.008365   \n",
       "788918    -0.154293  ...      0.028422     -0.003345      0.000912   \n",
       "788919     0.035394  ...     -0.063111      0.020878     -0.027317   \n",
       "788920    -0.017959  ...      0.016097     -0.002862      0.019315   \n",
       "788921    -0.081838  ...     -0.010569     -0.003877     -0.026599   \n",
       "\n",
       "        embedding_44  embedding_45  embedding_46  embedding_47  embedding_48  \\\n",
       "0           0.006498      0.010042     -0.015255     -0.014940     -0.025007   \n",
       "1           0.028801      0.005993     -0.012156     -0.046456     -0.001898   \n",
       "2          -0.005401      0.023001     -0.054847     -0.023912      0.021516   \n",
       "3          -0.022993      0.001508     -0.032522      0.050134      0.014272   \n",
       "4           0.027242     -0.008143      0.025566     -0.036693     -0.029620   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "788917      0.023248      0.007646     -0.014508      0.028956     -0.005257   \n",
       "788918      0.020102      0.026419      0.010614     -0.017537     -0.016065   \n",
       "788919      0.011153     -0.001443     -0.016620     -0.010329      0.011247   \n",
       "788920     -0.000383     -0.005775      0.005119     -0.019875      0.008745   \n",
       "788921      0.026948     -0.004177     -0.012035      0.016049      0.013764   \n",
       "\n",
       "        embedding_49  sourceEncoded  \n",
       "0           0.015603             19  \n",
       "1          -0.016560             19  \n",
       "2           0.001037             19  \n",
       "3           0.004789             19  \n",
       "4           0.075345             19  \n",
       "...              ...            ...  \n",
       "788917     -0.009287             20  \n",
       "788918     -0.017739             44  \n",
       "788919     -0.003789             41  \n",
       "788920      0.026813             19  \n",
       "788921      0.008026             19  \n",
       "\n",
       "[788922 rows x 53 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4c32637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only 5 LLM classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "866d67f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    347692\n",
       "13     52346\n",
       "59     22860\n",
       "58     21436\n",
       "37     18467\n",
       "41     18055\n",
       "35     12686\n",
       "27     10439\n",
       "47      9510\n",
       "44      9402\n",
       "Name: sourceEncoded, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = data['sourceEncoded'].value_counts()\n",
    "top.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "344fca36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "      <th>sourceEncoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.769663</td>\n",
       "      <td>26.64</td>\n",
       "      <td>-0.168179</td>\n",
       "      <td>0.077083</td>\n",
       "      <td>0.115720</td>\n",
       "      <td>0.010052</td>\n",
       "      <td>-0.051142</td>\n",
       "      <td>-0.122010</td>\n",
       "      <td>-0.025270</td>\n",
       "      <td>-0.031395</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052069</td>\n",
       "      <td>-0.041864</td>\n",
       "      <td>-0.063332</td>\n",
       "      <td>-0.004891</td>\n",
       "      <td>0.041612</td>\n",
       "      <td>-0.008916</td>\n",
       "      <td>-0.037787</td>\n",
       "      <td>-0.015231</td>\n",
       "      <td>-0.011546</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.610294</td>\n",
       "      <td>82.04</td>\n",
       "      <td>0.360020</td>\n",
       "      <td>0.061433</td>\n",
       "      <td>0.028456</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>0.082802</td>\n",
       "      <td>-0.080595</td>\n",
       "      <td>-0.016215</td>\n",
       "      <td>0.032471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004683</td>\n",
       "      <td>0.011520</td>\n",
       "      <td>0.027406</td>\n",
       "      <td>-0.013488</td>\n",
       "      <td>-0.020637</td>\n",
       "      <td>0.006689</td>\n",
       "      <td>0.026539</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.437086</td>\n",
       "      <td>25.08</td>\n",
       "      <td>-0.321289</td>\n",
       "      <td>0.052606</td>\n",
       "      <td>0.136353</td>\n",
       "      <td>-0.100970</td>\n",
       "      <td>-0.064315</td>\n",
       "      <td>0.103079</td>\n",
       "      <td>0.008150</td>\n",
       "      <td>-0.010910</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014132</td>\n",
       "      <td>-0.005759</td>\n",
       "      <td>-0.017750</td>\n",
       "      <td>0.017853</td>\n",
       "      <td>0.011929</td>\n",
       "      <td>0.016674</td>\n",
       "      <td>-0.001780</td>\n",
       "      <td>-0.011683</td>\n",
       "      <td>-0.030882</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.756410</td>\n",
       "      <td>63.73</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>-0.143843</td>\n",
       "      <td>-0.119845</td>\n",
       "      <td>-0.056691</td>\n",
       "      <td>0.057974</td>\n",
       "      <td>0.042479</td>\n",
       "      <td>-0.160052</td>\n",
       "      <td>-0.023304</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037873</td>\n",
       "      <td>0.022945</td>\n",
       "      <td>-0.018770</td>\n",
       "      <td>0.011276</td>\n",
       "      <td>-0.014351</td>\n",
       "      <td>0.051906</td>\n",
       "      <td>0.022502</td>\n",
       "      <td>-0.017162</td>\n",
       "      <td>-0.004475</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.652174</td>\n",
       "      <td>105.45</td>\n",
       "      <td>0.330286</td>\n",
       "      <td>-0.323615</td>\n",
       "      <td>-0.138482</td>\n",
       "      <td>-0.006044</td>\n",
       "      <td>-0.104217</td>\n",
       "      <td>-0.142862</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>0.200493</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016747</td>\n",
       "      <td>-0.015484</td>\n",
       "      <td>-0.006765</td>\n",
       "      <td>0.025826</td>\n",
       "      <td>0.014034</td>\n",
       "      <td>0.044829</td>\n",
       "      <td>0.073610</td>\n",
       "      <td>-0.015819</td>\n",
       "      <td>0.007446</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788899</th>\n",
       "      <td>0.365607</td>\n",
       "      <td>31.21</td>\n",
       "      <td>-0.296132</td>\n",
       "      <td>0.014905</td>\n",
       "      <td>-0.067647</td>\n",
       "      <td>-0.007877</td>\n",
       "      <td>-0.113005</td>\n",
       "      <td>0.197896</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.055768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022513</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.023398</td>\n",
       "      <td>0.070388</td>\n",
       "      <td>-0.010765</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>-0.032236</td>\n",
       "      <td>0.021076</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788901</th>\n",
       "      <td>0.498542</td>\n",
       "      <td>50.06</td>\n",
       "      <td>0.040016</td>\n",
       "      <td>-0.110140</td>\n",
       "      <td>-0.091529</td>\n",
       "      <td>0.132227</td>\n",
       "      <td>-0.052099</td>\n",
       "      <td>-0.019278</td>\n",
       "      <td>0.199577</td>\n",
       "      <td>0.016658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026841</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>-0.020538</td>\n",
       "      <td>-0.029363</td>\n",
       "      <td>0.016880</td>\n",
       "      <td>-0.034594</td>\n",
       "      <td>-0.037387</td>\n",
       "      <td>0.016397</td>\n",
       "      <td>0.030583</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788905</th>\n",
       "      <td>0.723684</td>\n",
       "      <td>65.93</td>\n",
       "      <td>0.092741</td>\n",
       "      <td>-0.373570</td>\n",
       "      <td>-0.124836</td>\n",
       "      <td>-0.192118</td>\n",
       "      <td>-0.051675</td>\n",
       "      <td>-0.119680</td>\n",
       "      <td>-0.058971</td>\n",
       "      <td>0.090961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033691</td>\n",
       "      <td>-0.007603</td>\n",
       "      <td>-0.023790</td>\n",
       "      <td>0.041450</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.005436</td>\n",
       "      <td>-0.003637</td>\n",
       "      <td>0.026415</td>\n",
       "      <td>-0.015854</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788915</th>\n",
       "      <td>0.434132</td>\n",
       "      <td>77.47</td>\n",
       "      <td>0.244636</td>\n",
       "      <td>-0.060586</td>\n",
       "      <td>-0.166191</td>\n",
       "      <td>-0.000782</td>\n",
       "      <td>-0.092432</td>\n",
       "      <td>-0.070292</td>\n",
       "      <td>0.093273</td>\n",
       "      <td>0.061433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029490</td>\n",
       "      <td>0.038883</td>\n",
       "      <td>-0.023161</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>-0.034493</td>\n",
       "      <td>-0.074051</td>\n",
       "      <td>-0.037351</td>\n",
       "      <td>0.006461</td>\n",
       "      <td>-0.027971</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788919</th>\n",
       "      <td>0.862745</td>\n",
       "      <td>72.87</td>\n",
       "      <td>0.047090</td>\n",
       "      <td>-0.202783</td>\n",
       "      <td>-0.112934</td>\n",
       "      <td>-0.196180</td>\n",
       "      <td>-0.037219</td>\n",
       "      <td>-0.073335</td>\n",
       "      <td>-0.025841</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063111</td>\n",
       "      <td>0.020878</td>\n",
       "      <td>-0.027317</td>\n",
       "      <td>0.011153</td>\n",
       "      <td>-0.001443</td>\n",
       "      <td>-0.016620</td>\n",
       "      <td>-0.010329</td>\n",
       "      <td>0.011247</td>\n",
       "      <td>-0.003789</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133164 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lexical_diversity  readability_score  embedding_0  embedding_1  \\\n",
       "6                0.769663              26.64    -0.168179     0.077083   \n",
       "7                0.610294              82.04     0.360020     0.061433   \n",
       "34               0.437086              25.08    -0.321289     0.052606   \n",
       "42               0.756410              63.73     0.047950    -0.143843   \n",
       "54               0.652174             105.45     0.330286    -0.323615   \n",
       "...                   ...                ...          ...          ...   \n",
       "788899           0.365607              31.21    -0.296132     0.014905   \n",
       "788901           0.498542              50.06     0.040016    -0.110140   \n",
       "788905           0.723684              65.93     0.092741    -0.373570   \n",
       "788915           0.434132              77.47     0.244636    -0.060586   \n",
       "788919           0.862745              72.87     0.047090    -0.202783   \n",
       "\n",
       "        embedding_2  embedding_3  embedding_4  embedding_5  embedding_6  \\\n",
       "6          0.115720     0.010052    -0.051142    -0.122010    -0.025270   \n",
       "7          0.028456     0.006923     0.082802    -0.080595    -0.016215   \n",
       "34         0.136353    -0.100970    -0.064315     0.103079     0.008150   \n",
       "42        -0.119845    -0.056691     0.057974     0.042479    -0.160052   \n",
       "54        -0.138482    -0.006044    -0.104217    -0.142862     0.006063   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "788899    -0.067647    -0.007877    -0.113005     0.197896     0.071460   \n",
       "788901    -0.091529     0.132227    -0.052099    -0.019278     0.199577   \n",
       "788905    -0.124836    -0.192118    -0.051675    -0.119680    -0.058971   \n",
       "788915    -0.166191    -0.000782    -0.092432    -0.070292     0.093273   \n",
       "788919    -0.112934    -0.196180    -0.037219    -0.073335    -0.025841   \n",
       "\n",
       "        embedding_7  ...  embedding_41  embedding_42  embedding_43  \\\n",
       "6         -0.031395  ...     -0.052069     -0.041864     -0.063332   \n",
       "7          0.032471  ...     -0.004683      0.011520      0.027406   \n",
       "34        -0.010910  ...     -0.014132     -0.005759     -0.017750   \n",
       "42        -0.023304  ...     -0.037873      0.022945     -0.018770   \n",
       "54         0.200493  ...     -0.016747     -0.015484     -0.006765   \n",
       "...             ...  ...           ...           ...           ...   \n",
       "788899     0.055768  ...      0.022513      0.002828      0.023398   \n",
       "788901     0.016658  ...      0.026841      0.002417     -0.020538   \n",
       "788905     0.090961  ...     -0.033691     -0.007603     -0.023790   \n",
       "788915     0.061433  ...      0.029490      0.038883     -0.023161   \n",
       "788919     0.035394  ...     -0.063111      0.020878     -0.027317   \n",
       "\n",
       "        embedding_44  embedding_45  embedding_46  embedding_47  embedding_48  \\\n",
       "6          -0.004891      0.041612     -0.008916     -0.037787     -0.015231   \n",
       "7          -0.013488     -0.020637      0.006689      0.026539      0.000174   \n",
       "34          0.017853      0.011929      0.016674     -0.001780     -0.011683   \n",
       "42          0.011276     -0.014351      0.051906      0.022502     -0.017162   \n",
       "54          0.025826      0.014034      0.044829      0.073610     -0.015819   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "788899      0.070388     -0.010765      0.004683      0.002490     -0.032236   \n",
       "788901     -0.029363      0.016880     -0.034594     -0.037387      0.016397   \n",
       "788905      0.041450      0.000611      0.005436     -0.003637      0.026415   \n",
       "788915      0.003190     -0.034493     -0.074051     -0.037351      0.006461   \n",
       "788919      0.011153     -0.001443     -0.016620     -0.010329      0.011247   \n",
       "\n",
       "        embedding_49  sourceEncoded  \n",
       "6          -0.011546             37  \n",
       "7           0.001229             58  \n",
       "34         -0.030882             13  \n",
       "42         -0.004475             58  \n",
       "54          0.007446             59  \n",
       "...              ...            ...  \n",
       "788899      0.021076             13  \n",
       "788901      0.030583             13  \n",
       "788905     -0.015854             58  \n",
       "788915     -0.027971             59  \n",
       "788919     -0.003789             41  \n",
       "\n",
       "[133164 rows x 53 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectedDataFrame = data[data['sourceEncoded'].isin([13, 59, 58, 37, 41])]\n",
    "selectedDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68cdd495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13    52346\n",
       "59    22860\n",
       "58    21436\n",
       "37    18467\n",
       "41    18055\n",
       "Name: sourceEncoded, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectedDataFrame['sourceEncoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca30b231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.769663</td>\n",
       "      <td>26.64</td>\n",
       "      <td>-0.168179</td>\n",
       "      <td>0.077083</td>\n",
       "      <td>0.115720</td>\n",
       "      <td>0.010052</td>\n",
       "      <td>-0.051142</td>\n",
       "      <td>-0.122010</td>\n",
       "      <td>-0.025270</td>\n",
       "      <td>-0.031395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>-0.052069</td>\n",
       "      <td>-0.041864</td>\n",
       "      <td>-0.063332</td>\n",
       "      <td>-0.004891</td>\n",
       "      <td>0.041612</td>\n",
       "      <td>-0.008916</td>\n",
       "      <td>-0.037787</td>\n",
       "      <td>-0.015231</td>\n",
       "      <td>-0.011546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.610294</td>\n",
       "      <td>82.04</td>\n",
       "      <td>0.360020</td>\n",
       "      <td>0.061433</td>\n",
       "      <td>0.028456</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>0.082802</td>\n",
       "      <td>-0.080595</td>\n",
       "      <td>-0.016215</td>\n",
       "      <td>0.032471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029178</td>\n",
       "      <td>-0.004683</td>\n",
       "      <td>0.011520</td>\n",
       "      <td>0.027406</td>\n",
       "      <td>-0.013488</td>\n",
       "      <td>-0.020637</td>\n",
       "      <td>0.006689</td>\n",
       "      <td>0.026539</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.001229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.437086</td>\n",
       "      <td>25.08</td>\n",
       "      <td>-0.321289</td>\n",
       "      <td>0.052606</td>\n",
       "      <td>0.136353</td>\n",
       "      <td>-0.100970</td>\n",
       "      <td>-0.064315</td>\n",
       "      <td>0.103079</td>\n",
       "      <td>0.008150</td>\n",
       "      <td>-0.010910</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020540</td>\n",
       "      <td>-0.014132</td>\n",
       "      <td>-0.005759</td>\n",
       "      <td>-0.017750</td>\n",
       "      <td>0.017853</td>\n",
       "      <td>0.011929</td>\n",
       "      <td>0.016674</td>\n",
       "      <td>-0.001780</td>\n",
       "      <td>-0.011683</td>\n",
       "      <td>-0.030882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.756410</td>\n",
       "      <td>63.73</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>-0.143843</td>\n",
       "      <td>-0.119845</td>\n",
       "      <td>-0.056691</td>\n",
       "      <td>0.057974</td>\n",
       "      <td>0.042479</td>\n",
       "      <td>-0.160052</td>\n",
       "      <td>-0.023304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038496</td>\n",
       "      <td>-0.037873</td>\n",
       "      <td>0.022945</td>\n",
       "      <td>-0.018770</td>\n",
       "      <td>0.011276</td>\n",
       "      <td>-0.014351</td>\n",
       "      <td>0.051906</td>\n",
       "      <td>0.022502</td>\n",
       "      <td>-0.017162</td>\n",
       "      <td>-0.004475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.652174</td>\n",
       "      <td>105.45</td>\n",
       "      <td>0.330286</td>\n",
       "      <td>-0.323615</td>\n",
       "      <td>-0.138482</td>\n",
       "      <td>-0.006044</td>\n",
       "      <td>-0.104217</td>\n",
       "      <td>-0.142862</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>0.200493</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038150</td>\n",
       "      <td>-0.016747</td>\n",
       "      <td>-0.015484</td>\n",
       "      <td>-0.006765</td>\n",
       "      <td>0.025826</td>\n",
       "      <td>0.014034</td>\n",
       "      <td>0.044829</td>\n",
       "      <td>0.073610</td>\n",
       "      <td>-0.015819</td>\n",
       "      <td>0.007446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788899</th>\n",
       "      <td>0.365607</td>\n",
       "      <td>31.21</td>\n",
       "      <td>-0.296132</td>\n",
       "      <td>0.014905</td>\n",
       "      <td>-0.067647</td>\n",
       "      <td>-0.007877</td>\n",
       "      <td>-0.113005</td>\n",
       "      <td>0.197896</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.055768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020827</td>\n",
       "      <td>0.022513</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.023398</td>\n",
       "      <td>0.070388</td>\n",
       "      <td>-0.010765</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>-0.032236</td>\n",
       "      <td>0.021076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788901</th>\n",
       "      <td>0.498542</td>\n",
       "      <td>50.06</td>\n",
       "      <td>0.040016</td>\n",
       "      <td>-0.110140</td>\n",
       "      <td>-0.091529</td>\n",
       "      <td>0.132227</td>\n",
       "      <td>-0.052099</td>\n",
       "      <td>-0.019278</td>\n",
       "      <td>0.199577</td>\n",
       "      <td>0.016658</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018988</td>\n",
       "      <td>0.026841</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>-0.020538</td>\n",
       "      <td>-0.029363</td>\n",
       "      <td>0.016880</td>\n",
       "      <td>-0.034594</td>\n",
       "      <td>-0.037387</td>\n",
       "      <td>0.016397</td>\n",
       "      <td>0.030583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788905</th>\n",
       "      <td>0.723684</td>\n",
       "      <td>65.93</td>\n",
       "      <td>0.092741</td>\n",
       "      <td>-0.373570</td>\n",
       "      <td>-0.124836</td>\n",
       "      <td>-0.192118</td>\n",
       "      <td>-0.051675</td>\n",
       "      <td>-0.119680</td>\n",
       "      <td>-0.058971</td>\n",
       "      <td>0.090961</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033102</td>\n",
       "      <td>-0.033691</td>\n",
       "      <td>-0.007603</td>\n",
       "      <td>-0.023790</td>\n",
       "      <td>0.041450</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.005436</td>\n",
       "      <td>-0.003637</td>\n",
       "      <td>0.026415</td>\n",
       "      <td>-0.015854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788915</th>\n",
       "      <td>0.434132</td>\n",
       "      <td>77.47</td>\n",
       "      <td>0.244636</td>\n",
       "      <td>-0.060586</td>\n",
       "      <td>-0.166191</td>\n",
       "      <td>-0.000782</td>\n",
       "      <td>-0.092432</td>\n",
       "      <td>-0.070292</td>\n",
       "      <td>0.093273</td>\n",
       "      <td>0.061433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.029490</td>\n",
       "      <td>0.038883</td>\n",
       "      <td>-0.023161</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>-0.034493</td>\n",
       "      <td>-0.074051</td>\n",
       "      <td>-0.037351</td>\n",
       "      <td>0.006461</td>\n",
       "      <td>-0.027971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788919</th>\n",
       "      <td>0.862745</td>\n",
       "      <td>72.87</td>\n",
       "      <td>0.047090</td>\n",
       "      <td>-0.202783</td>\n",
       "      <td>-0.112934</td>\n",
       "      <td>-0.196180</td>\n",
       "      <td>-0.037219</td>\n",
       "      <td>-0.073335</td>\n",
       "      <td>-0.025841</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033298</td>\n",
       "      <td>-0.063111</td>\n",
       "      <td>0.020878</td>\n",
       "      <td>-0.027317</td>\n",
       "      <td>0.011153</td>\n",
       "      <td>-0.001443</td>\n",
       "      <td>-0.016620</td>\n",
       "      <td>-0.010329</td>\n",
       "      <td>0.011247</td>\n",
       "      <td>-0.003789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133164 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lexical_diversity  readability_score  embedding_0  embedding_1  \\\n",
       "6                0.769663              26.64    -0.168179     0.077083   \n",
       "7                0.610294              82.04     0.360020     0.061433   \n",
       "34               0.437086              25.08    -0.321289     0.052606   \n",
       "42               0.756410              63.73     0.047950    -0.143843   \n",
       "54               0.652174             105.45     0.330286    -0.323615   \n",
       "...                   ...                ...          ...          ...   \n",
       "788899           0.365607              31.21    -0.296132     0.014905   \n",
       "788901           0.498542              50.06     0.040016    -0.110140   \n",
       "788905           0.723684              65.93     0.092741    -0.373570   \n",
       "788915           0.434132              77.47     0.244636    -0.060586   \n",
       "788919           0.862745              72.87     0.047090    -0.202783   \n",
       "\n",
       "        embedding_2  embedding_3  embedding_4  embedding_5  embedding_6  \\\n",
       "6          0.115720     0.010052    -0.051142    -0.122010    -0.025270   \n",
       "7          0.028456     0.006923     0.082802    -0.080595    -0.016215   \n",
       "34         0.136353    -0.100970    -0.064315     0.103079     0.008150   \n",
       "42        -0.119845    -0.056691     0.057974     0.042479    -0.160052   \n",
       "54        -0.138482    -0.006044    -0.104217    -0.142862     0.006063   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "788899    -0.067647    -0.007877    -0.113005     0.197896     0.071460   \n",
       "788901    -0.091529     0.132227    -0.052099    -0.019278     0.199577   \n",
       "788905    -0.124836    -0.192118    -0.051675    -0.119680    -0.058971   \n",
       "788915    -0.166191    -0.000782    -0.092432    -0.070292     0.093273   \n",
       "788919    -0.112934    -0.196180    -0.037219    -0.073335    -0.025841   \n",
       "\n",
       "        embedding_7  ...  embedding_40  embedding_41  embedding_42  \\\n",
       "6         -0.031395  ...      0.003378     -0.052069     -0.041864   \n",
       "7          0.032471  ...     -0.029178     -0.004683      0.011520   \n",
       "34        -0.010910  ...     -0.020540     -0.014132     -0.005759   \n",
       "42        -0.023304  ...      0.038496     -0.037873      0.022945   \n",
       "54         0.200493  ...     -0.038150     -0.016747     -0.015484   \n",
       "...             ...  ...           ...           ...           ...   \n",
       "788899     0.055768  ...      0.020827      0.022513      0.002828   \n",
       "788901     0.016658  ...     -0.018988      0.026841      0.002417   \n",
       "788905     0.090961  ...     -0.033102     -0.033691     -0.007603   \n",
       "788915     0.061433  ...      0.000784      0.029490      0.038883   \n",
       "788919     0.035394  ...     -0.033298     -0.063111      0.020878   \n",
       "\n",
       "        embedding_43  embedding_44  embedding_45  embedding_46  embedding_47  \\\n",
       "6          -0.063332     -0.004891      0.041612     -0.008916     -0.037787   \n",
       "7           0.027406     -0.013488     -0.020637      0.006689      0.026539   \n",
       "34         -0.017750      0.017853      0.011929      0.016674     -0.001780   \n",
       "42         -0.018770      0.011276     -0.014351      0.051906      0.022502   \n",
       "54         -0.006765      0.025826      0.014034      0.044829      0.073610   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "788899      0.023398      0.070388     -0.010765      0.004683      0.002490   \n",
       "788901     -0.020538     -0.029363      0.016880     -0.034594     -0.037387   \n",
       "788905     -0.023790      0.041450      0.000611      0.005436     -0.003637   \n",
       "788915     -0.023161      0.003190     -0.034493     -0.074051     -0.037351   \n",
       "788919     -0.027317      0.011153     -0.001443     -0.016620     -0.010329   \n",
       "\n",
       "        embedding_48  embedding_49  \n",
       "6          -0.015231     -0.011546  \n",
       "7           0.000174      0.001229  \n",
       "34         -0.011683     -0.030882  \n",
       "42         -0.017162     -0.004475  \n",
       "54         -0.015819      0.007446  \n",
       "...              ...           ...  \n",
       "788899     -0.032236      0.021076  \n",
       "788901      0.016397      0.030583  \n",
       "788905      0.026415     -0.015854  \n",
       "788915      0.006461     -0.027971  \n",
       "788919      0.011247     -0.003789  \n",
       "\n",
       "[133164 rows x 52 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = selectedDataFrame.drop(['sourceEncoded'], axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8555d7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6         37\n",
       "7         58\n",
       "34        13\n",
       "42        58\n",
       "54        59\n",
       "          ..\n",
       "788899    13\n",
       "788901    13\n",
       "788905    58\n",
       "788915    59\n",
       "788919    41\n",
       "Name: sourceEncoded, Length: 133164, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = selectedDataFrame['sourceEncoded']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d7d2cf",
   "metadata": {},
   "source": [
    "# Data split for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adbf3234",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae91d054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106531, 52)\n",
      "(26633, 52)\n",
      "(106531,)\n",
      "(26633,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c831d6",
   "metadata": {},
   "source": [
    "# Oversampling using ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bae4c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn = ADASYN()\n",
    "X_oversampled, y_oversampled = adasyn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efb32ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>embedding_0</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_40</th>\n",
       "      <th>embedding_41</th>\n",
       "      <th>embedding_42</th>\n",
       "      <th>embedding_43</th>\n",
       "      <th>embedding_44</th>\n",
       "      <th>embedding_45</th>\n",
       "      <th>embedding_46</th>\n",
       "      <th>embedding_47</th>\n",
       "      <th>embedding_48</th>\n",
       "      <th>embedding_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.752577</td>\n",
       "      <td>40.690000</td>\n",
       "      <td>-0.204950</td>\n",
       "      <td>0.098549</td>\n",
       "      <td>-0.016005</td>\n",
       "      <td>-0.070903</td>\n",
       "      <td>0.039634</td>\n",
       "      <td>0.004938</td>\n",
       "      <td>0.005084</td>\n",
       "      <td>-0.023801</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023121</td>\n",
       "      <td>-0.054560</td>\n",
       "      <td>-0.007940</td>\n",
       "      <td>-0.017508</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>-0.032671</td>\n",
       "      <td>-0.012267</td>\n",
       "      <td>-0.035420</td>\n",
       "      <td>-0.029598</td>\n",
       "      <td>0.007800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.662791</td>\n",
       "      <td>82.440000</td>\n",
       "      <td>-0.091552</td>\n",
       "      <td>0.011706</td>\n",
       "      <td>0.069581</td>\n",
       "      <td>-0.237689</td>\n",
       "      <td>0.046251</td>\n",
       "      <td>0.152222</td>\n",
       "      <td>-0.004697</td>\n",
       "      <td>-0.027788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.029759</td>\n",
       "      <td>-0.003016</td>\n",
       "      <td>0.033535</td>\n",
       "      <td>0.049674</td>\n",
       "      <td>0.005018</td>\n",
       "      <td>-0.044019</td>\n",
       "      <td>-0.002381</td>\n",
       "      <td>0.035043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.556034</td>\n",
       "      <td>72.560000</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>0.143419</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>-0.119575</td>\n",
       "      <td>0.025752</td>\n",
       "      <td>-0.062705</td>\n",
       "      <td>0.073281</td>\n",
       "      <td>-0.067261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016915</td>\n",
       "      <td>0.029244</td>\n",
       "      <td>0.013929</td>\n",
       "      <td>0.050985</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>0.051455</td>\n",
       "      <td>0.023458</td>\n",
       "      <td>0.020656</td>\n",
       "      <td>-0.022565</td>\n",
       "      <td>0.013477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.806452</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>-0.330653</td>\n",
       "      <td>0.071714</td>\n",
       "      <td>0.070528</td>\n",
       "      <td>-0.030881</td>\n",
       "      <td>0.080423</td>\n",
       "      <td>-0.072295</td>\n",
       "      <td>0.080562</td>\n",
       "      <td>0.011694</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052466</td>\n",
       "      <td>0.037395</td>\n",
       "      <td>-0.012585</td>\n",
       "      <td>0.012332</td>\n",
       "      <td>0.026525</td>\n",
       "      <td>-0.045064</td>\n",
       "      <td>0.054542</td>\n",
       "      <td>-0.014237</td>\n",
       "      <td>-0.005990</td>\n",
       "      <td>0.029337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.645390</td>\n",
       "      <td>54.150000</td>\n",
       "      <td>-0.025661</td>\n",
       "      <td>-0.091636</td>\n",
       "      <td>-0.210518</td>\n",
       "      <td>-0.085936</td>\n",
       "      <td>-0.003314</td>\n",
       "      <td>-0.035615</td>\n",
       "      <td>-0.094097</td>\n",
       "      <td>-0.036325</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002764</td>\n",
       "      <td>-0.009659</td>\n",
       "      <td>-0.049980</td>\n",
       "      <td>-0.026881</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>-0.028190</td>\n",
       "      <td>0.019145</td>\n",
       "      <td>-0.025257</td>\n",
       "      <td>-0.001848</td>\n",
       "      <td>0.006388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212330</th>\n",
       "      <td>0.772524</td>\n",
       "      <td>62.380000</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.148164</td>\n",
       "      <td>0.044331</td>\n",
       "      <td>0.010512</td>\n",
       "      <td>-0.150918</td>\n",
       "      <td>-0.039190</td>\n",
       "      <td>-0.174302</td>\n",
       "      <td>0.133292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013349</td>\n",
       "      <td>0.015207</td>\n",
       "      <td>0.014579</td>\n",
       "      <td>0.031889</td>\n",
       "      <td>0.012254</td>\n",
       "      <td>0.049691</td>\n",
       "      <td>0.019144</td>\n",
       "      <td>-0.009482</td>\n",
       "      <td>-0.015168</td>\n",
       "      <td>-0.062566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212331</th>\n",
       "      <td>0.570353</td>\n",
       "      <td>80.187572</td>\n",
       "      <td>0.250984</td>\n",
       "      <td>-0.112474</td>\n",
       "      <td>-0.129416</td>\n",
       "      <td>0.041581</td>\n",
       "      <td>-0.042187</td>\n",
       "      <td>-0.075098</td>\n",
       "      <td>0.038279</td>\n",
       "      <td>0.062097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>-0.005368</td>\n",
       "      <td>-0.042526</td>\n",
       "      <td>0.024095</td>\n",
       "      <td>-0.003162</td>\n",
       "      <td>0.031540</td>\n",
       "      <td>-0.001310</td>\n",
       "      <td>0.010929</td>\n",
       "      <td>-0.001356</td>\n",
       "      <td>0.011391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212332</th>\n",
       "      <td>0.743410</td>\n",
       "      <td>85.128678</td>\n",
       "      <td>0.183909</td>\n",
       "      <td>0.078467</td>\n",
       "      <td>0.034185</td>\n",
       "      <td>-0.136881</td>\n",
       "      <td>-0.045986</td>\n",
       "      <td>0.104006</td>\n",
       "      <td>0.068179</td>\n",
       "      <td>-0.091670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000839</td>\n",
       "      <td>-0.012105</td>\n",
       "      <td>0.011661</td>\n",
       "      <td>-0.054008</td>\n",
       "      <td>0.019639</td>\n",
       "      <td>0.026192</td>\n",
       "      <td>-0.005470</td>\n",
       "      <td>-0.004956</td>\n",
       "      <td>0.024217</td>\n",
       "      <td>0.016126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212333</th>\n",
       "      <td>0.555079</td>\n",
       "      <td>48.924755</td>\n",
       "      <td>-0.165414</td>\n",
       "      <td>-0.058040</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>-0.097961</td>\n",
       "      <td>0.112386</td>\n",
       "      <td>-0.001168</td>\n",
       "      <td>0.093758</td>\n",
       "      <td>-0.066165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001467</td>\n",
       "      <td>-0.006711</td>\n",
       "      <td>-0.027500</td>\n",
       "      <td>0.011319</td>\n",
       "      <td>0.017755</td>\n",
       "      <td>-0.009610</td>\n",
       "      <td>0.008199</td>\n",
       "      <td>0.010104</td>\n",
       "      <td>-0.012979</td>\n",
       "      <td>-0.004073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212334</th>\n",
       "      <td>0.603879</td>\n",
       "      <td>76.250000</td>\n",
       "      <td>0.143795</td>\n",
       "      <td>-0.083961</td>\n",
       "      <td>-0.031001</td>\n",
       "      <td>-0.091659</td>\n",
       "      <td>-0.016369</td>\n",
       "      <td>-0.033328</td>\n",
       "      <td>0.049232</td>\n",
       "      <td>-0.074147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008341</td>\n",
       "      <td>-0.017851</td>\n",
       "      <td>-0.003280</td>\n",
       "      <td>-0.020910</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>-0.010383</td>\n",
       "      <td>-0.002875</td>\n",
       "      <td>0.025942</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.013740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212335 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lexical_diversity  readability_score  embedding_0  embedding_1  \\\n",
       "0                0.752577          40.690000    -0.204950     0.098549   \n",
       "1                0.662791          82.440000    -0.091552     0.011706   \n",
       "2                0.556034          72.560000     0.007215     0.143419   \n",
       "3                0.806452          37.500000    -0.330653     0.071714   \n",
       "4                0.645390          54.150000    -0.025661    -0.091636   \n",
       "...                   ...                ...          ...          ...   \n",
       "212330           0.772524          62.380000     0.009781     0.148164   \n",
       "212331           0.570353          80.187572     0.250984    -0.112474   \n",
       "212332           0.743410          85.128678     0.183909     0.078467   \n",
       "212333           0.555079          48.924755    -0.165414    -0.058040   \n",
       "212334           0.603879          76.250000     0.143795    -0.083961   \n",
       "\n",
       "        embedding_2  embedding_3  embedding_4  embedding_5  embedding_6  \\\n",
       "0         -0.016005    -0.070903     0.039634     0.004938     0.005084   \n",
       "1          0.069581    -0.237689     0.046251     0.152222    -0.004697   \n",
       "2          0.000235    -0.119575     0.025752    -0.062705     0.073281   \n",
       "3          0.070528    -0.030881     0.080423    -0.072295     0.080562   \n",
       "4         -0.210518    -0.085936    -0.003314    -0.035615    -0.094097   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "212330     0.044331     0.010512    -0.150918    -0.039190    -0.174302   \n",
       "212331    -0.129416     0.041581    -0.042187    -0.075098     0.038279   \n",
       "212332     0.034185    -0.136881    -0.045986     0.104006     0.068179   \n",
       "212333     0.000044    -0.097961     0.112386    -0.001168     0.093758   \n",
       "212334    -0.031001    -0.091659    -0.016369    -0.033328     0.049232   \n",
       "\n",
       "        embedding_7  ...  embedding_40  embedding_41  embedding_42  \\\n",
       "0         -0.023801  ...     -0.023121     -0.054560     -0.007940   \n",
       "1         -0.027788  ...      0.007854      0.001624      0.029759   \n",
       "2         -0.067261  ...     -0.016915      0.029244      0.013929   \n",
       "3          0.011694  ...     -0.052466      0.037395     -0.012585   \n",
       "4         -0.036325  ...     -0.002764     -0.009659     -0.049980   \n",
       "...             ...  ...           ...           ...           ...   \n",
       "212330     0.133292  ...      0.013349      0.015207      0.014579   \n",
       "212331     0.062097  ...      0.001927     -0.005368     -0.042526   \n",
       "212332    -0.091670  ...     -0.000839     -0.012105      0.011661   \n",
       "212333    -0.066165  ...     -0.001467     -0.006711     -0.027500   \n",
       "212334    -0.074147  ...      0.008341     -0.017851     -0.003280   \n",
       "\n",
       "        embedding_43  embedding_44  embedding_45  embedding_46  embedding_47  \\\n",
       "0          -0.017508      0.013212     -0.032671     -0.012267     -0.035420   \n",
       "1          -0.003016      0.033535      0.049674      0.005018     -0.044019   \n",
       "2           0.050985      0.004976      0.051455      0.023458      0.020656   \n",
       "3           0.012332      0.026525     -0.045064      0.054542     -0.014237   \n",
       "4          -0.026881     -0.000158     -0.028190      0.019145     -0.025257   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "212330      0.031889      0.012254      0.049691      0.019144     -0.009482   \n",
       "212331      0.024095     -0.003162      0.031540     -0.001310      0.010929   \n",
       "212332     -0.054008      0.019639      0.026192     -0.005470     -0.004956   \n",
       "212333      0.011319      0.017755     -0.009610      0.008199      0.010104   \n",
       "212334     -0.020910      0.036802     -0.010383     -0.002875      0.025942   \n",
       "\n",
       "        embedding_48  embedding_49  \n",
       "0          -0.029598      0.007800  \n",
       "1          -0.002381      0.035043  \n",
       "2          -0.022565      0.013477  \n",
       "3          -0.005990      0.029337  \n",
       "4          -0.001848      0.006388  \n",
       "...              ...           ...  \n",
       "212330     -0.015168     -0.062566  \n",
       "212331     -0.001356      0.011391  \n",
       "212332      0.024217      0.016126  \n",
       "212333     -0.012979     -0.004073  \n",
       "212334      0.002933      0.013740  \n",
       "\n",
       "[212335 rows x 52 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d645a51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41    44476\n",
       "37    43420\n",
       "58    41920\n",
       "13    41787\n",
       "59    40732\n",
       "Name: sourceEncoded, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_oversampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ac8ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dc617d0",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97b5d57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_oversampled, y_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aae3638e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          13       0.72      0.92      0.81      8208\n",
      "          37       0.55      0.54      0.55      3691\n",
      "          41       0.72      0.63      0.67      4113\n",
      "          58       0.68      0.56      0.62      5229\n",
      "          59       0.56      0.47      0.51      5392\n",
      "\n",
      "    accuracy                           0.66     26633\n",
      "   macro avg       0.64      0.62      0.63     26633\n",
      "weighted avg       0.65      0.66      0.65     26633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_hat_rf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8062a236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6610595877295085"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_accuracy = accuracy_score(y_test, y_hat_rf)\n",
    "rf_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e16d092",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e145dc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cibhibaskar/Desktop/Kaggle/LLMHuman/env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_model = LogisticRegression(max_iter = 1000)\n",
    "\n",
    "log_reg_model.fit(X_oversampled,y_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dffadc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          13       0.89      0.71      0.79     10559\n",
      "          37       0.42      0.43      0.42      3616\n",
      "          41       0.59      0.73      0.65      3627\n",
      "          58       0.52      0.60      0.56      4305\n",
      "          59       0.43      0.46      0.45      4526\n",
      "\n",
      "    accuracy                           0.62     26633\n",
      "   macro avg       0.57      0.59      0.57     26633\n",
      "weighted avg       0.64      0.62      0.62     26633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_logreg = log_reg_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_hat_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2a203ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6157398715878797"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_accuracy = accuracy_score(y_test, y_hat_logreg)\n",
    "logreg_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4fc382",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9388b268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf_model = KNeighborsClassifier()\n",
    "\n",
    "knn_clf_model.fit(X_oversampled, y_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9d197c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          13       0.92      0.63      0.75     10559\n",
      "          37       0.28      0.48      0.35      3616\n",
      "          41       0.42      0.64      0.51      3627\n",
      "          58       0.48      0.40      0.44      4305\n",
      "          59       0.38      0.34      0.36      4526\n",
      "\n",
      "    accuracy                           0.53     26633\n",
      "   macro avg       0.50      0.50      0.48     26633\n",
      "weighted avg       0.60      0.53      0.55     26633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_knn = knn_clf_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_hat_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6266b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5252881763226073"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_accuracy = accuracy_score(y_test, y_hat_knn)\n",
    "knn_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e91d9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4667534",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5aedc0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=1000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_model = MLPClassifier(alpha=0.0001, hidden_layer_sizes=(50, 50), learning_rate_init=0.001, max_iter=1000)\n",
    "mlp_model.fit(X_oversampled, y_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b223c1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          13       0.75      0.93      0.83      8507\n",
      "          37       0.62      0.60      0.61      3726\n",
      "          41       0.69      0.71      0.70      3496\n",
      "          58       0.72      0.61      0.66      5084\n",
      "          59       0.63      0.49      0.55      5820\n",
      "\n",
      "    accuracy                           0.70     26633\n",
      "   macro avg       0.68      0.67      0.67     26633\n",
      "weighted avg       0.69      0.70      0.69     26633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_mlp = mlp_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_hat_mlp, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd82271d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6974054744114444"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_accuracy = accuracy_score(y_test, y_hat_mlp)\n",
    "mlp_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6118b8",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning of MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14379175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.model_selection import GridSearchCV\\n\\n# Define hyperparameters to search\\n\\nmlp_param_grid = {\\n    'hidden_layer_sizes': [(100,), (50, 50), (50, 100, 50)],\\n    'alpha': [0.0001 ,0.001, 0.01],\\n    'learning_rate_init': [0.001, 0.01, 0.1],\\n}\\n\\n# Grid search with cross-validation\\nmlp_grid_search = GridSearchCV(mlp_model, mlp_param_grid, cv=5, scoring='accuracy', verbose=3)\\nmlp_grid_search.fit(X_oversampled, y_oversampled)\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameters to search\n",
    "\n",
    "mlp_param_grid = {\n",
    "    'hidden_layer_sizes': [(100,), (50, 50), (50, 100, 50)],\n",
    "    'alpha': [0.0001 ,0.001, 0.01],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "mlp_grid_search = GridSearchCV(mlp_model, mlp_param_grid, cv=5, scoring='accuracy', verbose=3)\n",
    "mlp_grid_search.fit(X_oversampled, y_oversampled)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2e0a31",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent (SGD) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2edd60db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(X_oversampled, y_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40e6a71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          13       0.83      0.77      0.80     10559\n",
      "          37       0.30      0.84      0.44      3616\n",
      "          41       0.71      0.40      0.51      3627\n",
      "          58       0.72      0.21      0.33      4305\n",
      "          59       0.46      0.33      0.38      4526\n",
      "\n",
      "    accuracy                           0.57     26633\n",
      "   macro avg       0.60      0.51      0.49     26633\n",
      "weighted avg       0.66      0.57      0.57     26633\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat_sgd = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_hat_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da8f1d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5661022040325911"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_accuracy = accuracy_score(y_test, y_hat_sgd)\n",
    "sgd_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9490ea28",
   "metadata": {},
   "source": [
    "# Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1a23ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = ['Logistic Regression', 'Random Forest Classifier', \n",
    "          'K-Nearest Neighbor Classifier', 'Multilayer Perceptron Classifier', \n",
    "          'SGD Classifier']\n",
    "\n",
    "accuracy_scores = [round(logreg_accuracy, 2), round(rf_accuracy, 2), round(knn_accuracy, 2),\n",
    "                  round(mlp_accuracy, 2), round(sgd_accuracy, 2)]\n",
    "\n",
    "plt.figure(figsize=[15,5])\n",
    "plt.bar(models, accuracy_scores, color=['maroon', 'lightgreen', 'lightblue', 'red', 'green'])\n",
    "\n",
    "plt.ylabel('Accuracy Score')\n",
    "\n",
    "for i in range(len(models)):\n",
    "    plt.text(i,accuracy_scores[i], str(accuracy_scores[i]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49f448",
   "metadata": {},
   "source": [
    "# Save the model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d122111",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('multiclassclf_mlp.pkl', 'wb') as f:\n",
    "    pickle.dump(mlp_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad096a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a1d0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29e533b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
